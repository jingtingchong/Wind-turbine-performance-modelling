{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from typing import Iterable\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from joblib import dump, load\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data_finetune = pd.read_csv(\"data_finetune.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>instanceID</th>\n",
       "      <th>Wind_speed</th>\n",
       "      <th>TI</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450954</th>\n",
       "      <td>2020-12-13 23:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>B_WTG01</td>\n",
       "      <td>6.219789</td>\n",
       "      <td>13.680036</td>\n",
       "      <td>9.128333</td>\n",
       "      <td>542.963406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250695</th>\n",
       "      <td>2020-07-12 10:30:00</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>B_WTG01</td>\n",
       "      <td>5.502723</td>\n",
       "      <td>19.909536</td>\n",
       "      <td>18.020833</td>\n",
       "      <td>361.234628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471681</th>\n",
       "      <td>2020-12-29 22:50:00</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>B_WTG01</td>\n",
       "      <td>6.885329</td>\n",
       "      <td>12.528561</td>\n",
       "      <td>4.351667</td>\n",
       "      <td>762.492368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408888</th>\n",
       "      <td>2020-11-11 12:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>B_WTG01</td>\n",
       "      <td>9.122236</td>\n",
       "      <td>10.780250</td>\n",
       "      <td>10.756667</td>\n",
       "      <td>1569.216417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14913</th>\n",
       "      <td>2020-01-12 12:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>B_WTG01</td>\n",
       "      <td>5.227403</td>\n",
       "      <td>18.879639</td>\n",
       "      <td>8.642500</td>\n",
       "      <td>280.115814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425465</th>\n",
       "      <td>2020-11-24 06:50:00</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>B_WTG09</td>\n",
       "      <td>7.298661</td>\n",
       "      <td>15.227533</td>\n",
       "      <td>12.595834</td>\n",
       "      <td>781.406852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101672</th>\n",
       "      <td>2020-03-19 10:40:00</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>B_WTG09</td>\n",
       "      <td>3.191359</td>\n",
       "      <td>17.653836</td>\n",
       "      <td>9.745000</td>\n",
       "      <td>40.664581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42776</th>\n",
       "      <td>2020-02-03 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>B_WTG09</td>\n",
       "      <td>6.644093</td>\n",
       "      <td>14.493794</td>\n",
       "      <td>9.076667</td>\n",
       "      <td>612.544883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>2020-01-08 15:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>B_WTG09</td>\n",
       "      <td>5.745972</td>\n",
       "      <td>13.970354</td>\n",
       "      <td>7.398333</td>\n",
       "      <td>342.725793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223100</th>\n",
       "      <td>2020-06-21 03:20:00</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>B_WTG09</td>\n",
       "      <td>6.655664</td>\n",
       "      <td>11.410919</td>\n",
       "      <td>14.946666</td>\n",
       "      <td>579.849779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ts  Month  Day  Hour instanceID  Wind_speed  \\\n",
       "450954  2020-12-13 23:00:00     12   13    23    B_WTG01    6.219789   \n",
       "250695  2020-07-12 10:30:00      7   12    10    B_WTG01    5.502723   \n",
       "471681  2020-12-29 22:50:00     12   29    22    B_WTG01    6.885329   \n",
       "408888  2020-11-11 12:00:00     11   11    12    B_WTG01    9.122236   \n",
       "14913   2020-01-12 12:10:00      1   12    12    B_WTG01    5.227403   \n",
       "...                     ...    ...  ...   ...        ...         ...   \n",
       "425465  2020-11-24 06:50:00     11   24     6    B_WTG09    7.298661   \n",
       "101672  2020-03-19 10:40:00      3   19    10    B_WTG09    3.191359   \n",
       "42776   2020-02-03 00:00:00      2    3     0    B_WTG09    6.644093   \n",
       "9908    2020-01-08 15:20:00      1    8    15    B_WTG09    5.745972   \n",
       "223100  2020-06-21 03:20:00      6   21     3    B_WTG09    6.655664   \n",
       "\n",
       "               TI  Temperature        Power  \n",
       "450954  13.680036     9.128333   542.963406  \n",
       "250695  19.909536    18.020833   361.234628  \n",
       "471681  12.528561     4.351667   762.492368  \n",
       "408888  10.780250    10.756667  1569.216417  \n",
       "14913   18.879639     8.642500   280.115814  \n",
       "...           ...          ...          ...  \n",
       "425465  15.227533    12.595834   781.406852  \n",
       "101672  17.653836     9.745000    40.664581  \n",
       "42776   14.493794     9.076667   612.544883  \n",
       "9908    13.970354     7.398333   342.725793  \n",
       "223100  11.410919    14.946666   579.849779  \n",
       "\n",
       "[90000 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load normalization function \n",
    "scaler1 = load('scaler1.bin')\n",
    "scaler2 = load('scaler2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_count = data_finetune['instanceID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dims: Iterable[int], output_activation: nn.Module = None):\n",
    "        \"\"\"Creates a network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = dims[0]\n",
    "        self.out_size = dims[-1]\n",
    "        self.layers = self.make_seq(dims, output_activation)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_seq(dims: Iterable[int], output_activation: nn.Module) -> nn.Module:\n",
    "        \"\"\"Creates a sequential network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        :return (nn.Module): return created sequential layers\n",
    "        \"\"\"\n",
    "        mods = []\n",
    "\n",
    "        for i in range(len(dims) - 2):\n",
    "            mods.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            mods.append(nn.ReLU())\n",
    "\n",
    "        mods.append(nn.Linear(dims[-2], dims[-1]))\n",
    "        if output_activation:\n",
    "            mods.append(output_activation())\n",
    "        return nn.Sequential(*mods)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Computes a forward pass through the network\n",
    "\n",
    "        :param x (torch.Tensor): input tensor to feed into the network\n",
    "        :return (torch.Tensor): output computed by the network\n",
    "        \"\"\"\n",
    "        # Feedforward\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, quantile, net, lr, batch_size, epoch):    \n",
    "    \n",
    "    # create tensor dataset\n",
    "    train = TensorDataset(Tensor(X), Tensor(y))\n",
    "\n",
    "    # create data loader from dataset\n",
    "    trainset = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr = lr)\n",
    "        \n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for ep in range(epoch):\n",
    "\n",
    "        for t in trainset:\n",
    "            X_temp, y_temp = t\n",
    "            output = net(X_temp)\n",
    "            residual = y_temp - output\n",
    "            loss = Tensor.max(quantile*residual, (quantile-1)*residual).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return net, net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use a very low learning rate at this stage, because we are training on a dataset that is very small. This is to prevent the risk of overfitting very quickly if we apply large weight updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hyperparameters\n",
    "model = torch.load(sys.path[0] + '/hparams_finetune.pth')\n",
    "\n",
    "# load the pretrained weights\n",
    "pretrain = torch.load(sys.path[0] + '/pretrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median': OrderedDict([('layers.0.weight',\n",
       "               tensor([[-0.4231,  0.2336, -0.0885],\n",
       "                       [-0.6750, -0.1923,  0.1808],\n",
       "                       [-0.0807, -0.1944,  0.1123],\n",
       "                       [ 0.0126, -0.2398, -0.1289],\n",
       "                       [ 0.4486, -0.2861,  0.3437],\n",
       "                       [-0.6428,  0.3671, -0.4600],\n",
       "                       [ 0.5408, -0.2385, -0.1524],\n",
       "                       [ 0.3557, -0.1515,  0.2148],\n",
       "                       [-0.6883, -0.1069,  0.0626],\n",
       "                       [-0.4806,  0.2262,  0.1405],\n",
       "                       [ 0.0316, -0.0122,  0.1909],\n",
       "                       [ 0.0300,  0.3099,  0.2421],\n",
       "                       [-0.3464, -0.2597, -0.2908],\n",
       "                       [ 0.8016,  0.2263, -0.2149],\n",
       "                       [ 0.3245,  0.2140,  0.3012],\n",
       "                       [ 0.6756,  0.0734, -0.0814]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([-0.1946, -0.3724,  0.6272,  0.1927, -0.2128,  0.2722,  0.6633, -0.1131,\n",
       "                        0.4979, -0.6168,  0.1588,  0.6774, -0.2937,  0.4460,  0.2466,  0.5666])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[ 1.1829e-01,  3.5958e-01, -2.9728e-02,  9.5605e-02, -2.6772e-01,\n",
       "                         1.6992e-01, -1.7877e-02,  4.5073e-02,  3.4833e-01,  1.9070e-01,\n",
       "                         2.5188e-01, -4.2475e-02,  2.1249e-01, -4.5607e-01, -1.6487e-01,\n",
       "                        -6.8518e-04],\n",
       "                       [ 1.5580e-01, -1.6206e-01,  3.6279e-01,  1.0384e-01, -2.1074e-01,\n",
       "                         8.9101e-02,  1.0249e-01, -2.8008e-01, -2.4225e-01, -5.1495e-01,\n",
       "                         1.3444e-01,  2.8690e-01,  1.8028e-01,  1.1570e-01, -1.5742e-02,\n",
       "                        -1.2090e-01],\n",
       "                       [-2.1535e-02, -3.5853e-02,  6.2717e-02, -7.8028e-02,  1.1687e-02,\n",
       "                        -5.3700e-02,  1.4687e-01,  2.5974e-02, -9.0871e-02,  2.2448e-01,\n",
       "                         3.2211e-01, -1.1298e-01,  8.7987e-02,  2.4754e-01, -1.0339e-01,\n",
       "                         1.3341e-01],\n",
       "                       [-3.1508e-02,  6.3375e-02,  3.7084e-02,  2.4989e-01,  5.4741e-02,\n",
       "                        -3.1028e-01,  2.8800e-01,  1.8060e-02, -6.1930e-02, -3.1424e-01,\n",
       "                         1.6928e-01, -2.0836e-01,  1.2905e-01,  1.2524e-01,  1.1334e-01,\n",
       "                        -4.8638e-02],\n",
       "                       [ 1.6101e-01,  2.1041e-01,  5.2900e-02,  1.0155e-01, -1.3879e-01,\n",
       "                        -8.8968e-02, -2.3388e-01, -6.4342e-02,  1.3531e-01, -2.8094e-01,\n",
       "                         8.0969e-02,  8.9909e-02, -5.6404e-02, -4.3753e-02,  8.2246e-02,\n",
       "                         4.1646e-02],\n",
       "                       [ 1.8594e-01,  8.9738e-03,  1.3136e-01,  5.5434e-02, -2.8886e-01,\n",
       "                        -2.7328e-02, -1.1717e-01,  3.4170e-02,  1.1256e-01,  4.8416e-01,\n",
       "                         9.5931e-02, -9.0552e-02, -1.1473e-01, -3.6468e-01, -1.2636e-01,\n",
       "                        -6.8256e-01],\n",
       "                       [-8.3030e-03, -4.1468e-01,  1.5119e-01,  5.3932e-02,  1.7954e-01,\n",
       "                        -4.5883e-02,  3.2276e-01,  6.2416e-02, -3.4730e-02, -1.6200e-01,\n",
       "                         2.3022e-01, -3.1903e-02, -1.5600e-01,  2.6247e-01,  3.3211e-02,\n",
       "                         3.2145e-01],\n",
       "                       [ 2.3133e-01,  3.3078e-01,  3.4455e-01,  6.6273e-02, -2.8636e-03,\n",
       "                         1.2602e-01,  6.6641e-02, -3.3272e-01,  1.8316e-01, -6.1219e-02,\n",
       "                        -2.4865e-02,  6.5117e-04, -1.9618e-01, -1.9379e-01,  2.3055e-01,\n",
       "                         7.3519e-02],\n",
       "                       [-1.0619e-01, -3.7404e-01,  3.2979e-01, -2.4930e-01, -3.0664e-01,\n",
       "                         2.5243e-01,  5.1309e-02, -2.7809e-01, -1.0494e-01, -9.8522e-02,\n",
       "                         2.5931e-01, -2.0169e-02, -3.3272e-02, -1.8104e-01, -2.9613e-02,\n",
       "                        -7.2807e-02],\n",
       "                       [ 2.2109e-01,  2.0741e-01,  1.3481e-01,  1.7926e-01,  2.5770e-01,\n",
       "                        -3.1676e-01,  1.7370e-01,  6.2593e-01, -1.0951e-01,  6.8560e-01,\n",
       "                         5.1009e-02, -6.1298e-01,  1.0007e-01, -2.9900e-01, -3.4324e-01,\n",
       "                        -2.1258e-01],\n",
       "                       [-5.7470e-02, -1.0621e-01, -1.2487e-01, -2.0733e-01,  1.6682e-01,\n",
       "                        -1.7360e-01, -2.4696e-01,  1.0250e-01, -9.6769e-02,  3.4987e-02,\n",
       "                         1.2928e-01,  1.5402e-01,  1.4987e-01, -1.4127e-01, -2.4705e-01,\n",
       "                        -9.0420e-02],\n",
       "                       [ 9.0591e-02,  3.5831e-01,  1.6438e-01,  2.0459e-01, -9.0442e-02,\n",
       "                         2.5482e-01, -6.3298e-02, -1.6664e-01,  4.6027e-01, -1.0181e-03,\n",
       "                        -1.3394e-01,  2.3820e-01,  1.6622e-01, -2.9613e-01, -1.5753e-01,\n",
       "                        -1.8464e-01],\n",
       "                       [ 8.3814e-03,  2.7576e-01, -3.0736e-01, -1.1104e-01, -1.0382e-01,\n",
       "                        -1.7517e-01, -1.7400e-01, -2.3056e-01,  1.2577e-01,  2.8354e-01,\n",
       "                        -1.3492e-01, -1.5100e-01,  1.9089e-01, -1.1344e-01, -1.6133e-02,\n",
       "                        -3.3567e-01],\n",
       "                       [-2.2086e-02, -2.2185e-01,  2.3253e-01, -1.1421e-01,  9.0163e-02,\n",
       "                         1.4491e-02,  9.2369e-03, -2.3447e-02, -2.4321e-01, -1.8167e-01,\n",
       "                         2.6234e-01, -4.2921e-02,  1.6278e-01,  1.2200e-01, -1.8660e-01,\n",
       "                         1.9924e-01],\n",
       "                       [-1.5888e-01, -2.2125e-02,  1.9484e-01, -1.0025e-01, -7.0567e-02,\n",
       "                         1.2452e-01,  3.0443e-01, -1.0320e-01,  9.2593e-02, -1.4420e-01,\n",
       "                        -3.9743e-02,  2.6332e-01, -7.8850e-02, -1.9274e-01, -9.4817e-02,\n",
       "                        -9.3110e-02],\n",
       "                       [-2.5208e-02, -3.6289e-01,  1.7043e-01,  8.9808e-02,  5.4916e-02,\n",
       "                        -1.6576e-02,  2.0428e-01,  1.0217e-01, -2.6670e-02, -3.5527e-01,\n",
       "                        -8.9357e-02,  1.2325e-01, -7.6022e-02,  9.1346e-02,  1.5884e-01,\n",
       "                         1.2481e-01]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.3483,  0.3825,  0.0328,  0.0909,  0.3056, -0.0559,  0.2165,  0.1601,\n",
       "                       -0.0277, -0.1390, -0.1869,  0.3000, -0.1121,  0.1240,  0.4077,  0.0227])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[ 0.2546,  0.0115,  0.0085,  0.1368, -0.0599, -0.0090, -0.2870,  0.1922,\n",
       "                        -0.1705,  0.3468, -0.1425,  0.1809,  0.2532,  0.1238,  0.2712, -0.3692],\n",
       "                       [ 0.1171,  0.0543, -0.1967,  0.0873, -0.0740,  0.1317, -0.2969, -0.0197,\n",
       "                        -0.0252, -0.0072,  0.1001,  0.2168,  0.0416,  0.0693,  0.3784, -0.2202],\n",
       "                       [ 0.1150, -0.1633, -0.0203, -0.1366, -0.2225,  0.1343, -0.2233, -0.0750,\n",
       "                        -0.0226, -0.2094,  0.2380, -0.0964, -0.2506,  0.0382, -0.2473, -0.0585],\n",
       "                       [-0.2556, -0.0911, -0.1488,  0.0517, -0.1852, -0.3029, -0.1081,  0.1113,\n",
       "                         0.0748,  0.0363,  0.1704,  0.1040, -0.2710, -0.1725,  0.1043, -0.1034],\n",
       "                       [-0.2275, -0.1285,  0.0995, -0.2374, -0.3164, -0.1213,  0.0121,  0.2659,\n",
       "                        -0.0696,  0.1870, -0.0716, -0.0936, -0.0662,  0.0881,  0.3630, -0.0651],\n",
       "                       [ 0.0334,  0.2221,  0.0017, -0.1095,  0.1093, -0.0594,  0.1756,  0.0251,\n",
       "                        -0.1138,  0.0889,  0.0658, -0.3121,  0.0913,  0.0944,  0.2446,  0.0254],\n",
       "                       [-0.1957,  0.1012,  0.1015, -0.0165, -0.0673,  0.1339,  0.2484, -0.1319,\n",
       "                        -0.0424,  0.0245,  0.0192, -0.5183, -0.2574,  0.1074,  0.0170,  0.0448],\n",
       "                       [ 0.0795,  0.2295, -0.2481, -0.1068,  0.2754,  0.2311, -0.2070,  0.1498,\n",
       "                         0.2121,  0.0015, -0.1154,  0.2336,  0.2251,  0.0903,  0.2711, -0.2237],\n",
       "                       [-0.0756,  0.2058, -0.0945,  0.0729, -0.0347,  0.1597,  0.1997,  0.1850,\n",
       "                         0.0750,  0.0407, -0.0652, -0.1866,  0.2654, -0.1341,  0.2348,  0.2235],\n",
       "                       [-0.0380,  0.0427,  0.1000,  0.1328, -0.2417, -0.3382,  0.1408,  0.1816,\n",
       "                        -0.3466,  0.3481,  0.0339,  0.0239, -0.3477, -0.1718,  0.2238, -0.0879],\n",
       "                       [ 0.0312, -0.2610,  0.2328,  0.0845, -0.2144, -0.1184,  0.2165, -0.0342,\n",
       "                        -0.0453,  0.1144, -0.1606, -0.2460, -0.0987,  0.0903, -0.0903, -0.0197],\n",
       "                       [ 0.3237,  0.0607,  0.0264, -0.3152,  0.1004, -0.1685, -0.1212,  0.3695,\n",
       "                         0.1232,  0.1120, -0.2477, -0.0312, -0.1549, -0.2541,  0.3000, -0.0152],\n",
       "                       [-0.1808, -0.0292,  0.2315, -0.0805, -0.2155,  0.2111, -0.2470, -0.1534,\n",
       "                        -0.2143,  0.1304, -0.2066,  0.1318,  0.1412, -0.0376, -0.1396, -0.2188],\n",
       "                       [-0.3821,  0.2807,  0.1242,  0.2591,  0.0862,  0.4064,  0.1393, -0.0919,\n",
       "                        -0.1334, -0.2662,  0.1328, -0.3959, -0.0622,  0.2117,  0.3033,  0.2696],\n",
       "                       [-0.0899, -0.0193,  0.0301, -0.2711,  0.2031,  0.2095, -0.1153,  0.0565,\n",
       "                         0.0153,  0.1927, -0.1450, -0.1738, -0.2700,  0.2675,  0.0682,  0.0441],\n",
       "                       [ 0.1593, -0.0637,  0.3025,  0.0465,  0.0682, -0.2632, -0.0244, -0.1912,\n",
       "                        -0.2647,  0.4211,  0.1547,  0.3453, -0.0017,  0.0200, -0.0511, -0.1538]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.3075,  0.4349,  0.1330, -0.2733,  0.5161,  0.0557,  0.2564,  0.3617,\n",
       "                       -0.1474,  0.3399, -0.4376,  0.1899, -0.0208,  0.3134,  0.0773, -0.0355])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[ 0.1367, -0.2470,  0.1897, -0.0887, -0.0515,  0.0760, -0.0887,  0.0092,\n",
       "                        -0.1060, -0.1623, -0.0822,  0.0674, -0.0970, -0.0968, -0.1188, -0.0321],\n",
       "                       [-0.2814, -0.3598,  0.0244,  0.1557,  0.1838,  0.0051,  0.1040, -0.4277,\n",
       "                         0.1077,  0.3118, -0.2653, -0.2021,  0.0089, -0.0544, -0.0295, -0.2498],\n",
       "                       [-0.2132, -0.1098, -0.1892, -0.2087, -0.0163, -0.0122,  0.2304, -0.0264,\n",
       "                         0.0844,  0.3020, -0.3454, -0.4088,  0.0022,  0.3473,  0.0839, -0.0394],\n",
       "                       [-0.1220,  0.1152, -0.0270,  0.0194,  0.2666,  0.2836,  0.1471,  0.0698,\n",
       "                        -0.0955,  0.0269, -0.4006,  0.1060, -0.1809,  0.2938,  0.2094, -0.1293],\n",
       "                       [ 0.0219, -0.2175,  0.1077, -0.0947,  0.0508, -0.2314,  0.1424, -0.3001,\n",
       "                         0.0715, -0.2692, -0.1004, -0.1368, -0.0869, -0.3089,  0.1140,  0.1758],\n",
       "                       [ 0.2515, -0.1562,  0.0882,  0.0968,  0.3666,  0.3003, -0.0168, -0.2121,\n",
       "                         0.0964, -0.0509,  0.0867, -0.1819, -0.0670,  0.3323, -0.0990, -0.1516],\n",
       "                       [-0.0450, -0.6807, -0.1706, -0.2088, -0.0808, -0.0261,  0.0726, -0.6411,\n",
       "                        -0.1245,  0.0819, -0.2397, -0.4813,  0.0051,  0.1308, -0.1009,  0.0803],\n",
       "                       [ 0.2782,  0.0902,  0.2897, -0.1233, -0.0942, -0.1376, -0.2178,  0.0772,\n",
       "                        -0.0031,  0.0968,  0.0666, -0.1440,  0.1484, -0.0911,  0.0990,  0.1939],\n",
       "                       [-0.0068,  0.3432, -0.0500, -0.2394,  0.2779, -0.2568, -0.2858,  0.2903,\n",
       "                        -0.1012,  0.1209, -0.0257,  0.2789,  0.0814, -0.1097,  0.0422,  0.0432],\n",
       "                       [-0.1700,  0.1872, -0.2574,  0.1646, -0.2248, -0.2845, -0.1804, -0.1683,\n",
       "                         0.1119,  0.1452,  0.1289, -0.2751,  0.1241, -0.1182, -0.1619,  0.0412],\n",
       "                       [ 0.1860,  0.2476, -0.0131, -0.0692, -0.0246, -0.1224,  0.0215, -0.2082,\n",
       "                         0.0971, -0.0964, -0.1339,  0.1349,  0.2453, -0.9816,  0.0335, -0.1743],\n",
       "                       [ 0.0477,  0.1526, -0.1317,  0.0747, -0.0279,  0.1799, -0.0189,  0.0345,\n",
       "                         0.0049,  0.2044, -0.8301, -0.3329,  0.1465, -0.1355, -0.0203, -0.2987],\n",
       "                       [ 0.2190,  0.0674, -0.1685, -0.2435, -0.0386,  0.1722,  0.1959,  0.0788,\n",
       "                        -0.1645, -0.2121,  0.4337, -0.0113, -0.1183,  0.0177, -0.1456, -0.2688],\n",
       "                       [ 0.2270,  0.0714, -0.0977,  0.1663,  0.3578, -0.0297,  0.0339,  0.2353,\n",
       "                        -0.2008, -0.0746, -0.3504,  0.1210, -0.1258, -0.2111,  0.1636, -0.1218],\n",
       "                       [ 0.0097,  0.3277,  0.2409, -0.1110, -0.1251, -0.1481, -0.1349,  0.2958,\n",
       "                        -0.2021,  0.3489,  0.0113,  0.2660,  0.2081,  0.0329, -0.1395,  0.2970],\n",
       "                       [ 0.1821,  0.2997,  0.1491,  0.0817, -0.0602,  0.1679, -0.0641,  0.0645,\n",
       "                        -0.0222,  0.0126, -0.1049,  0.3101,  0.0702, -0.2186, -0.0046, -0.0574]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.1096,  0.3807,  0.3647,  0.0389,  0.1080,  0.3271,  0.5251,  0.2514,\n",
       "                        0.3284,  0.0359, -0.0272,  0.0388, -0.1407,  0.2118,  0.0204,  0.2764])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[-0.0472,  0.2774,  0.3159,  0.1724,  0.0179,  0.2775,  0.3115, -0.1389,\n",
       "                        -0.2718, -0.0249,  0.0538, -0.0140, -0.0242, -0.2543, -0.1426, -0.2272]])),\n",
       "              ('layers.8.bias', tensor([0.1661]))]),\n",
       " 'UQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[-7.6303e-02, -1.9972e-01, -8.8184e-02],\n",
       "                       [-5.7976e-02,  1.5029e-01, -1.3686e-01],\n",
       "                       [-5.5003e-01,  6.2787e-02,  7.0958e-02],\n",
       "                       [-1.0924e+00, -1.4176e-01,  3.9364e-02],\n",
       "                       [-5.4260e-01,  1.4263e-01, -6.7817e-02],\n",
       "                       [-4.2788e-01,  2.1047e-01,  2.2179e-01],\n",
       "                       [ 2.1525e-01, -8.7318e-02, -6.7098e-02],\n",
       "                       [ 3.1853e-02,  2.5985e-01,  1.2418e-02],\n",
       "                       [-7.9748e-01,  3.7516e-02,  4.4851e-02],\n",
       "                       [ 3.6188e-01, -1.4674e-01,  6.1625e-02],\n",
       "                       [ 1.2435e-02,  1.7592e-02,  1.4849e-01],\n",
       "                       [-1.4767e-01, -2.5111e-01,  4.8075e-02],\n",
       "                       [ 2.4080e-01, -1.4291e-01, -4.3967e-02],\n",
       "                       [ 5.0130e-02, -1.0238e-02,  3.5919e-04],\n",
       "                       [-1.0311e-01,  3.4120e-02, -5.2267e-01],\n",
       "                       [-4.0177e-01, -3.5626e-01, -7.6123e-02]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.4293,  0.3475,  0.6165,  0.5517, -0.0502, -0.1368, -0.3422, -0.3117,\n",
       "                        0.6887,  0.0322,  0.0788, -0.0920, -0.4838, -0.4941, -0.4504, -0.0352])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[ 7.9975e-02,  1.2898e-01,  3.4585e-03, -3.0007e-01, -3.9790e-01,\n",
       "                        -3.2375e-01, -4.1411e-02,  2.4902e-01, -2.9231e-01,  1.8948e-01,\n",
       "                         4.6554e-02, -1.6294e-01, -1.4624e-01, -1.8151e-01,  3.7174e-01,\n",
       "                         6.4639e-02],\n",
       "                       [-1.5612e-01,  2.7807e-01,  1.0241e-01,  3.2515e-01,  8.0841e-02,\n",
       "                         2.2779e-01,  1.1978e-01, -4.1126e-01,  2.6119e-01, -2.0166e-01,\n",
       "                        -2.5785e-01,  3.5386e-02, -5.7682e-02,  7.5720e-02, -7.0242e-01,\n",
       "                        -3.6672e-02],\n",
       "                       [ 1.5779e-01,  1.8572e-02, -1.2674e-01, -3.8586e-01, -1.4496e-01,\n",
       "                        -2.8354e-01, -5.4452e-02,  3.6116e-01, -3.4488e-01,  1.4591e-01,\n",
       "                        -5.2619e-02, -1.6637e-01,  1.0690e-01,  9.7024e-02,  5.9517e-01,\n",
       "                         1.3937e-01],\n",
       "                       [ 3.9546e-02, -9.6474e-02,  1.7759e-01,  1.2775e-01,  1.8511e-02,\n",
       "                        -4.0550e-01, -1.1349e-01, -1.0379e-01,  9.8051e-02,  1.2366e-01,\n",
       "                        -2.0211e-01, -2.0520e-01,  1.1562e-01,  1.5065e-01,  4.8043e-01,\n",
       "                        -1.7941e-01],\n",
       "                       [ 1.1492e-01, -2.1500e-01,  1.3359e-01,  5.9451e-02, -2.8281e-01,\n",
       "                        -5.7804e-01, -3.3648e-02,  9.1521e-02,  8.3013e-02,  3.3410e-02,\n",
       "                        -3.4210e-02, -5.4333e-02, -1.4312e-01,  7.6851e-02,  1.0516e-01,\n",
       "                         5.6536e-02],\n",
       "                       [ 1.2479e-01, -1.0393e-01,  1.2087e-01, -8.5438e-02, -3.7575e-01,\n",
       "                        -2.6250e-01,  2.0553e-01,  1.6778e-01, -1.7243e-01,  2.9514e-03,\n",
       "                         2.9216e-01,  2.2948e-01,  3.4106e-02, -1.4670e-01,  4.3145e-02,\n",
       "                         2.3139e-01],\n",
       "                       [ 1.1677e-01, -1.2370e-01, -5.5580e-04, -3.2993e-01,  1.4627e-02,\n",
       "                        -4.2466e-01, -4.4602e-02,  1.2410e-01, -2.3626e-01,  4.5716e-02,\n",
       "                        -1.5946e-01,  1.0500e-01, -2.6014e-01,  1.3559e-01,  4.2736e-01,\n",
       "                        -9.3376e-02],\n",
       "                       [-1.9601e-01, -2.1693e-01,  5.4845e-02, -1.6802e-01, -2.4415e-01,\n",
       "                        -1.7543e-01, -6.4795e-02,  5.2401e-01, -3.9082e-01, -4.3357e-01,\n",
       "                        -2.4659e-01,  5.0765e-02, -1.2970e-01,  1.3243e-02,  3.7770e-01,\n",
       "                        -2.1169e-02],\n",
       "                       [-4.8522e-01,  2.5688e-01, -5.5171e-02,  2.1231e-01,  1.0772e-01,\n",
       "                        -1.4731e-01, -4.2405e-01, -8.4216e-01, -1.1540e-01,  2.1411e-02,\n",
       "                         1.4501e-01, -1.1089e-01, -1.1340e+00, -1.1426e-01,  5.9029e-02,\n",
       "                        -5.8909e-02],\n",
       "                       [ 2.8264e-02,  2.5925e-02, -5.1618e-01, -4.2874e-01,  6.9863e-04,\n",
       "                        -8.3579e-02,  2.6076e-01,  9.8907e-02, -4.0276e-01,  2.5989e-01,\n",
       "                         8.5274e-02,  4.0865e-02,  1.5048e-01, -5.0926e-02,  6.5205e-01,\n",
       "                        -1.8669e-01],\n",
       "                       [ 7.4554e-02,  3.7399e-01,  1.7808e-01, -2.3435e-01, -6.3904e-02,\n",
       "                        -7.6543e-02,  2.7619e-01, -5.2842e-02, -3.8417e-02,  2.4716e-01,\n",
       "                         2.3570e-01,  7.0427e-02,  3.3993e-01, -6.9128e-02,  2.0953e-01,\n",
       "                         6.3703e-02],\n",
       "                       [ 1.5529e-01,  2.6831e-01, -1.2077e-01, -2.1095e-01, -1.7489e-01,\n",
       "                         8.4864e-02,  2.1914e-01,  1.5082e-01, -1.5452e-01,  2.6496e-01,\n",
       "                         3.1012e-01,  1.9399e-01,  2.9827e-01,  2.0164e-01,  1.3600e-01,\n",
       "                         5.0080e-02],\n",
       "                       [ 1.0785e-01,  1.1579e-01,  3.8260e-01,  5.8821e-01,  4.3236e-02,\n",
       "                         6.1527e-02,  2.4728e-01,  1.4107e-01,  4.8571e-01, -3.6968e-02,\n",
       "                         2.2446e-01,  1.2387e-01,  3.3936e-01, -1.8071e-01,  1.7421e-01,\n",
       "                         2.6477e-01],\n",
       "                       [-1.4082e-01,  3.2695e-01, -2.5309e+00, -5.9139e-01, -3.4961e-01,\n",
       "                        -1.4864e+00, -1.9030e+00,  6.6453e-02, -1.0351e+00,  8.2326e-02,\n",
       "                        -2.8339e-01, -9.1644e-01, -1.0757e+00, -1.5786e-01, -1.0203e+00,\n",
       "                        -8.1293e-01],\n",
       "                       [-1.9198e-02,  1.4734e-01,  3.3377e-01,  5.1007e-01, -4.5576e-02,\n",
       "                        -1.3541e-01,  2.2770e-02,  1.6111e-01,  4.9790e-01,  1.1427e-01,\n",
       "                         1.0349e-01,  1.2406e-03,  1.2514e-01,  7.9729e-02, -1.0140e-01,\n",
       "                         7.8960e-02],\n",
       "                       [-2.5837e-01, -1.9156e-01, -1.9013e-01, -1.0247e-01, -2.2243e-01,\n",
       "                         4.2761e-02,  4.6611e-02,  1.9086e-01, -3.2927e-01,  1.3476e-01,\n",
       "                        -3.6775e-01,  1.3712e-01, -2.6889e-01, -7.0913e-02,  1.9290e-01,\n",
       "                        -1.1048e-01]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.0474,  0.0473,  0.0683,  0.0389, -0.0629,  0.1167,  0.0223, -0.0011,\n",
       "                        0.0885, -0.1888,  0.2498,  0.4396, -0.0800,  0.0081, -0.1039, -0.2660])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[ 0.2575,  0.0461,  0.0566, -0.0325,  0.2311,  0.2897,  0.1176, -0.1429,\n",
       "                         0.0626,  0.0896,  0.1994,  0.1218, -0.2212,  0.0140, -0.1078,  0.2502],\n",
       "                       [ 0.0370,  0.0909, -0.0284, -0.0352,  0.2396,  0.1693,  0.1008, -0.0485,\n",
       "                        -0.2746, -0.3480,  0.0143,  0.0717, -0.2435,  0.1269, -0.3896,  0.0591],\n",
       "                       [-0.0836,  0.0307, -0.0346,  0.0578, -0.1925,  0.0542, -0.0778, -0.1901,\n",
       "                        -0.0468,  0.1589, -0.0743, -0.1206,  0.0410,  0.1349, -0.1588,  0.1359],\n",
       "                       [ 0.0920,  0.0491,  0.0230, -0.1967,  0.0178,  0.1084,  0.1338,  0.2296,\n",
       "                         0.0137,  0.0367,  0.1718,  0.4015, -0.0364,  0.2131, -0.2335, -0.1180],\n",
       "                       [-0.1580, -0.0371, -0.1979,  0.1493,  0.1103, -0.1973, -0.0176, -0.2222,\n",
       "                        -0.2438, -0.1057, -0.1791, -0.2005,  0.1534, -0.1186, -0.1392, -0.0138],\n",
       "                       [ 0.0311,  0.1316,  0.1083, -0.0438, -0.0017,  0.1647, -0.0280,  0.0602,\n",
       "                         0.1948, -0.0132,  0.3103,  0.0949, -0.1566,  0.0081, -0.2273, -0.0373],\n",
       "                       [-0.1335, -0.3501,  0.2063,  0.2201, -0.0536,  0.0866,  0.0504, -0.0075,\n",
       "                        -0.0324, -0.0043, -0.0093,  0.2653, -0.3395, -0.0427, -0.2270,  0.0607],\n",
       "                       [-0.1685,  0.3388,  0.0292,  0.0211,  0.2133,  0.0968, -0.1886, -0.0302,\n",
       "                         0.3752,  0.0058,  0.2226,  0.0519, -0.3975,  0.0782, -0.0548,  0.2138],\n",
       "                       [ 0.1689,  0.4071,  0.1642,  0.3184,  0.0251, -0.0572,  0.1420,  0.0834,\n",
       "                         0.1125, -0.1890,  0.3531,  0.3960, -0.3894,  0.0202, -0.1908, -0.1097],\n",
       "                       [-0.0630, -0.0898,  0.0587, -0.3298, -0.0483, -0.3377,  0.0246, -0.1339,\n",
       "                        -0.2196, -0.0349, -0.1016, -0.2639,  0.1094,  0.1237,  0.0300,  0.0603],\n",
       "                       [ 0.1985, -0.5201, -0.2484, -0.1924,  0.0868, -0.0658,  0.0841, -0.0245,\n",
       "                         0.0255, -0.0802,  0.2604, -0.0541, -0.1880, -0.0320, -0.3031, -0.0553],\n",
       "                       [ 0.2394, -0.1358,  0.1094,  0.0791,  0.2887,  0.0045,  0.2167,  0.0779,\n",
       "                        -0.1900,  0.2064,  0.0656,  0.3838, -0.4575, -0.0899,  0.0106,  0.0356],\n",
       "                       [ 0.1803,  0.0019, -0.0050,  0.3455,  0.0583,  0.2809,  0.2651,  0.7160,\n",
       "                         0.2298,  0.4415,  0.0363,  0.0662,  0.0098,  0.0026,  0.3113,  0.1516],\n",
       "                       [-0.0484, -0.0359,  0.1533,  0.1337, -0.1226,  0.1516,  0.0327,  0.0736,\n",
       "                         0.0851,  0.0103, -0.2490, -0.2259, -0.2423, -0.2240, -0.2172,  0.0569],\n",
       "                       [ 0.1388,  0.5164, -0.0623,  0.0222,  0.3187, -0.1153,  0.1704,  0.8208,\n",
       "                        -0.1220,  0.5481,  0.1483, -0.0781,  0.4745, -0.2303,  0.3543,  0.3717],\n",
       "                       [-0.1687,  0.0113, -0.1740,  0.0412,  0.0868, -0.0376,  0.0677, -0.1319,\n",
       "                         0.0294, -0.2105, -0.0383, -0.0090,  0.0747, -0.0302, -0.1715, -0.1821]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.6187, -0.0007, -0.1634,  0.3974, -0.2408,  0.3461,  0.3740,  0.0228,\n",
       "                        0.5091, -0.3250,  0.1839,  0.0498, -0.1855, -0.2106,  0.0610, -0.2477])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[ 0.2329, -0.0807,  0.1449,  0.4124,  0.1236,  0.1945,  0.3778,  0.2059,\n",
       "                         0.4002, -0.0608,  0.1607,  0.3284, -0.3037,  0.1887, -0.3633, -0.0869],\n",
       "                       [-0.0461, -0.1015, -0.1208, -0.0551, -0.2342,  0.1019,  0.1825, -0.0946,\n",
       "                        -0.0496, -0.2464, -0.1568, -0.1473,  0.1084,  0.1925, -0.0088,  0.1984],\n",
       "                       [-0.1154, -0.0333, -0.1165,  0.1803,  0.0814, -0.1955, -0.0976,  0.0941,\n",
       "                         0.0729,  0.2245, -0.1695, -0.1165,  0.0453,  0.2041, -0.0970,  0.2137],\n",
       "                       [-0.0796, -0.2187,  0.0642, -0.0971, -0.1448, -0.0790,  0.2121, -0.0481,\n",
       "                         0.1392,  0.2565, -0.0343,  0.1605, -0.4735, -0.0474, -0.2702,  0.0493],\n",
       "                       [ 0.0554,  0.2101, -0.1358, -0.2304,  0.0574,  0.0948, -0.0245,  0.1971,\n",
       "                        -0.2235, -0.1034, -0.0897, -0.1237,  0.0799, -0.2468,  0.2924,  0.0765],\n",
       "                       [ 0.0780, -0.1795,  0.2057, -0.0901,  0.1970,  0.0513, -0.2188,  0.0027,\n",
       "                        -0.0671,  0.0592,  0.1813,  0.0550, -0.1060, -0.0009, -0.0994, -0.0744],\n",
       "                       [-0.1140,  0.1749,  0.0612,  0.1157,  0.1114, -0.1364,  0.0080, -0.1088,\n",
       "                        -0.0311, -0.2568, -0.0912,  0.0289, -0.1878,  0.0538, -0.2213, -0.1164],\n",
       "                       [ 0.1480,  0.1743,  0.1642,  0.2186,  0.1545,  0.1981,  0.3258, -0.0466,\n",
       "                         0.3231,  0.2404,  0.2346,  0.1539, -0.3021, -0.1293, -0.4687,  0.1049],\n",
       "                       [-0.1157,  0.1920,  0.0749, -0.0458, -0.1695, -0.1453,  0.2612,  0.1774,\n",
       "                        -0.0571, -0.0680,  0.0536, -0.0752, -0.0143,  0.0774,  0.4023,  0.2175],\n",
       "                       [-0.4761, -0.1674, -0.0180, -0.5369,  0.2081, -0.5538,  0.0967, -0.2198,\n",
       "                        -0.1353,  0.1203, -0.1366, -0.1661,  0.0793,  0.1617,  0.0934, -0.1779],\n",
       "                       [ 0.3896,  0.2323, -0.2291,  0.3522,  0.1818,  0.3474,  0.0339, -0.1261,\n",
       "                         0.2118,  0.1875, -0.1169, -0.1519,  0.1531,  0.0143, -0.2781, -0.2465],\n",
       "                       [ 0.2866,  0.1767, -0.2149, -0.0498,  0.0777,  0.0418,  0.2386,  0.1811,\n",
       "                         0.3714, -0.1127,  0.0450,  0.1207, -0.3196, -0.1932, -0.0384,  0.1449],\n",
       "                       [-0.1038,  0.1382, -0.2009, -0.0742, -0.2061,  0.0671,  0.0264,  0.0624,\n",
       "                        -0.1995,  0.0345, -0.2284, -0.2988,  0.1144, -0.2009,  0.1452, -0.1628],\n",
       "                       [-0.2947, -0.2016, -0.0390,  0.0070, -0.1183,  0.0436, -0.3682, -0.2608,\n",
       "                        -0.3653, -0.2156,  0.0020,  0.1488, -0.1049,  0.0858,  0.1813, -0.2065],\n",
       "                       [ 0.1346, -0.0886,  0.1959,  0.0088, -0.0206,  0.2494, -0.1800,  0.1905,\n",
       "                        -0.1122, -0.0492, -0.1505, -0.1000, -0.1819, -0.0870, -0.1992, -0.2453],\n",
       "                       [-0.0198, -0.1287, -0.0462, -0.1081,  0.1295, -0.0098, -0.0314, -0.1228,\n",
       "                        -0.0338, -0.0030,  0.0160, -0.2345,  0.2450,  0.0401,  0.3164, -0.0431]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.4194, -0.2426, -0.1239, -0.1031,  0.2455, -0.0871, -0.1181,  0.4201,\n",
       "                        0.2076,  0.1863,  0.6024,  0.2813,  0.2013,  0.3453, -0.1661,  0.0926])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[ 0.3601,  0.0027, -0.1451,  0.1508, -0.1828,  0.0480, -0.1376,  0.1828,\n",
       "                        -0.2385, -0.2086,  0.2102,  0.2810, -0.1232, -0.2326, -0.0208, -0.1650]])),\n",
       "              ('layers.8.bias', tensor([-0.0207]))]),\n",
       " 'LQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[-0.8379, -0.0813, -0.0068],\n",
       "                       [-0.0762,  0.1732, -0.0359],\n",
       "                       [ 0.0272, -0.4614,  0.1328],\n",
       "                       [ 0.0941, -0.1587,  0.0116],\n",
       "                       [-0.4391, -0.1664,  0.0040],\n",
       "                       [ 0.1014,  0.1603,  0.0279],\n",
       "                       [-0.1727,  0.2669,  0.1062],\n",
       "                       [ 0.2665,  0.1593,  0.0706],\n",
       "                       [ 0.3244, -0.0990, -0.0127],\n",
       "                       [ 0.5900, -0.1807, -0.0413],\n",
       "                       [ 0.1058, -0.0302, -0.0222],\n",
       "                       [ 0.6054,  0.0948, -0.0122],\n",
       "                       [ 0.1870, -0.2761, -0.1649],\n",
       "                       [ 0.0434,  0.0197, -0.1617],\n",
       "                       [-0.1905, -0.0842,  0.1375],\n",
       "                       [-0.2458, -0.1104, -0.0623]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.7809,  0.3043, -0.5627,  0.0968,  0.1472, -0.2701,  0.4523,  0.1257,\n",
       "                        0.6177, -0.5807, -0.0570, -0.0051, -0.6352, -0.0818,  0.0608,  0.1700])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[-0.0972, -0.1399,  0.3068,  0.0083,  0.1477,  0.1453, -0.0152,  0.0230,\n",
       "                         0.1315, -0.1747,  0.1318, -0.1625,  0.0110,  0.0488, -0.1302, -0.1737],\n",
       "                       [ 0.4043,  0.1944,  0.0176,  0.1894,  0.2551,  0.2561,  0.2734,  0.0528,\n",
       "                         0.0884, -0.6233,  0.0397, -0.2102, -0.2010,  0.1141,  0.1358,  0.2278],\n",
       "                       [-0.0859,  0.0246,  0.0654,  0.0813, -0.2419, -0.0598, -0.1579, -0.0388,\n",
       "                         0.2706, -0.2666, -0.0921, -0.1073,  0.2368, -0.2855, -0.0623, -0.0574],\n",
       "                       [-0.0207,  0.1005,  0.1002,  0.3212, -0.0393,  0.2037, -0.0041,  0.1548,\n",
       "                         0.2482,  0.1217,  0.2470,  0.3567,  0.2748,  0.0420, -0.0483,  0.0426],\n",
       "                       [ 0.0643, -0.1104, -0.0383, -0.1547, -0.0072,  0.1589,  0.0009, -0.0872,\n",
       "                         0.0998,  0.0193,  0.0756, -0.2301, -0.0900, -0.2736, -0.2728,  0.0391],\n",
       "                       [-0.1857, -0.1240,  0.0407, -0.0195, -0.3599, -0.1306,  0.1434, -0.0185,\n",
       "                         0.3887, -0.3669,  0.1442, -0.0603, -0.1143,  0.0861,  0.0527, -0.0299],\n",
       "                       [ 0.3611, -0.1312, -0.0402,  0.2288,  0.2641, -0.1529,  0.1380, -0.2813,\n",
       "                        -0.0125, -0.2788,  0.1126, -0.5922, -0.1231, -0.1699, -0.0236,  0.1819],\n",
       "                       [-0.3587,  0.2503, -0.0250,  0.2294,  0.0291, -0.1112,  0.0411,  0.0697,\n",
       "                         0.2729, -0.3405,  0.0881, -0.0115, -0.0924,  0.0909,  0.1416,  0.2249],\n",
       "                       [-0.0431,  0.1097, -0.0837, -0.0309, -0.1086, -0.0080, -0.1805, -0.1665,\n",
       "                        -0.0981,  0.0119, -0.0424, -0.0884,  0.0470, -0.0767,  0.1575, -0.1582],\n",
       "                       [ 0.2078,  0.2301, -0.3042, -0.1739, -0.2387,  0.1319, -0.0467,  0.0510,\n",
       "                         0.4250, -0.2837, -0.0597, -0.1872, -0.1191, -0.0188,  0.1899, -0.0567],\n",
       "                       [ 0.0432, -0.3460, -0.0215, -0.2171, -0.1596, -0.0463,  0.0912, -0.3114,\n",
       "                        -0.0787, -0.0280, -0.0699, -0.2434,  0.1227, -0.0847, -0.0545, -0.2246],\n",
       "                       [-0.0545,  0.1143, -0.1871, -0.0876,  0.2792, -0.2565, -0.0506, -0.0120,\n",
       "                         0.0242,  0.0452,  0.0296, -0.2896, -0.1028, -0.1870,  0.2922,  0.2270],\n",
       "                       [-0.0900, -0.1063,  0.0891,  0.1003, -0.0127, -0.0849, -0.2404, -0.2378,\n",
       "                         0.4533, -0.3617, -0.1272,  0.0727, -0.0520, -0.0267, -0.3679, -0.2173],\n",
       "                       [-0.3902, -0.0090, -0.0735,  0.1056, -0.2619,  0.1452,  0.0459,  0.1285,\n",
       "                         0.4921,  0.2308,  0.0028,  0.0462, -0.0010,  0.0293, -0.0445,  0.0470],\n",
       "                       [ 0.2967,  0.3222,  0.2004,  0.0139, -0.0889, -0.0553,  0.1792,  0.3647,\n",
       "                        -0.1220, -0.2313, -0.1149, -0.2912,  0.1377,  0.2163, -0.0386,  0.1478],\n",
       "                       [ 0.4365, -0.1894,  0.2908,  0.2463,  0.0947,  0.2290, -0.2152,  0.2218,\n",
       "                        -0.0617,  0.3414,  0.2865, -0.0179,  0.0360,  0.2449, -0.1770,  0.0650]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.4282,  0.0485,  0.0591, -0.0540, -0.0610,  0.1815,  0.1875,  0.2578,\n",
       "                        0.0198,  0.0878,  0.1133,  0.0756,  0.2658,  0.3499,  0.0211, -0.3042])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[ 6.7426e-02,  2.2730e-01,  2.1769e-02, -1.5629e-01, -1.4137e-01,\n",
       "                         2.9199e-01,  2.1049e-02, -7.8967e-02, -1.7419e-01,  1.0008e-01,\n",
       "                         1.4448e-01, -1.2013e-01,  1.4587e-01, -8.6947e-02,  2.4795e-01,\n",
       "                         5.9868e-03],\n",
       "                       [ 4.4124e-02,  1.7228e-01,  1.1998e-01, -3.5978e-01, -1.3825e-01,\n",
       "                         2.1826e-01,  5.6262e-02,  6.8177e-02,  2.2673e-01,  6.0633e-02,\n",
       "                         5.8477e-03, -7.9016e-03,  1.5460e-01, -3.1561e-02, -1.2946e-01,\n",
       "                        -3.9896e-01],\n",
       "                       [ 6.1846e-03,  1.0813e-01, -1.5706e-01, -3.1177e-01, -2.5708e-01,\n",
       "                         1.5688e-01,  8.8655e-02, -1.0954e-02,  7.1331e-02, -3.1368e-01,\n",
       "                        -8.8516e-02, -3.5571e-01, -1.0837e-03, -2.5853e-02, -3.7162e-02,\n",
       "                        -5.2822e-02],\n",
       "                       [ 2.5316e-01, -2.4088e-01, -4.7865e-02,  2.5885e-01,  2.0721e-01,\n",
       "                         2.2846e-01, -2.4126e-03,  8.1050e-02,  3.5977e-02,  1.1582e-01,\n",
       "                        -1.0654e-01,  1.6998e-01,  1.4000e-01,  3.2999e-01,  9.6361e-02,\n",
       "                        -9.2475e-02],\n",
       "                       [ 3.0720e-01,  3.6292e-01, -1.7574e-01, -1.0674e-01,  1.1304e-01,\n",
       "                        -1.0293e-02,  1.0246e-01, -1.1600e-01, -1.0385e-01,  2.5840e-01,\n",
       "                         1.3784e-01,  4.0839e-02,  2.5826e-01, -4.5950e-01,  2.5010e-01,\n",
       "                        -1.1911e-02],\n",
       "                       [ 1.2310e-01, -2.2694e-01, -1.8617e-01, -2.1828e-01,  2.4523e-01,\n",
       "                        -3.9395e-02, -1.0431e-01,  1.5138e-01, -2.4730e-01, -8.3302e-02,\n",
       "                         3.0254e-01,  1.3438e-01,  7.0366e-02,  2.8031e-01, -1.1747e-01,\n",
       "                        -1.0532e-01],\n",
       "                       [ 5.9733e-02, -1.1400e-01, -7.8511e-02,  5.1109e-02,  1.6218e-01,\n",
       "                         2.2357e-02, -1.2389e-01, -4.7083e-02,  5.0398e-02,  2.3291e-02,\n",
       "                         9.2566e-02, -2.2877e-01, -1.0822e-01, -1.8845e-01,  7.6257e-02,\n",
       "                        -8.4977e-02],\n",
       "                       [-3.2852e-03, -1.0351e-01, -2.5657e-01, -5.7467e-02, -2.2384e-01,\n",
       "                         1.5074e-01, -2.2114e-02, -2.3256e-01,  1.3061e-01,  2.5097e-02,\n",
       "                         3.8375e-02, -7.7246e-02, -2.0948e-01,  1.4847e-01,  2.1722e-02,\n",
       "                        -1.4476e-01],\n",
       "                       [-7.1867e-02,  3.5105e-01,  2.4996e-01, -3.3331e-01, -3.3830e-02,\n",
       "                         1.7999e-01,  3.1115e-01, -2.9716e-01, -2.1786e-01,  8.2995e-03,\n",
       "                         1.9189e-01,  1.9158e-01,  1.5564e-01, -9.3072e-02,  3.4830e-01,\n",
       "                         5.2711e-02],\n",
       "                       [ 2.4092e-01, -3.7199e-01,  4.8594e-03,  5.2898e-02, -2.9151e-02,\n",
       "                         1.3801e-02,  4.2546e-04,  4.7370e-01,  1.5934e-01,  1.7385e-01,\n",
       "                        -8.0020e-02,  2.8184e-02,  2.4273e-01,  3.8721e-01, -1.3291e-01,\n",
       "                        -4.1827e-01],\n",
       "                       [-2.9206e-04,  3.0011e-01,  1.7755e-01, -6.3157e-02, -1.2959e-01,\n",
       "                        -1.5875e-01,  2.3218e-01, -1.3333e-01,  1.3139e-01, -1.2436e-01,\n",
       "                        -5.8246e-02, -1.6136e-01, -1.5227e-01,  3.6556e-03,  1.8158e-01,\n",
       "                         4.6531e-03],\n",
       "                       [ 2.5759e-01,  7.8737e-02, -1.6192e-02,  1.6262e-01,  1.0174e-02,\n",
       "                         3.1495e-01, -1.0443e-01,  1.9627e-01, -2.4029e-01, -8.1564e-03,\n",
       "                        -1.9646e-02, -4.7906e-02,  1.2317e-01,  6.7544e-02, -2.0995e-01,\n",
       "                         1.7816e-02],\n",
       "                       [ 2.2907e-01, -1.2400e-01,  2.6012e-01,  2.5786e-02,  1.3996e-01,\n",
       "                        -2.5982e-01,  5.1882e-02, -3.1938e-01,  1.9269e-01, -1.7180e-01,\n",
       "                         1.6087e-01, -1.5778e-01,  5.8549e-03, -9.0443e-02,  1.4972e-02,\n",
       "                         1.2889e-02],\n",
       "                       [-2.4832e-02, -1.5269e-01,  1.4904e-03, -8.9195e-02,  2.6822e-01,\n",
       "                         1.9701e-01, -5.9971e-02,  1.6480e-01,  1.2298e-01, -2.0294e-01,\n",
       "                        -1.5232e-01, -4.7940e-01,  3.6660e-01, -2.7177e-02,  5.7995e-02,\n",
       "                        -2.5894e-01],\n",
       "                       [ 2.3082e-02,  1.7901e-01,  3.1423e-01,  1.6247e-01, -1.5425e-01,\n",
       "                         1.5347e-01, -2.5403e-01,  2.9318e-02, -1.9354e-02,  1.7997e-02,\n",
       "                         1.7941e-01, -1.3381e-01,  1.4354e-01,  4.7709e-01, -1.7371e-01,\n",
       "                         5.0117e-02],\n",
       "                       [ 2.1981e-01,  2.7303e-01,  3.1758e-01, -7.0462e-02,  1.9762e-01,\n",
       "                         1.9546e-01,  1.3798e-01, -2.6065e-01,  2.2579e-01,  2.1311e-01,\n",
       "                        -1.2538e-01,  2.0914e-01,  1.3519e-01, -1.8127e-01,  2.0627e-01,\n",
       "                         2.8877e-01]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.0338,  0.0089, -0.0050,  0.1703,  0.3423,  0.4477, -0.1999, -0.1949,\n",
       "                        0.3062,  0.4272,  0.2006,  0.0788,  0.0906,  0.3608,  0.1543, -0.0357])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[-0.1044, -0.0472, -0.2734,  0.1012, -0.2346,  0.3828,  0.2098,  0.0455,\n",
       "                        -0.0352,  0.3040, -0.2071, -0.0189, -0.2834,  0.1011,  0.4306, -0.1212],\n",
       "                       [-0.1621,  0.0311,  0.0456, -0.2364,  0.0711, -0.2133,  0.0304, -0.1177,\n",
       "                        -0.1531,  0.2479, -0.0011, -0.3131, -0.2060, -0.1887, -0.0859, -0.2179],\n",
       "                       [ 0.1185, -0.1697, -0.1016,  0.0543,  0.0390, -0.1461, -0.1055, -0.1740,\n",
       "                         0.0342, -0.1630, -0.1251,  0.0339, -0.0037, -0.0429,  0.1056,  0.1730],\n",
       "                       [-0.2566, -0.0977, -0.1456,  0.0376, -0.1462, -0.1647,  0.2125, -0.0648,\n",
       "                        -0.0629, -0.2184,  0.0105,  0.0276,  0.1099, -0.1110, -0.1198, -0.0964],\n",
       "                       [-0.1493,  0.2183,  0.0988, -0.0260, -0.0220, -0.1132,  0.2728,  0.1467,\n",
       "                         0.0101,  0.0760,  0.2634, -0.0961,  0.2322,  0.0512, -0.3068,  0.2868],\n",
       "                       [ 0.1073, -0.2485,  0.1460, -0.1004, -0.2532, -0.2337,  0.0363,  0.1640,\n",
       "                         0.0192,  0.0738,  0.0361,  0.1352, -0.0443, -0.2547, -0.0077, -0.1201],\n",
       "                       [ 0.2068,  0.2613, -0.0111, -0.2149,  0.3730,  0.2831, -0.0900, -0.0861,\n",
       "                         0.3353,  0.0231,  0.0101,  0.1404,  0.0400,  0.1956, -0.3215,  0.2929],\n",
       "                       [ 0.1327, -0.0009, -0.1206,  0.2240,  0.1565,  0.1384,  0.2337, -0.1595,\n",
       "                         0.0503, -0.3780, -0.0310,  0.0453,  0.0021,  0.2687, -0.3241,  0.2592],\n",
       "                       [-0.2595, -0.2345, -0.2119, -0.1430,  0.1740,  0.0924,  0.1845, -0.0772,\n",
       "                        -0.2479,  0.1246, -0.0526, -0.2218,  0.0919,  0.1580,  0.0492, -0.1567],\n",
       "                       [-0.1090,  0.1359,  0.1063,  0.1879, -0.0418,  0.4541,  0.0120,  0.1218,\n",
       "                         0.0022,  0.1791, -0.1088,  0.0862,  0.0547,  0.0952,  0.1448,  0.1458],\n",
       "                       [ 0.0122,  0.0799, -0.1873,  0.2638, -0.1428,  0.1281,  0.0258,  0.1089,\n",
       "                        -0.1231,  0.4168, -0.1077,  0.3063, -0.0719,  0.2745,  0.0969,  0.1991],\n",
       "                       [-0.1843, -0.3424, -0.0228, -0.0292, -0.2795, -0.1193, -0.2165, -0.1751,\n",
       "                        -0.4515,  0.3592, -0.3771,  0.1328,  0.0965,  0.0197,  0.2545, -0.4025],\n",
       "                       [-0.0397, -0.1163,  0.0958, -0.0807,  0.3517, -0.0233,  0.0502,  0.1474,\n",
       "                         0.2717, -0.2230,  0.2841,  0.2470,  0.2230,  0.1386, -0.1499,  0.2056],\n",
       "                       [-0.0127, -0.3317, -0.1868, -0.0318,  0.0221, -0.1825,  0.0369,  0.1467,\n",
       "                         0.0814,  0.1595, -0.0566, -0.0175,  0.1040,  0.0396, -0.0508, -0.1053],\n",
       "                       [ 0.1117, -0.1322,  0.1237, -0.1301, -0.2654, -0.3157,  0.1578, -0.2052,\n",
       "                         0.0900,  0.0070,  0.1153, -0.1973, -0.0102,  0.1568,  0.1673,  0.1288],\n",
       "                       [-0.0854, -0.0991,  0.1666, -0.1298,  0.1428, -0.0138, -0.2697, -0.2065,\n",
       "                         0.0362,  0.4363, -0.0030,  0.1145,  0.1693,  0.2147,  0.3368, -0.0606]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.2226,  0.1036,  0.0419,  0.0322,  0.2758, -0.3762,  0.1510,  0.2548,\n",
       "                       -0.2231,  0.2984,  0.4867,  0.2603,  0.2806, -0.0728, -0.1869, -0.1542])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[ 0.3079,  0.0241, -0.0627, -0.0159, -0.0847, -0.0525, -0.2834, -0.1751,\n",
       "                        -0.1527,  0.2133,  0.4154,  0.1750, -0.2546,  0.0856,  0.0813,  0.0530]])),\n",
       "              ('layers.8.bias', tensor([-0.2806]))])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define quantiles and hyperparameters\n",
    "q_median = 0.5\n",
    "q_upper = 0.975\n",
    "q_lower = 0.025\n",
    "dims = model['dims']\n",
    "lr = model['lr']\n",
    "batch_size = int(model['batch_size'])\n",
    "epoch = model['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch size: 500\n",
      "epoch: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"lr:\", lr)\n",
    "print(\"batch size:\", batch_size)\n",
    "print(\"epoch:\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done B_WTG01\n",
      "Done B_WTG02\n",
      "Done B_WTG03\n",
      "Done B_WTG04\n",
      "Done B_WTG05\n",
      "Done B_WTG06\n",
      "Done B_WTG07\n",
      "Done B_WTG08\n",
      "Done B_WTG09\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################################### training ######################################################### \n",
    "\n",
    "turbines = data_finetune.instanceID.unique()\n",
    "median_state_dict_all = []\n",
    "UQ_state_dict_all = []\n",
    "LQ_state_dict_all = []\n",
    "\n",
    "\n",
    "for ID in turbines:\n",
    "    \n",
    "    # select data based on turbine ID\n",
    "    data_temp = data_finetune[data_finetune['instanceID'] == ID]\n",
    "\n",
    "    # normalize data\n",
    "    X = scaler1.transform(data_temp.iloc[:, 5:-1])\n",
    "    y = scaler2.transform(data_temp.iloc[:, -1:])\n",
    "    \n",
    "    # create network and load pretrain weights\n",
    "    net_median_temp = Net(dims = dims)\n",
    "    net_median_temp.load_state_dict(pretrain['median'])\n",
    "    \n",
    "    net_upper_temp = Net(dims = dims)\n",
    "    net_upper_temp.load_state_dict(pretrain['UQ'])\n",
    "    \n",
    "    net_lower_temp = Net(dims = dims)\n",
    "    net_lower_temp.load_state_dict(pretrain['LQ'])\n",
    "    \n",
    "    # train\n",
    "    net_median_temp, median_state_dict = train(X=X, y=y, quantile=q_median, net=net_median_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_upper_temp, UQ_state_dict = train(X=X, y=y, quantile=q_upper, net=net_upper_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_lower_temp, LQ_state_dict = train(X=X, y=y, quantile=q_lower, net=net_lower_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    \n",
    "    median_state_dict_all.append(median_state_dict)\n",
    "    UQ_state_dict_all.append(UQ_state_dict)\n",
    "    LQ_state_dict_all.append(LQ_state_dict)\n",
    "    \n",
    "    print('Done', ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_state_dict_all_zip = dict(zip(turbines, median_state_dict_all))\n",
    "UQ_state_dict_all_zip = dict(zip(turbines, UQ_state_dict_all))\n",
    "LQ_state_dict_all_zip = dict(zip(turbines, LQ_state_dict_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save trained network\n",
    "\n",
    "torch.save(median_state_dict_all_zip, sys.path[0] + '/median.pth')\n",
    "torch.save(UQ_state_dict_all_zip, sys.path[0] + '/UQ.pth')\n",
    "torch.save(LQ_state_dict_all_zip, sys.path[0] + '/LQ.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
