{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from typing import Iterable\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from joblib import dump, load\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data_finetune = pd.read_csv(\"data_finetune.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>instanceID</th>\n",
       "      <th>Wind_speed</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958671</th>\n",
       "      <td>2020-11-13 00:30:00</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>6.343173</td>\n",
       "      <td>9.355000</td>\n",
       "      <td>496.738776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682500</th>\n",
       "      <td>2020-08-13 16:40:00</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>3.461359</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>42.106780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827043</th>\n",
       "      <td>2020-09-30 11:50:00</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>3.595130</td>\n",
       "      <td>10.966667</td>\n",
       "      <td>58.858180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278880</th>\n",
       "      <td>2020-04-02 05:20:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>16.338689</td>\n",
       "      <td>6.796667</td>\n",
       "      <td>2043.203491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794451</th>\n",
       "      <td>2020-09-19 17:10:00</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>6.913757</td>\n",
       "      <td>16.663334</td>\n",
       "      <td>614.239596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580775</th>\n",
       "      <td>2020-07-11 01:10:00</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.650944</td>\n",
       "      <td>10.298334</td>\n",
       "      <td>830.078456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122912</th>\n",
       "      <td>2020-02-10 15:20:00</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.982645</td>\n",
       "      <td>2.593333</td>\n",
       "      <td>825.983393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11129</th>\n",
       "      <td>2020-01-04 16:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.100355</td>\n",
       "      <td>7.396552</td>\n",
       "      <td>653.990937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855014</th>\n",
       "      <td>2020-10-09 17:40:00</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>4.106625</td>\n",
       "      <td>7.183333</td>\n",
       "      <td>166.245071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564836</th>\n",
       "      <td>2020-07-05 18:40:00</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>9.763854</td>\n",
       "      <td>10.733333</td>\n",
       "      <td>1889.555786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ts  Month  Day  Hour instanceID  Wind_speed  \\\n",
       "958671  2020-11-13 00:30:00     11   13     0    C_WTG01    6.343173   \n",
       "682500  2020-08-13 16:40:00      8   13    16    C_WTG01    3.461359   \n",
       "827043  2020-09-30 11:50:00      9   30    11    C_WTG01    3.595130   \n",
       "278880  2020-04-02 05:20:00      4    2     5    C_WTG01   16.338689   \n",
       "794451  2020-09-19 17:10:00      9   19    17    C_WTG01    6.913757   \n",
       "...                     ...    ...  ...   ...        ...         ...   \n",
       "580775  2020-07-11 01:10:00      7   11     1    C_WTG21    6.650944   \n",
       "122912  2020-02-10 15:20:00      2   10    15    C_WTG21    6.982645   \n",
       "11129   2020-01-04 16:10:00      1    4    16    C_WTG21    6.100355   \n",
       "855014  2020-10-09 17:40:00     10    9    17    C_WTG21    4.106625   \n",
       "564836  2020-07-05 18:40:00      7    5    18    C_WTG21    9.763854   \n",
       "\n",
       "        Temperature        Power  \n",
       "958671     9.355000   496.738776  \n",
       "682500    23.900000    42.106780  \n",
       "827043    10.966667    58.858180  \n",
       "278880     6.796667  2043.203491  \n",
       "794451    16.663334   614.239596  \n",
       "...             ...          ...  \n",
       "580775    10.298334   830.078456  \n",
       "122912     2.593333   825.983393  \n",
       "11129      7.396552   653.990937  \n",
       "855014     7.183333   166.245071  \n",
       "564836    10.733333  1889.555786  \n",
       "\n",
       "[210000 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load normalization function \n",
    "scaler1 = load('scaler1.bin')\n",
    "scaler2 = load('scaler2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_count = data_finetune['instanceID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dims: Iterable[int], output_activation: nn.Module = None):\n",
    "        \"\"\"Creates a network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = dims[0]\n",
    "        self.out_size = dims[-1]\n",
    "        self.layers = self.make_seq(dims, output_activation)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_seq(dims: Iterable[int], output_activation: nn.Module) -> nn.Module:\n",
    "        \"\"\"Creates a sequential network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        :return (nn.Module): return created sequential layers\n",
    "        \"\"\"\n",
    "        mods = []\n",
    "\n",
    "        for i in range(len(dims) - 2):\n",
    "            mods.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            mods.append(nn.ReLU())\n",
    "\n",
    "        mods.append(nn.Linear(dims[-2], dims[-1]))\n",
    "        if output_activation:\n",
    "            mods.append(output_activation())\n",
    "        return nn.Sequential(*mods)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Computes a forward pass through the network\n",
    "\n",
    "        :param x (torch.Tensor): input tensor to feed into the network\n",
    "        :return (torch.Tensor): output computed by the network\n",
    "        \"\"\"\n",
    "        # Feedforward\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, quantile, net, lr, batch_size, epoch):    \n",
    "    \n",
    "    # create tensor dataset\n",
    "    train = TensorDataset(Tensor(X), Tensor(y))\n",
    "\n",
    "    # create data loader from dataset\n",
    "    trainset = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr = lr)\n",
    "        \n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for ep in range(epoch):\n",
    "\n",
    "        for t in trainset:\n",
    "            X_temp, y_temp = t\n",
    "            output = net(X_temp)\n",
    "            residual = y_temp - output\n",
    "            loss = Tensor.max(quantile*residual, (quantile-1)*residual).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return net, net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use a very low learning rate at this stage, because we are training on a dataset that is very small. This is to prevent the risk of overfitting very quickly if we apply large weight updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hyperparameters\n",
    "model = torch.load( sys.path[0] + '/hparams_finetune.pth')\n",
    "\n",
    "# load the pretrained weights\n",
    "pretrain = torch.load( sys.path[0] + '/pretrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median': OrderedDict([('layers.0.weight',\n",
       "               tensor([[ 0.6106,  0.0762],\n",
       "                       [-0.6366,  0.1307],\n",
       "                       [-0.4563, -0.4057],\n",
       "                       [-0.3796,  0.0350],\n",
       "                       [-0.1742, -0.3416],\n",
       "                       [-0.0939,  0.0997],\n",
       "                       [ 0.3924,  0.0652],\n",
       "                       [-0.8840,  0.3396],\n",
       "                       [ 0.0718, -0.3383],\n",
       "                       [ 0.0707, -0.3138],\n",
       "                       [-0.5365,  0.2656],\n",
       "                       [-0.2757, -0.0786],\n",
       "                       [-0.1289, -0.0610],\n",
       "                       [ 0.4826, -0.1186],\n",
       "                       [ 0.6405, -0.2557],\n",
       "                       [ 0.4083,  0.3597]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.6671,  0.2189,  0.2621,  0.4966, -0.5246,  0.5422,  0.1403, -0.1392,\n",
       "                       -0.3579, -0.2003,  0.5679,  0.2289, -0.5770, -0.2383,  0.0978, -0.2161])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[-4.9831e-02, -2.5418e-01, -3.4251e-01, -2.4918e-01,  1.7800e-01,\n",
       "                        -1.6836e-01, -1.3421e-01, -2.2057e-01,  4.2617e-01,  7.9735e-02,\n",
       "                        -8.9806e-02, -3.9974e-01,  9.8292e-02,  3.3392e-01,  2.4130e-01,\n",
       "                         1.9865e-01],\n",
       "                       [-3.2907e-02, -1.8243e-01, -4.4557e-01, -3.7170e-01, -1.4654e-01,\n",
       "                        -6.0693e-01,  2.7223e-01, -5.9381e-02,  3.0214e-02, -3.4436e-02,\n",
       "                        -1.5534e-01,  2.2356e-01, -1.4402e-01,  2.7108e-01,  2.8247e-01,\n",
       "                         4.4200e-01],\n",
       "                       [ 6.4246e-02, -4.6646e-03, -4.0435e-02,  3.6007e-02, -4.6931e-01,\n",
       "                         7.5186e-02,  3.7337e-02, -4.1775e-01, -5.5726e-01, -2.0857e-01,\n",
       "                         3.3132e-04,  1.1053e-01, -1.1490e-01, -2.9598e-01, -2.9221e-01,\n",
       "                        -5.3132e-01],\n",
       "                       [ 3.8807e-01, -1.9955e-01,  3.3253e-02,  6.7373e-02, -1.9513e-02,\n",
       "                         1.9521e-01,  4.0928e-01,  6.8086e-02,  1.4360e-01,  1.6778e-01,\n",
       "                        -1.4106e-01, -4.1155e-02,  2.6804e-02,  1.2962e-01, -5.5797e-02,\n",
       "                         2.6595e-01],\n",
       "                       [-1.8099e-01,  3.9280e-01,  2.7928e-01,  5.4158e-01,  2.5370e-01,\n",
       "                         8.9115e-02,  2.1726e-01,  1.8109e-01,  2.6469e-01,  5.1242e-02,\n",
       "                         2.7273e-01, -6.0166e-02, -2.4545e-02,  3.2305e-01, -1.6060e-02,\n",
       "                        -6.3135e-02],\n",
       "                       [-1.6218e-01, -9.1211e-02,  1.8652e-02,  1.7737e-01, -3.9505e-01,\n",
       "                         3.3264e-01,  1.2099e-01, -2.8738e-02, -3.5445e-01,  1.3432e-03,\n",
       "                        -1.0046e-01, -7.4588e-02, -2.4337e-02, -2.6161e-02, -1.1596e-01,\n",
       "                        -7.4147e-01],\n",
       "                       [-2.7166e-01, -2.2806e-01, -9.1034e-03, -2.6835e-01,  3.0163e-02,\n",
       "                        -9.8662e-02,  2.7245e-01,  9.8148e-02,  1.6644e-02,  9.2686e-03,\n",
       "                         6.9961e-02,  2.1244e-02,  8.1585e-02,  4.7205e-02, -1.8262e-01,\n",
       "                         4.1842e-02],\n",
       "                       [ 1.1804e-01, -1.6784e-01, -1.8884e-01, -7.3969e-02, -1.1707e-01,\n",
       "                        -1.2950e-01,  1.4379e-01, -2.6997e-01, -2.5957e-03, -1.6335e-01,\n",
       "                         4.2690e-02, -2.9608e-01, -1.0698e-01,  8.4845e-02, -1.1488e-01,\n",
       "                        -2.8228e-02],\n",
       "                       [-1.6828e-01,  2.1482e-02,  1.2988e-01, -5.5941e-02, -1.3889e-01,\n",
       "                         1.9242e-01, -1.6180e-01, -6.4276e-02,  1.8876e-01,  1.4226e-01,\n",
       "                         1.6738e-01,  2.2453e-02,  7.8884e-02, -6.2584e-02, -2.0656e-01,\n",
       "                         7.0183e-02],\n",
       "                       [ 3.3989e-01, -3.1511e-01,  1.4958e-01, -2.7240e-01,  2.1209e-01,\n",
       "                         5.4147e-02,  9.9583e-02,  1.3498e-05, -1.7056e-02, -2.0747e-01,\n",
       "                         3.5430e-03, -1.4860e-01, -1.9149e-01,  1.6014e-01,  3.0901e-01,\n",
       "                        -9.1460e-02],\n",
       "                       [-1.5250e-01,  7.7096e-02,  1.8910e-01,  1.9899e-01, -2.9761e-02,\n",
       "                        -1.1886e-01, -4.7228e-02,  2.2388e-01,  4.5368e-01,  2.1723e-01,\n",
       "                        -1.3290e-01, -4.0947e-02,  1.9139e-01, -3.3388e-01, -3.1511e-01,\n",
       "                        -2.4934e-01],\n",
       "                       [ 1.2613e-02, -1.3190e-01,  4.3120e-02,  1.8070e-01, -1.3689e-01,\n",
       "                         1.0423e-01,  6.6096e-02, -1.2179e-01, -4.4565e-02, -3.0662e-02,\n",
       "                        -1.7088e-01, -1.5717e-01,  9.4846e-02,  2.0979e-02, -1.6039e-01,\n",
       "                        -2.1670e-01],\n",
       "                       [ 4.2326e-02, -3.3866e-01, -2.0870e-02, -4.3928e-01, -5.9753e-01,\n",
       "                         6.9337e-02,  2.0157e-01,  1.3305e-03, -1.0596e-01,  1.1565e-01,\n",
       "                        -5.7203e-03, -4.2123e-02, -1.1345e-02,  1.4995e-01,  2.8846e-01,\n",
       "                         1.1022e-01],\n",
       "                       [-1.8586e-01, -1.9655e-01, -4.0382e-02,  6.3010e-02, -1.3656e-01,\n",
       "                        -1.4908e-01, -4.2358e-02, -1.3174e-01, -2.0421e-02,  2.1716e-01,\n",
       "                        -4.4230e-02, -1.3929e-01, -1.2628e-01, -9.7067e-03, -1.1195e-01,\n",
       "                        -1.7608e-01],\n",
       "                       [-1.6025e-01,  2.3339e-01,  3.2864e-01,  3.2040e-01,  1.2322e-04,\n",
       "                         2.4392e-01,  6.3703e-02,  2.4698e-01, -1.3301e-01, -9.1220e-02,\n",
       "                         8.8823e-02,  3.3179e-01, -1.1997e-02, -2.0708e-01, -1.6277e-01,\n",
       "                        -2.3139e-01],\n",
       "                       [-6.6052e-02,  1.6674e-01,  7.7509e-02,  1.7303e-01,  1.6462e-02,\n",
       "                        -1.1270e-01, -6.4882e-02,  6.4054e-02, -2.2706e-01,  1.4996e-01,\n",
       "                         1.7977e-01,  3.2976e-01,  1.8203e-01, -7.5062e-02, -9.8716e-02,\n",
       "                        -4.4349e-01]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.2188, -0.5885,  0.4366, -0.0278, -0.0692, -0.0174, -0.0132,  0.3379,\n",
       "                        0.2286,  0.0737,  0.1061, -0.2321,  0.3099, -0.2104,  0.4116, -0.0927])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[-0.1601, -0.3169, -0.0361, -0.0274, -0.1535, -0.0724, -0.2422,  0.2106,\n",
       "                         0.0341, -0.0308, -0.2271,  0.0806,  0.2736,  0.1673, -0.2878, -0.2355],\n",
       "                       [ 0.0256, -0.6296,  0.1167,  0.1688, -0.1607, -0.0040,  0.0037, -0.0828,\n",
       "                         0.1411,  0.0318,  0.0321, -0.2776,  0.2747,  0.0108, -0.1821, -0.0546],\n",
       "                       [-0.1629, -0.0018, -0.1592,  0.0112,  0.0109,  0.1582, -0.1836,  0.0532,\n",
       "                         0.1075, -0.1182, -0.1601,  0.1216,  0.0489,  0.1478, -0.1050,  0.0582],\n",
       "                       [ 0.0550, -1.0094,  0.2249,  0.1600,  0.1366, -0.0269,  0.0804,  0.1739,\n",
       "                         0.0746,  0.0118,  0.2393,  0.0066, -0.0786,  0.1198,  0.0787, -0.0905],\n",
       "                       [ 0.2414, -0.1408, -0.3907,  0.0085, -0.1883, -0.1343,  0.1725, -0.0578,\n",
       "                        -0.3374,  0.4070, -0.1109, -0.0515,  0.3804,  0.0626, -0.4312, -0.0771],\n",
       "                       [-0.2059,  0.0587, -0.1234, -0.1482,  0.2452,  0.1135, -0.1094,  0.0799,\n",
       "                         0.1566, -0.2718,  0.0563,  0.1206,  0.1286,  0.1270,  0.2886,  0.2889],\n",
       "                       [-0.1140, -0.3292,  0.0741,  0.2739, -0.3017, -0.0843,  0.0449,  0.2130,\n",
       "                         0.0284,  0.1510,  0.1304,  0.0524,  0.1474,  0.2295, -0.3505,  0.0202],\n",
       "                       [ 0.1241, -0.1373,  0.1099,  0.1072, -0.0514, -0.2157, -0.0350, -0.1413,\n",
       "                         0.0708, -0.1296, -0.1696,  0.0396, -0.2138,  0.2322, -0.0219, -0.1424],\n",
       "                       [-0.1363, -0.1848, -0.2198,  0.0926,  0.0694, -0.2560, -0.1908, -0.2697,\n",
       "                        -0.2819,  0.1194, -0.0427, -0.1866,  0.0248,  0.1431, -0.0132,  0.0579],\n",
       "                       [ 0.0427,  0.1329,  0.1504, -0.3594, -0.1180,  0.0902, -0.0658, -0.2455,\n",
       "                         0.0890, -0.0528, -0.0145,  0.1973, -0.2880,  0.2450,  0.2325,  0.0951],\n",
       "                       [ 0.1432, -0.3544, -0.4193,  0.0220, -0.0867, -0.2822, -0.1279, -0.1185,\n",
       "                        -0.1134,  0.0458, -0.3060, -0.0218,  0.1774, -0.1749, -0.4101,  0.0429],\n",
       "                       [-0.2245, -0.3786, -0.6013,  0.2715, -0.0457, -0.0155,  0.2233,  0.1642,\n",
       "                        -0.1826,  0.1541, -0.1070, -0.0539,  0.1367, -0.2169, -0.2921,  0.0255],\n",
       "                       [ 0.0141, -0.2834, -0.0876,  0.2012, -0.2727, -0.3425,  0.0035, -0.1199,\n",
       "                        -0.2651, -0.1044,  0.0576, -0.0472,  0.2201,  0.0776, -0.4388, -0.1534],\n",
       "                       [-0.1644, -0.2940,  0.0144,  0.0033, -0.2651,  0.1382, -0.1150, -0.1415,\n",
       "                         0.2117,  0.0162,  0.1419, -0.2068,  0.0820,  0.0786, -0.0783, -0.0517],\n",
       "                       [ 0.3099, -0.5110,  0.1907,  0.2023, -0.1208,  0.2225, -0.0133,  0.3372,\n",
       "                        -0.0641,  0.1661, -0.1073, -0.0442,  0.1144,  0.2159, -0.1764,  0.2357],\n",
       "                       [-0.2461, -0.0442,  0.0324, -0.0661,  0.1707, -0.2241, -0.1595,  0.0333,\n",
       "                         0.0072,  0.2555, -0.0587, -0.1620, -0.2625, -0.2398, -0.0603, -0.0703]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.1661,  0.4306, -0.2060,  0.1377,  0.3266,  0.2075,  0.2775, -0.2059,\n",
       "                       -0.3352,  0.2798,  0.0919, -0.0091, -0.0397, -0.1328,  0.3962, -0.3070])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[ 3.0828e-02,  1.8793e-01, -8.3743e-02, -3.6567e-01, -5.9742e-02,\n",
       "                        -4.8633e-02, -1.0663e-01,  5.6474e-02, -1.3691e-01,  3.3977e-02,\n",
       "                        -1.1169e-01, -6.8459e-03, -1.5413e-01, -2.2720e-01, -2.5110e-02,\n",
       "                        -1.7702e-01],\n",
       "                       [-2.7725e-01,  1.0684e-01, -5.7004e-02,  1.3926e-03, -1.6323e-01,\n",
       "                        -2.0517e-01, -1.6338e-01,  2.0348e-01,  1.1417e-01, -9.6514e-02,\n",
       "                        -1.7057e-01, -7.7464e-03,  9.9333e-02,  2.3109e-01, -3.7020e-01,\n",
       "                        -2.3120e-01],\n",
       "                       [ 2.1482e-01, -1.7427e-01, -1.1828e-02,  1.4630e-01, -2.2780e-01,\n",
       "                         1.7411e-01,  5.1502e-02, -9.5153e-02,  4.0120e-02,  2.7459e-01,\n",
       "                         1.1299e-01,  8.7595e-02, -1.2646e-01,  2.3716e-01, -2.2020e-01,\n",
       "                         3.4795e-02],\n",
       "                       [ 1.4681e-01,  2.5490e-01,  2.1482e-01, -9.9444e-02,  4.4203e-01,\n",
       "                        -2.5466e-01, -2.7780e-02,  2.6835e-02, -9.4243e-02,  9.7567e-02,\n",
       "                         2.4628e-01,  2.7407e-01,  3.4163e-02, -1.8170e-01,  3.1537e-01,\n",
       "                        -2.0202e-01],\n",
       "                       [-2.3838e-03, -3.6157e-02, -2.9394e-02,  2.4254e-01, -6.6130e-02,\n",
       "                         1.2563e-01, -1.2839e-01,  1.0313e-01, -2.1465e-01,  2.7653e-01,\n",
       "                        -4.5766e-01,  2.8133e-02, -3.8852e-01,  1.6583e-01,  1.1939e-02,\n",
       "                        -1.1824e-01],\n",
       "                       [-1.2067e-01,  1.2153e-01,  2.3926e-02, -7.2663e-03,  2.8578e-01,\n",
       "                        -3.5278e-01,  1.6202e-01, -1.4162e-01, -1.0979e-01,  8.4883e-02,\n",
       "                         1.7502e-01,  2.8703e-01,  2.7533e-02,  2.7920e-01,  2.5917e-01,\n",
       "                         1.7345e-01],\n",
       "                       [ 2.8732e-01, -1.5418e-01,  2.7967e-01, -8.5322e-02, -2.3404e-01,\n",
       "                         2.8255e-01,  9.7404e-03,  1.6665e-01,  5.7950e-02, -1.5860e-01,\n",
       "                        -3.7703e-01, -1.0292e-01, -2.0994e-01,  5.2898e-02,  1.3730e-01,\n",
       "                         1.9535e-01],\n",
       "                       [-8.3636e-02,  4.7741e-02, -1.1983e-01,  8.4065e-02, -8.4706e-02,\n",
       "                         2.9616e-01, -1.2288e-01, -1.2052e-01, -8.0094e-02,  2.6246e-01,\n",
       "                        -9.2198e-02,  4.3284e-02, -2.5481e-01,  6.2993e-02, -1.5015e-01,\n",
       "                         1.8157e-01],\n",
       "                       [-6.3633e-02, -1.0926e-01,  8.7027e-02,  1.2334e-02, -1.3448e-01,\n",
       "                         2.9567e-01, -1.2830e-01, -3.4147e-02, -1.6272e-01,  2.4117e-01,\n",
       "                        -2.6377e-01,  2.4033e-01,  2.1563e-02,  8.2653e-02, -2.3825e-01,\n",
       "                        -1.7999e-01],\n",
       "                       [-4.9784e-02,  8.7664e-02, -1.4331e-01, -2.8194e-01, -4.0520e-03,\n",
       "                         1.0609e-01,  3.3435e-01, -1.2100e-01, -5.1219e-03, -1.4421e-01,\n",
       "                         8.3285e-02, -1.9781e-01,  1.4573e-01,  1.2678e-01,  1.9879e-01,\n",
       "                        -2.3674e-01],\n",
       "                       [-2.0582e-02,  3.8178e-01, -1.0565e-01, -9.7007e-02,  3.8916e-04,\n",
       "                        -2.6350e-01,  1.7632e-02,  8.1963e-03, -9.9837e-02, -2.6150e-01,\n",
       "                        -5.6952e-02,  1.3697e-01,  1.8432e-01, -1.8292e-02,  2.1782e-01,\n",
       "                         1.2125e-01],\n",
       "                       [ 1.0849e-01, -2.1638e-01, -1.3022e-01,  1.4600e-01, -1.0504e-01,\n",
       "                         4.2280e-02,  1.6048e-01, -6.7207e-02, -2.3575e-01,  1.9917e-01,\n",
       "                        -1.5126e-01,  4.0934e-02,  6.0339e-02, -8.2962e-02, -2.6189e-01,\n",
       "                        -1.3198e-01],\n",
       "                       [ 1.4638e-01,  2.7625e-01, -6.8769e-02, -9.5047e-03,  3.4427e-01,\n",
       "                        -2.1895e-01,  2.5938e-02,  2.1005e-01, -1.3748e-01, -1.8462e-01,\n",
       "                        -1.0647e-01,  2.1924e-01, -6.6090e-02,  1.5807e-01,  2.8457e-01,\n",
       "                        -1.0588e-01],\n",
       "                       [ 3.1347e-03,  7.0729e-02,  1.5926e-01,  1.4637e-01, -7.4028e-02,\n",
       "                         1.7468e-01, -8.0188e-02,  7.4444e-02, -7.3935e-02, -2.8432e-04,\n",
       "                        -1.1323e-01, -1.1396e-01,  6.2809e-02, -1.9561e-01, -1.6611e-01,\n",
       "                        -1.1647e-01],\n",
       "                       [ 1.4962e-01,  4.2618e-01,  1.5163e-01, -1.8660e-01,  1.1667e-01,\n",
       "                        -1.1767e-01,  2.9221e-01,  1.3572e-01, -1.2769e-01,  6.8698e-02,\n",
       "                        -2.9115e-02, -4.1829e-02, -1.3452e-01,  9.9411e-02,  1.2379e-01,\n",
       "                        -7.6646e-02],\n",
       "                       [ 3.4371e-04,  2.8282e-02,  1.8553e-01, -2.8772e-01, -1.3182e-01,\n",
       "                        -3.3103e-01, -1.4498e-01,  1.0632e-01, -1.3182e-01,  1.0202e-01,\n",
       "                         2.2565e-01,  6.5546e-02,  1.2362e-01,  2.3996e-01,  2.1146e-01,\n",
       "                         5.3737e-02]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.0378, -0.0419,  0.0104,  0.2464,  0.2373,  0.4516,  0.3278,  0.2864,\n",
       "                        0.3658,  0.0382,  0.4223,  0.1061,  0.2128,  0.2426,  0.2964, -0.0050])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[-0.0154, -0.1453, -0.1115,  0.2040, -0.1548,  0.3296, -0.1328, -0.2599,\n",
       "                        -0.2761,  0.1193,  0.1616, -0.1410,  0.3633, -0.2802,  0.2192, -0.0019]])),\n",
       "              ('layers.8.bias', tensor([-0.0831]))]),\n",
       " 'UQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[-0.1813,  0.2682],\n",
       "                       [ 0.2890, -0.4236],\n",
       "                       [-0.7375,  0.0862],\n",
       "                       [ 0.0960, -0.3078],\n",
       "                       [-0.7773,  0.0150],\n",
       "                       [-0.1984, -0.0631],\n",
       "                       [-0.6203,  0.4309],\n",
       "                       [ 0.1071,  0.2062],\n",
       "                       [ 0.7283, -0.0025],\n",
       "                       [-0.3248,  0.2832],\n",
       "                       [ 0.6064,  0.3331],\n",
       "                       [-0.6838, -0.3486],\n",
       "                       [-0.5313, -0.1921],\n",
       "                       [ 0.3829, -0.0348],\n",
       "                       [-0.1368, -0.0359],\n",
       "                       [-0.0961, -0.1100]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.2785, -0.4733,  0.7468, -0.7737, -0.1631,  0.7745, -0.0749, -0.3708,\n",
       "                        0.2967,  0.2888,  0.0516, -0.0839,  0.2449,  0.4135,  0.5502,  0.5740])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[-0.0658,  0.0812,  0.0026, -0.1543,  0.1226, -0.2315, -0.1274, -0.1894,\n",
       "                         0.0197, -0.1801, -0.1447, -0.2857, -0.1608,  0.1340, -0.0332,  0.2103],\n",
       "                       [-0.1453, -0.1564, -0.1926, -0.1563,  0.1076,  0.0335,  0.0118, -0.1377,\n",
       "                         0.1323, -0.0979, -0.0385, -0.1696, -0.2226, -0.1190, -0.2912, -0.1626],\n",
       "                       [-0.0128, -0.1760, -0.2113, -0.1771, -0.4148,  0.3433, -0.0691,  0.3633,\n",
       "                        -0.0146, -0.0052,  0.1416, -0.3402,  0.1186,  0.1528,  0.2261,  0.3430],\n",
       "                       [-0.1083, -0.1281, -0.2877,  0.1373, -0.3380,  0.0214,  0.1702,  0.0515,\n",
       "                         0.3387, -0.0630,  0.2353, -0.1400,  0.0203,  0.2931,  0.1584,  0.1393],\n",
       "                       [-0.0303, -0.1815, -0.2510, -0.1419,  0.0517, -0.0484, -0.0145,  0.1311,\n",
       "                        -0.1798, -0.0254, -0.1424,  0.0295,  0.0680,  0.0256,  0.0159, -0.2893],\n",
       "                       [-0.2733,  0.2332, -0.0825,  0.2884, -0.1376,  0.1516,  0.0578,  0.0232,\n",
       "                         0.3569, -0.1826,  0.1690, -0.2907, -0.0179,  0.2618,  0.0693, -0.1532],\n",
       "                       [-0.1308,  0.1283, -0.2121, -0.0119, -0.2472,  0.1635, -0.2410, -0.0728,\n",
       "                         0.0172, -0.4242, -0.2877, -0.3072,  0.0661, -0.0622,  0.0375,  0.0968],\n",
       "                       [ 0.1091,  0.1682, -0.2385,  0.1001, -0.2222,  0.3054, -0.1598,  0.1443,\n",
       "                         0.3358,  0.0681,  0.2280, -0.1808, -0.1964,  0.3369,  0.3113,  0.3799],\n",
       "                       [-0.2553, -0.0132, -0.0440, -0.0841, -0.1303, -0.1107,  0.1785, -0.2145,\n",
       "                         0.0898, -0.0749, -0.1278,  0.0076, -0.1184, -0.1977,  0.0338, -0.2747],\n",
       "                       [-0.4785,  0.4144, -0.3701,  0.1776, -0.1416, -0.3774, -0.1230,  0.1777,\n",
       "                         0.1667, -0.1111,  0.3999, -0.0557, -0.1884,  0.1606, -0.2689, -0.1690],\n",
       "                       [-0.1821,  0.0337, -0.2971,  0.2276, -0.0823, -0.2929,  0.0179,  0.1716,\n",
       "                         0.1195, -0.2026, -0.1977,  0.1202,  0.1461, -0.0526,  0.1554, -0.2998],\n",
       "                       [ 0.1418, -0.2383, -0.0704,  0.0698,  0.0018, -0.1376, -0.0382, -0.2198,\n",
       "                        -0.0834, -0.1966, -0.2460,  0.0361,  0.0304,  0.0563,  0.1529, -0.1706],\n",
       "                       [ 0.1976, -0.1397,  0.1791, -0.4253,  0.3840,  0.1386,  0.0189, -0.0148,\n",
       "                         0.0082,  0.3117, -0.1971, -0.1505,  0.2117, -0.2522,  0.0808,  0.0139],\n",
       "                       [ 0.0115,  0.1348,  0.1791,  0.0649,  0.5327,  0.4096,  0.1630, -0.1706,\n",
       "                        -0.2964,  0.0710,  0.1377,  0.3314,  0.0721, -0.2406,  0.3809,  0.2286],\n",
       "                       [-0.1678, -0.1844, -0.0842, -0.0899,  0.1545,  0.1101,  0.0926,  0.0205,\n",
       "                        -0.0064,  0.0871, -0.1482, -0.2903, -0.1492,  0.1064, -0.1253, -0.0742],\n",
       "                       [ 0.0987, -0.0029, -0.1983,  0.0047,  0.3500,  0.0642,  0.0112,  0.2324,\n",
       "                         0.1995,  0.0243,  0.2620,  0.2050, -0.1886,  0.1760, -0.0457, -0.0595]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([-0.0589, -0.0280,  0.3525,  0.2938, -0.1441,  0.0084,  0.0768,  0.0180,\n",
       "                        0.0861, -0.2666, -0.0388, -0.2320,  0.3603,  0.1516, -0.1545, -0.0276])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[-1.3153e-02,  7.0868e-02, -5.8666e-02,  5.5605e-02,  1.8287e-01,\n",
       "                        -2.0464e-01, -2.0547e-01, -2.7064e-02, -9.6887e-04, -3.1401e-02,\n",
       "                         1.4674e-01,  6.4896e-03, -4.2298e-02, -1.1595e-01, -6.4829e-02,\n",
       "                         1.5656e-01],\n",
       "                       [-3.5056e-02, -1.5062e-01,  1.3569e-01, -1.4061e-01,  2.1475e-01,\n",
       "                         4.4314e-02,  2.7029e-02,  7.5763e-03,  7.2786e-04,  2.2734e-04,\n",
       "                         1.2257e-01, -2.8187e-02, -1.3823e-01, -4.4278e-01, -2.4021e-01,\n",
       "                         1.7952e-01],\n",
       "                       [ 4.6156e-02,  1.5111e-01, -8.1440e-02,  2.9860e-01,  6.5368e-02,\n",
       "                         9.4119e-02,  2.5580e-01, -4.4522e-02, -7.9852e-02, -3.5739e-01,\n",
       "                        -6.2954e-02, -5.2856e-02, -3.2506e-01, -7.9463e-02, -1.5786e-01,\n",
       "                        -1.0688e-01],\n",
       "                       [ 3.4397e-01,  2.3350e-01, -1.1110e-02,  6.6843e-02,  1.5198e-01,\n",
       "                        -4.1869e-02,  1.9571e-01, -1.2164e-01,  6.5389e-02,  4.8703e-01,\n",
       "                         7.4373e-02, -9.0870e-02,  1.4924e-01,  2.8087e-01,  2.2758e-01,\n",
       "                         8.8057e-02],\n",
       "                       [-5.6393e-02,  1.7088e-01,  2.7355e-01, -3.0966e-03,  1.6652e-01,\n",
       "                        -9.5673e-02,  1.4319e-02, -2.8908e-01, -9.2268e-02,  2.2282e-01,\n",
       "                        -1.0347e-01, -9.3317e-02,  4.7053e-02,  1.2983e-01,  1.7544e-01,\n",
       "                         3.3266e-02],\n",
       "                       [ 6.1427e-02,  2.3522e-01,  1.5246e-01,  2.7799e-01, -8.9583e-02,\n",
       "                         1.9089e-01,  1.3237e-01,  2.6790e-01, -1.5031e-01, -5.6524e-01,\n",
       "                         3.0745e-01,  2.6438e-02, -2.6083e-01, -2.2143e-01, -2.5750e-01,\n",
       "                        -1.4871e-01],\n",
       "                       [-1.3984e-01,  2.9808e-02,  2.0020e-01, -3.7677e-01, -1.3543e-01,\n",
       "                        -2.1188e-01,  1.6731e-01, -1.6695e-01, -7.8300e-02, -2.6107e-01,\n",
       "                        -1.8747e-01, -1.0762e-01,  3.6913e-01,  6.2400e-01, -2.2364e-01,\n",
       "                        -2.8681e-01],\n",
       "                       [ 5.0191e-03, -7.6317e-02, -1.7072e-01,  1.3302e-01,  8.9976e-02,\n",
       "                         2.6993e-01, -2.5077e-02, -1.3620e-03,  1.8196e-01, -1.7436e-01,\n",
       "                        -8.2242e-02,  1.6950e-01, -3.3658e-01, -3.3672e-01, -1.7636e-01,\n",
       "                        -1.0449e-01],\n",
       "                       [ 1.3021e-01,  1.1449e-02, -9.5003e-02,  2.3419e-02,  1.9206e-03,\n",
       "                        -1.8137e-01,  1.5767e-01, -1.4575e-02, -2.4912e-01,  7.0599e-03,\n",
       "                         9.1184e-02,  9.5743e-02, -2.4872e-01,  1.1282e-01, -8.0442e-02,\n",
       "                        -1.2382e-01],\n",
       "                       [-1.3448e-01,  4.1701e-02,  2.2046e-01,  1.6640e-01, -1.8895e-01,\n",
       "                         1.5117e-01,  2.8319e-01,  1.7321e-01,  2.7400e-01, -4.6152e-01,\n",
       "                        -1.3083e-01, -9.3555e-02, -2.5465e-01, -1.8696e-02, -6.6850e-02,\n",
       "                         2.4494e-01],\n",
       "                       [-2.9027e-03,  1.6409e-01, -2.3607e-01, -3.7219e-01, -2.9166e-02,\n",
       "                        -9.7091e-02, -2.9361e-01, -1.4626e-01,  1.5077e-01, -1.1279e-01,\n",
       "                         1.5619e-01,  4.7356e-02,  3.1634e-01,  1.3178e-01,  1.6674e-01,\n",
       "                        -1.8283e-01],\n",
       "                       [ 1.9273e-01, -3.0544e-02,  3.1222e-01,  1.7610e-01, -9.2089e-03,\n",
       "                        -3.7697e-02, -9.3389e-02,  3.0423e-01,  1.5512e-01, -3.5012e-01,\n",
       "                         3.1668e-01,  6.8186e-02, -5.4252e-02, -1.7601e-01, -3.9934e-03,\n",
       "                         9.0231e-02],\n",
       "                       [ 1.3061e-01,  2.0736e-01,  2.9889e-02,  4.8364e-02,  1.3028e-02,\n",
       "                        -9.1368e-03, -2.3800e-01,  1.7786e-01,  1.5691e-01, -4.5585e-01,\n",
       "                         1.7929e-01,  1.2536e-01, -1.2298e-01, -1.2102e-01, -9.6691e-02,\n",
       "                        -5.5186e-02],\n",
       "                       [-5.5767e-02,  3.6052e-02,  1.4711e-01,  1.2351e-01, -1.7680e-01,\n",
       "                         3.4291e-01,  3.2913e-01,  3.1808e-01,  9.4865e-02, -4.0429e-01,\n",
       "                        -1.6563e-01, -6.2440e-02, -1.2161e-02, -2.8411e-01, -1.4067e-01,\n",
       "                         2.2772e-01],\n",
       "                       [ 5.9018e-02,  1.6310e-01,  3.5236e-01,  2.9890e-01, -9.1980e-02,\n",
       "                         1.7291e-01, -1.5401e-02,  3.2554e-01,  2.7375e-01, -3.0084e-01,\n",
       "                         9.5061e-02,  1.9836e-01, -1.3590e-01, -1.3191e-01,  1.7610e-01,\n",
       "                        -1.5947e-01],\n",
       "                       [-1.4384e-01, -1.7208e-01, -1.0175e-01, -1.2665e-01,  1.1193e-02,\n",
       "                        -2.2722e-01,  2.1238e-01, -1.9235e-01,  7.8961e-02,  1.3880e-01,\n",
       "                        -1.9637e-01,  2.2484e-01,  4.0400e-02, -1.7268e-01, -2.0935e-02,\n",
       "                         1.4047e-01]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.1740, -0.2302,  0.2428,  0.0172,  0.1216, -0.0841,  0.4820,  0.1917,\n",
       "                       -0.2137,  0.1702,  0.2248, -0.0251,  0.2282,  0.4379,  0.4018,  0.1293])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[-2.7858e-01, -2.0513e-01,  8.4783e-02,  3.2906e-01,  4.7708e-02,\n",
       "                        -1.8658e-01, -1.1376e-01, -4.9774e-01, -1.8098e-01, -4.5219e-02,\n",
       "                        -2.2362e-01, -1.4275e-01,  4.7083e-02,  1.9822e-01,  9.2767e-02,\n",
       "                         1.1702e-01],\n",
       "                       [-5.4086e-02, -3.6968e-01,  7.9065e-02,  2.9357e-01,  5.1202e-01,\n",
       "                        -6.9158e-02,  4.6357e-01, -8.7318e-03,  5.5341e-02, -1.2183e-01,\n",
       "                         2.3080e-01,  1.8399e-01,  1.4021e-01, -2.8664e-01, -2.1042e-01,\n",
       "                        -9.5869e-03],\n",
       "                       [ 1.9432e-01,  1.4097e-01,  4.1544e-02,  9.0395e-02, -8.6813e-03,\n",
       "                         2.2725e-01, -2.5387e-01, -1.1293e-01, -2.4207e-01, -1.0396e-01,\n",
       "                        -1.5701e-01, -1.6568e-01,  4.6860e-02,  3.0660e-01,  2.3994e-01,\n",
       "                        -2.0656e-01],\n",
       "                       [-5.5927e-04,  2.4440e-01, -1.2791e-01,  1.1896e-01,  4.3248e-02,\n",
       "                         4.3569e-02,  1.1382e-01,  3.9651e-02, -1.5742e-01,  2.1356e-01,\n",
       "                        -1.3226e-01,  2.6621e-01,  3.2152e-02,  1.1565e-01,  3.3307e-01,\n",
       "                        -5.7193e-02],\n",
       "                       [-1.2303e-01, -2.2118e-01,  2.9603e-01, -2.3494e-01,  1.3941e-01,\n",
       "                         2.6222e-01, -6.0435e-02, -2.2247e-01, -4.8573e-02, -1.2853e-01,\n",
       "                        -3.0066e-01,  3.7469e-02,  1.6910e-02,  2.2250e-01,  2.4769e-01,\n",
       "                         3.1410e-01],\n",
       "                       [-7.3103e-02,  2.3511e-03,  2.8256e-01, -8.1677e-02, -4.7016e-02,\n",
       "                        -2.3468e-03, -6.1957e-01, -1.3775e-01,  1.3843e-01, -1.1955e-01,\n",
       "                        -1.3235e-01,  1.0813e-01,  1.2715e-01,  8.8838e-02, -6.6409e-03,\n",
       "                        -1.1046e-01],\n",
       "                       [ 2.0084e-01, -1.0803e-01, -2.1971e-02,  3.3647e-02,  1.9465e-01,\n",
       "                        -1.8647e-01, -8.8490e-02,  1.9924e-01, -1.6512e-01,  2.9314e-01,\n",
       "                        -1.5360e-01,  2.2857e-01,  1.1043e-01,  2.8221e-01,  3.5208e-01,\n",
       "                         3.1116e-01],\n",
       "                       [ 2.4116e-03, -1.1469e-01, -6.4864e-02, -2.4537e-01, -5.9890e-02,\n",
       "                         1.7519e-02, -4.8938e-01,  6.6334e-02, -1.6593e-01,  1.3754e-01,\n",
       "                        -2.2871e-01,  6.0658e-02,  9.1403e-02,  3.2733e-01, -1.0385e-01,\n",
       "                         8.0940e-02],\n",
       "                       [-3.3662e-01, -3.7048e-01,  4.2045e-02,  1.5244e-01, -1.2941e-01,\n",
       "                        -5.5748e-02, -4.1443e-01, -6.2595e-02,  1.7975e-01, -1.9978e-01,\n",
       "                        -3.2406e-01, -1.6121e-02, -1.4135e-01,  9.6757e-02, -1.1007e-01,\n",
       "                        -1.1442e-01],\n",
       "                       [ 3.8582e-02, -4.8197e-01, -7.2021e-02,  2.7083e-01,  2.3122e-01,\n",
       "                         6.3993e-02,  7.3759e-01, -3.2487e-01, -8.1668e-02,  1.2477e-01,\n",
       "                         2.2280e-01, -2.9643e-02, -1.7034e-01, -9.2636e-02, -1.1073e-01,\n",
       "                         2.4252e-01],\n",
       "                       [ 1.1481e-01,  2.4945e-01, -2.4613e-01, -1.6319e-01,  3.1869e-02,\n",
       "                        -1.2676e-01, -1.9103e-01, -2.9847e-01, -2.2568e-01, -1.1307e-01,\n",
       "                         1.4644e-01, -2.7169e-01,  7.3505e-02,  1.2681e-01, -2.8155e-01,\n",
       "                         1.5641e-01],\n",
       "                       [ 4.2353e-02,  1.9852e-01,  2.3027e-01, -8.8947e-02, -1.3904e-01,\n",
       "                        -8.2569e-02, -6.7125e-01, -1.8525e-01, -7.3428e-02, -9.2413e-02,\n",
       "                        -2.8088e-01,  2.2429e-01,  2.9179e-02, -7.3275e-02,  6.4692e-02,\n",
       "                         1.5225e-02],\n",
       "                       [ 7.2632e-02,  1.7967e-01,  5.5304e-02, -1.9042e-01, -2.2207e-02,\n",
       "                        -2.3236e-01,  3.5365e-02, -2.2445e-02,  8.6998e-02, -2.0674e-01,\n",
       "                         1.1722e-01, -2.9136e-01, -3.0820e-01, -3.0837e-01, -4.2687e-02,\n",
       "                        -2.1530e-02],\n",
       "                       [ 2.8693e-02, -5.3221e-02,  1.3948e-01, -4.5256e-02, -3.9624e-02,\n",
       "                         2.4187e-01, -5.2426e-01,  2.3520e-01,  8.6106e-02,  1.5140e-01,\n",
       "                        -2.7133e-01,  1.8710e-01, -3.0059e-02,  3.3933e-01,  3.0937e-01,\n",
       "                         2.6639e-01],\n",
       "                       [-1.9641e-02, -2.2876e-01, -4.0955e-02, -2.2570e-01, -1.6935e-01,\n",
       "                         2.3818e-01,  2.5615e-02,  1.5030e-01, -2.2465e-01, -4.4485e-02,\n",
       "                         6.7230e-02, -4.7361e-02, -4.3564e-02, -5.7481e-02, -1.6575e-01,\n",
       "                        -1.9579e-01],\n",
       "                       [ 1.5632e-01,  1.4516e-01,  1.1000e-01, -1.3239e-01,  8.9893e-02,\n",
       "                         1.3061e-01, -1.4191e-02, -2.0400e-01,  8.2136e-02,  6.5296e-02,\n",
       "                         6.4966e-02, -1.1715e-01, -2.6534e-01, -1.5302e-01, -8.3011e-02,\n",
       "                        -1.2555e-01]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.0382,  0.2384, -0.0196,  0.0185,  0.3848,  0.2427,  0.1332,  0.3800,\n",
       "                        0.1526,  0.1473,  0.0371,  0.1940, -0.2192,  0.3121,  0.0314, -0.0163])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[ 0.0654, -0.1823,  0.0796,  0.2319,  0.1243,  0.1491,  0.1644,  0.2352,\n",
       "                         0.0589, -0.3433, -0.1648,  0.0604, -0.0114,  0.2739, -0.1554,  0.0277]])),\n",
       "              ('layers.8.bias', tensor([0.2083]))]),\n",
       " 'LQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[ 0.2337, -0.0942],\n",
       "                       [ 0.2142,  0.3291],\n",
       "                       [-0.4844,  0.3078],\n",
       "                       [ 0.2297,  0.0655],\n",
       "                       [ 0.2495, -0.2373],\n",
       "                       [-0.7065, -0.4494],\n",
       "                       [-0.6676,  0.4437],\n",
       "                       [-0.2588, -0.1736],\n",
       "                       [ 0.8056,  0.5449],\n",
       "                       [ 0.5956, -0.3357],\n",
       "                       [ 0.6585, -0.0120],\n",
       "                       [ 0.1178,  0.1093],\n",
       "                       [ 0.5422, -0.0213],\n",
       "                       [-0.4736,  0.2809],\n",
       "                       [ 0.6222, -0.0278],\n",
       "                       [-0.0743, -0.0880]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.0697, -0.4065,  0.1554,  0.0050, -0.0787, -0.2960,  0.3282, -0.0726,\n",
       "                        0.3128, -0.2568, -0.2409, -0.2815,  0.5195,  0.3096, -1.2241,  0.5519])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[ 0.0763, -0.2077, -0.2126,  0.2492, -0.0315,  0.0813, -0.2008, -0.2242,\n",
       "                        -0.2101,  0.1727, -0.0400,  0.0895, -0.1717, -0.1773, -0.0361, -0.2320],\n",
       "                       [ 0.1704, -0.0617, -0.1920, -0.1291, -0.2727,  0.0725, -0.0628, -0.2593,\n",
       "                        -0.1649, -0.1622,  0.2365, -0.1468, -0.1413, -0.2166,  0.0215, -0.0740],\n",
       "                       [-0.2704, -0.2295,  0.1257,  0.1982,  0.0540, -0.1043, -0.2790,  0.1180,\n",
       "                         0.1544, -0.0774, -0.2892,  0.1426, -0.0997, -0.2723,  0.0681, -0.2854],\n",
       "                       [ 0.1972, -0.0959,  0.1721,  0.1558, -0.0174,  0.3117, -0.0527,  0.0362,\n",
       "                        -0.0048,  0.0992,  0.0333, -0.0573, -0.2037,  0.2651, -0.3988,  0.1580],\n",
       "                       [ 0.0598,  0.0097,  0.2339, -0.1349,  0.1893,  0.0751,  0.2624,  0.0220,\n",
       "                         0.1870, -0.2974, -0.4452, -0.1920, -0.0628,  0.2557, -0.0848,  0.2399],\n",
       "                       [ 0.3256,  0.1848, -0.0274,  0.1399,  0.0878, -0.0504, -0.0381, -0.1156,\n",
       "                         0.4701,  0.4710,  0.0897,  0.0203,  0.6408,  0.2269, -0.4243,  0.1308],\n",
       "                       [ 0.0170,  0.1055, -0.1343,  0.3467,  0.2604,  0.0958,  0.2238, -0.0199,\n",
       "                         0.2606,  0.0626,  0.0660,  0.2183, -0.2428, -0.1634, -0.8552,  0.2217],\n",
       "                       [ 0.0177, -0.3188, -0.0344, -0.0141,  0.0018, -0.1906, -0.1972, -0.1695,\n",
       "                         0.1770,  0.0243, -0.0663, -0.1872,  0.1529, -0.1126, -0.6577, -0.1750],\n",
       "                       [ 0.1489,  0.2543,  0.2841,  0.2568,  0.1534,  0.0574, -0.1056, -0.0808,\n",
       "                        -0.1370,  0.1216,  0.0398,  0.2720, -0.2430,  0.1864, -0.2752,  0.3386],\n",
       "                       [-0.2128, -0.2567, -0.2153,  0.0135, -0.2394,  0.3100, -0.3025, -0.0784,\n",
       "                         0.3061,  0.0838,  0.2387, -0.3216, -0.0576, -0.0535, -0.6343, -0.0861],\n",
       "                       [-0.0733, -0.1721, -0.0090, -0.1808, -0.1352, -0.1653, -0.2177,  0.1470,\n",
       "                        -0.2096,  0.1372, -0.1532,  0.0395,  0.0689,  0.0808, -0.2486, -0.1276],\n",
       "                       [-0.2961,  0.0873, -0.1560,  0.0389, -0.1414, -0.2224, -0.1661, -0.1201,\n",
       "                        -0.1458, -0.1404,  0.0213,  0.0865, -0.2524,  0.0552, -0.0190, -0.2151],\n",
       "                       [ 0.1325,  0.2384,  0.1354, -0.0055, -0.1731,  0.2847,  0.2762,  0.2668,\n",
       "                        -0.1729, -0.1014,  0.1792, -0.2104, -0.1211, -0.0711, -0.0908,  0.1173],\n",
       "                       [ 0.0091, -0.2834,  0.0569,  0.0524, -0.1256, -0.0326,  0.0853,  0.0196,\n",
       "                        -0.0567,  0.0201, -0.3114, -0.1741, -0.2315, -0.1768, -0.1345,  0.1056],\n",
       "                       [ 0.1371, -0.2860, -0.3215, -0.1196,  0.1134, -0.2657, -0.1437, -0.0767,\n",
       "                         0.1264,  0.2184,  0.2338, -0.0504,  0.6065,  0.1626, -0.9896, -0.0523],\n",
       "                       [-0.2455, -0.0378, -0.1086, -0.0656, -0.0768,  0.0503, -0.1855,  0.0790,\n",
       "                         0.1035, -0.1497, -0.2426, -0.1490, -0.1360, -0.0332,  0.2056, -0.1064]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([-0.2451,  0.1111, -0.2911,  0.3897,  0.2264, -0.0627, -0.0137,  0.1708,\n",
       "                        0.3657,  0.1336, -0.0835,  0.1655,  0.2722, -0.2047,  0.1706, -0.0857])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[ 2.0482e-02,  8.6139e-02, -3.1440e-02,  5.2470e-02,  2.5043e-01,\n",
       "                        -1.4407e-01,  2.8929e-01,  1.6461e-01,  6.4119e-02, -3.2267e-03,\n",
       "                         2.4003e-01,  8.6940e-02,  2.4201e-01, -1.1096e-01, -2.5815e-01,\n",
       "                         2.2755e-01],\n",
       "                       [ 1.1100e-01, -2.6060e-01, -2.0398e-01, -2.6338e-01, -2.4162e-01,\n",
       "                        -1.7725e-01,  5.9483e-02, -8.7368e-02, -2.7744e-02, -2.6072e-01,\n",
       "                         2.4306e-01,  1.5167e-01,  2.0154e-02, -3.5445e-02, -2.2553e-03,\n",
       "                        -2.7228e-02],\n",
       "                       [-1.8993e-01,  1.4787e-01, -1.8331e-01, -1.5790e-01, -2.3216e-01,\n",
       "                        -1.0556e-01,  1.3512e-01, -2.0720e-01, -2.0545e-01,  2.0503e-02,\n",
       "                        -1.2063e-01, -8.5309e-02, -2.2956e-01, -3.3481e-02, -8.6817e-02,\n",
       "                         8.3738e-02],\n",
       "                       [-9.9305e-02,  2.8636e-01,  1.8404e-01,  2.1260e-01,  1.0478e-01,\n",
       "                        -4.2522e-01,  3.1488e-01,  2.5012e-02,  3.3292e-01,  9.1126e-02,\n",
       "                        -9.5730e-02,  4.8288e-02,  3.0169e-01, -9.9305e-02,  1.1019e-01,\n",
       "                        -4.8196e-02],\n",
       "                       [ 1.6231e-01, -1.1043e-01, -1.1240e-01,  1.7134e-01,  2.9404e-01,\n",
       "                        -4.2321e-01,  2.0752e-02,  1.9166e-02,  1.8553e-01,  1.0102e-01,\n",
       "                        -1.6509e-01,  1.3961e-01,  1.8342e-01, -4.7662e-02,  1.9019e-01,\n",
       "                        -1.4441e-01],\n",
       "                       [ 1.8469e-01, -7.2365e-02, -3.6791e-02, -3.6168e-02, -2.7238e-02,\n",
       "                        -1.9638e-01, -1.4370e-01, -1.4388e-02, -1.7026e-01, -8.9934e-03,\n",
       "                         7.5113e-02,  4.9189e-02, -5.6780e-02, -1.1681e-01,  1.7593e-01,\n",
       "                         1.2926e-01],\n",
       "                       [-1.6514e-01,  9.0628e-02,  1.7481e-01, -1.4441e-01,  7.5163e-02,\n",
       "                        -4.6444e-03,  5.1204e-02,  2.1529e-01, -7.0723e-02,  4.7480e-02,\n",
       "                        -2.2518e-01,  9.0313e-02,  6.7519e-02, -1.3332e-01, -2.1554e-01,\n",
       "                         1.9517e-01],\n",
       "                       [ 1.6028e-01,  1.8766e-01, -2.3796e-02,  1.9841e-01, -9.9535e-02,\n",
       "                         1.6595e-01,  3.7819e-01,  2.2121e-01,  1.6465e-01,  3.5918e-01,\n",
       "                         2.7770e-02,  2.0622e-01, -1.2189e-02, -2.5495e-01,  4.8926e-01,\n",
       "                         1.1680e-01],\n",
       "                       [-7.9659e-02, -1.1909e-01,  1.3649e-01,  3.8271e-01,  2.7180e-01,\n",
       "                        -2.9047e-01,  2.2812e-01,  1.8513e-01,  2.9845e-02,  1.2019e-01,\n",
       "                         1.3046e-01, -6.9128e-02,  1.0977e-02,  2.0565e-01, -6.2371e-02,\n",
       "                        -1.1798e-01],\n",
       "                       [ 1.1614e-01, -1.3790e-01,  7.0998e-02,  5.9830e-04, -1.3766e-02,\n",
       "                        -2.4432e-01,  3.3632e-01,  1.9093e-01,  2.1914e-01,  3.4758e-02,\n",
       "                        -7.2387e-02, -1.1662e-01, -1.9922e-01,  2.0366e-01, -2.3622e-01,\n",
       "                        -1.3410e-01],\n",
       "                       [-1.3849e-01,  2.1806e-01, -2.7081e-01, -6.1049e-03,  8.3455e-02,\n",
       "                         1.8304e-01,  3.2889e-01,  4.0062e-01,  4.3197e-02,  1.6412e-01,\n",
       "                         1.5364e-01,  5.8137e-02, -6.2756e-02, -2.0300e-01,  1.2357e-01,\n",
       "                         1.0267e+00],\n",
       "                       [ 6.4171e-02, -5.4455e-02,  4.5036e-02,  2.6188e-02,  1.4084e-01,\n",
       "                        -2.0006e-01,  1.5460e-01,  3.6068e-01,  2.2476e-01,  3.8740e-01,\n",
       "                         1.3115e-01, -2.3507e-03,  2.3180e-05,  2.2291e-01, -8.1143e-03,\n",
       "                        -2.2431e-01],\n",
       "                       [ 1.3755e-01, -1.3362e-01, -1.4364e-02, -1.3951e-01, -1.6828e-01,\n",
       "                        -2.2803e-01,  1.0397e-01,  6.2171e-04,  1.2460e-01, -1.0898e-01,\n",
       "                        -4.5789e-02, -2.9680e-01,  7.1870e-02, -7.6360e-02, -9.3689e-02,\n",
       "                         4.7175e-02],\n",
       "                       [-2.2195e-01, -5.0623e-02,  5.4319e-02,  6.2284e-02, -1.3016e-01,\n",
       "                        -1.4362e-01,  5.9103e-02, -1.0340e-01,  2.6338e-03,  5.0897e-03,\n",
       "                         1.9951e-01,  7.5156e-02,  1.4352e-01, -3.9846e-02, -7.2805e-02,\n",
       "                         4.1767e-02],\n",
       "                       [ 2.3164e-01,  1.6596e-01,  1.1166e-01,  6.9793e-02,  3.3647e-01,\n",
       "                        -2.7905e-01,  1.9860e-01,  1.5276e-01,  3.4416e-01,  3.3899e-01,\n",
       "                         1.2087e-01, -1.2885e-01,  7.7750e-02, -8.0553e-02, -1.7030e-01,\n",
       "                         2.6168e-02],\n",
       "                       [ 1.8472e-01, -1.3582e-03, -1.7717e-03, -1.9103e-01,  1.0883e-01,\n",
       "                        -8.0165e-02, -1.1607e-01, -1.1160e-01,  1.6721e-01, -1.2522e-01,\n",
       "                         1.2443e-03, -1.1589e-01, -8.1494e-02,  2.4503e-01, -2.1619e-01,\n",
       "                        -2.2609e-01]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.4104,  0.0980,  0.1563,  0.3176,  0.4073, -0.0270,  0.2225,  0.0725,\n",
       "                        0.2473, -0.0510,  0.1811,  0.0279,  0.0441,  0.0049,  0.2854, -0.1836])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[ 8.8116e-02, -8.3859e-02, -2.3088e-01, -2.2554e-01,  1.0512e-01,\n",
       "                        -1.0245e-01, -2.2467e-01, -1.0001e-01, -9.7528e-03,  8.7434e-02,\n",
       "                         2.3490e-02,  1.1342e-01, -2.7802e-01,  1.9199e-01, -1.3936e-01,\n",
       "                        -1.5374e-01],\n",
       "                       [ 9.4283e-02, -1.6356e-01, -1.8283e-01,  3.5689e-01,  3.6401e-01,\n",
       "                         1.3311e-01, -8.3861e-02, -1.7057e-01,  2.7648e-01,  9.3648e-02,\n",
       "                        -1.6233e-01,  2.5375e-01, -7.3575e-02, -3.6200e-02,  3.0514e-01,\n",
       "                         8.7777e-02],\n",
       "                       [-1.3875e-01,  2.2893e-01,  1.8665e-01,  1.3941e-01,  2.2014e-01,\n",
       "                        -8.1469e-02, -2.3031e-01, -2.4421e-01,  6.8381e-03, -1.4766e-01,\n",
       "                        -2.0564e-01, -1.1945e-01, -2.3294e-02,  5.1405e-02, -2.4054e-01,\n",
       "                         2.0688e-01],\n",
       "                       [ 3.7759e-02,  5.1712e-02,  8.9947e-02, -5.2415e-02, -1.1511e-02,\n",
       "                         1.2102e-01,  1.2217e-01, -4.7228e-03, -6.1957e-02,  7.1755e-02,\n",
       "                        -1.7692e-01, -2.3030e-01, -6.7594e-02,  2.2217e-01, -2.0908e-01,\n",
       "                         1.4109e-01],\n",
       "                       [ 1.2273e-01,  2.6638e-01,  3.0340e-01,  1.3132e-01,  3.3397e-01,\n",
       "                         1.4414e-01,  1.4870e-01, -9.7050e-02,  2.6697e-01,  1.9532e-01,\n",
       "                        -7.4950e-02, -1.2867e-01,  3.3548e-01,  4.4032e-02,  1.6856e-01,\n",
       "                        -2.2807e-01],\n",
       "                       [ 7.6196e-02,  3.1244e-02, -1.6467e-01,  6.9419e-02, -5.3834e-03,\n",
       "                        -2.2042e-02,  1.2811e-01,  3.2928e-01, -2.2746e-01, -7.8262e-02,\n",
       "                        -7.5276e-02,  1.5074e-01, -3.1944e-01,  4.0425e-02, -8.4662e-02,\n",
       "                        -3.3349e-02],\n",
       "                       [ 2.5013e-01,  1.4325e-01,  1.8907e-01,  2.7791e-01,  3.8306e-01,\n",
       "                         2.3067e-01,  3.0909e-01, -1.9310e-01,  1.8987e-01, -7.1508e-02,\n",
       "                        -3.4374e-01,  1.3936e-01,  3.5768e-02,  1.4745e-01,  1.5735e-01,\n",
       "                         8.3871e-02],\n",
       "                       [-6.5849e-02,  2.6436e-01,  1.0398e-01, -4.5315e-03, -1.2666e-01,\n",
       "                        -1.2143e-01, -4.0914e-02, -9.8540e-02, -4.7620e-02,  1.1803e-01,\n",
       "                        -4.0046e-01, -3.6550e-02,  3.7414e-01, -1.3640e-02, -9.4671e-02,\n",
       "                        -4.2353e-02],\n",
       "                       [-3.0973e-01,  8.9092e-02,  1.7886e-01,  2.7866e-02, -2.7935e-01,\n",
       "                        -3.4795e-02,  1.3973e-01,  5.5422e-01, -2.2367e-01, -1.3531e-01,\n",
       "                         1.9251e-01, -1.6951e-01, -6.9191e-03,  4.5706e-04, -3.6174e-01,\n",
       "                        -8.0515e-03],\n",
       "                       [-2.2135e-01, -1.8929e-01, -6.9165e-02,  1.5564e-01, -7.3405e-02,\n",
       "                        -2.2489e-01,  5.3021e-02, -6.4936e-02,  1.3672e-01,  2.8523e-02,\n",
       "                        -1.2609e-01, -1.5875e-01, -3.9358e-02,  1.0342e-01, -1.6065e-01,\n",
       "                        -3.5363e-02],\n",
       "                       [-3.1988e-01,  1.1697e-01, -1.4319e-01,  1.9056e-02,  1.3805e-01,\n",
       "                        -9.6910e-02, -1.5542e-01, -9.9611e-02, -2.3418e-02, -1.6954e-01,\n",
       "                         4.4340e-02,  1.1263e-01, -7.4118e-02, -1.9327e-01,  4.6524e-02,\n",
       "                        -1.5991e-01],\n",
       "                       [ 2.2441e-01,  1.9882e-01, -1.2682e-04,  6.5780e-02,  1.5816e-01,\n",
       "                        -1.1735e-01,  1.6426e-02,  6.2426e-02, -3.8993e-02,  3.0839e-01,\n",
       "                         3.5755e-01, -5.6759e-02,  9.1117e-02,  1.4824e-01,  1.2886e-01,\n",
       "                         1.5061e-01],\n",
       "                       [-8.3613e-02, -2.0892e-02,  1.8560e-01, -3.1243e-02,  5.4093e-02,\n",
       "                        -1.0346e-01, -2.4588e-01, -2.1022e-01,  3.0372e-03, -1.6556e-01,\n",
       "                        -2.2190e-01, -1.0438e-01,  2.0951e-02,  3.7537e-02, -4.5989e-02,\n",
       "                         1.8138e-01],\n",
       "                       [ 1.3511e-01, -1.9643e-01,  2.1127e-01,  1.6910e-01,  4.6351e-02,\n",
       "                        -2.2891e-01, -1.5115e-01, -1.8258e-01, -1.4119e-02,  5.5528e-02,\n",
       "                        -1.4382e-01, -5.9059e-02, -7.9394e-02, -1.3259e-01, -2.3430e-01,\n",
       "                        -1.4983e-02],\n",
       "                       [ 2.3819e-01, -4.2376e-02,  2.5430e-01, -6.2962e-02, -1.1414e-01,\n",
       "                         1.9083e-01,  1.8348e-01, -4.9018e-01, -1.2815e-01, -6.9768e-02,\n",
       "                        -3.5908e-01,  8.1255e-02,  1.1136e-01,  8.9373e-02, -9.6393e-02,\n",
       "                         1.0296e-01],\n",
       "                       [-2.4364e-01, -1.1605e-01, -1.0786e-01, -2.2987e-01, -1.7964e-01,\n",
       "                         1.0144e-01, -1.1401e-01,  4.2392e-01, -1.6682e-01, -1.7839e-01,\n",
       "                         2.3792e-01, -1.4856e-02, -5.3604e-02, -9.8811e-02, -1.6469e-01,\n",
       "                        -1.1870e-01]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([-0.0202,  0.3662, -0.2392,  0.0479, -0.0090, -0.0977,  0.3740,  0.3738,\n",
       "                        0.1743, -0.0456, -0.1886, -0.0200, -0.1509, -0.2314,  0.3390,  0.4918])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[-0.0183, -0.3673, -0.0146, -0.1616, -0.0871,  0.0496, -0.2634, -0.1066,\n",
       "                         0.2617,  0.0118, -0.1808,  0.1062,  0.1837, -0.0741, -0.2109,  0.6205]])),\n",
       "              ('layers.8.bias', tensor([0.0706]))])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define quantiles and hyperparameters\n",
    "q_median = 0.5\n",
    "q_upper = 0.975\n",
    "q_lower = 0.025\n",
    "# dims = model['dims']\n",
    "dims = (2, 16, 16, 16, 16, 1)\n",
    "lr = model['lr']\n",
    "batch_size = int(model['batch_size'])\n",
    "epoch = model['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch size: 500\n",
      "epoch: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"lr:\", lr)\n",
    "print(\"batch size:\", batch_size)\n",
    "print(\"epoch:\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done C_WTG01\n",
      "Done C_WTG02\n",
      "Done C_WTG03\n",
      "Done C_WTG04\n",
      "Done C_WTG05\n",
      "Done C_WTG06\n",
      "Done C_WTG07\n",
      "Done C_WTG08\n",
      "Done C_WTG09\n",
      "Done C_WTG10\n",
      "Done C_WTG11\n",
      "Done C_WTG12\n",
      "Done C_WTG13\n",
      "Done C_WTG14\n",
      "Done C_WTG15\n",
      "Done C_WTG16\n",
      "Done C_WTG17\n",
      "Done C_WTG18\n",
      "Done C_WTG19\n",
      "Done C_WTG20\n",
      "Done C_WTG21\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################################### training ######################################################### \n",
    "\n",
    "turbines = data_finetune.instanceID.unique()\n",
    "median_state_dict_all = []\n",
    "UQ_state_dict_all = []\n",
    "LQ_state_dict_all = []\n",
    "\n",
    "\n",
    "for ID in turbines:\n",
    "    \n",
    "    # select data based on turbine ID\n",
    "    data_temp = data_finetune[data_finetune['instanceID'] == ID]\n",
    "\n",
    "    # normalize data\n",
    "    X = scaler1.transform(data_temp.iloc[:, 5:-1])\n",
    "    y = scaler2.transform(data_temp.iloc[:, -1:])\n",
    "    \n",
    "    # create network and load pretrain weights\n",
    "    net_median_temp = Net(dims = dims)\n",
    "    net_median_temp.load_state_dict(pretrain['median'])\n",
    "    \n",
    "    net_upper_temp = Net(dims = dims)\n",
    "    net_upper_temp.load_state_dict(pretrain['UQ'])\n",
    "    \n",
    "    net_lower_temp = Net(dims = dims)\n",
    "    net_lower_temp.load_state_dict(pretrain['LQ'])\n",
    "    \n",
    "    # train\n",
    "    net_median_temp, median_state_dict = train(X=X, y=y, quantile=q_median, net=net_median_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_upper_temp, UQ_state_dict = train(X=X, y=y, quantile=q_upper, net=net_upper_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_lower_temp, LQ_state_dict = train(X=X, y=y, quantile=q_lower, net=net_lower_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    \n",
    "    median_state_dict_all.append(median_state_dict)\n",
    "    UQ_state_dict_all.append(UQ_state_dict)\n",
    "    LQ_state_dict_all.append(LQ_state_dict)\n",
    "    \n",
    "    print('Done', ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_state_dict_all_zip = dict(zip(turbines, median_state_dict_all))\n",
    "UQ_state_dict_all_zip = dict(zip(turbines, UQ_state_dict_all))\n",
    "LQ_state_dict_all_zip = dict(zip(turbines, LQ_state_dict_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # save trained network\n",
    "\n",
    "# torch.save(median_state_dict_all_zip, sys.path[0] + '/median.pth')\n",
    "# torch.save(UQ_state_dict_all_zip, sys.path[0] + '/UQ.pth')\n",
    "# torch.save(LQ_state_dict_all_zip, sys.path[0] + '/LQ.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
