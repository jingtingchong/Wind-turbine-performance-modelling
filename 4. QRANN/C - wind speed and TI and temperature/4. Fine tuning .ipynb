{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from typing import Iterable\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from joblib import dump, load\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data_finetune = pd.read_csv(\"data_finetune.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>instanceID</th>\n",
       "      <th>Wind_speed</th>\n",
       "      <th>TI</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958671</th>\n",
       "      <td>2020-11-13 00:30:00</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>6.343173</td>\n",
       "      <td>15.312233</td>\n",
       "      <td>9.355000</td>\n",
       "      <td>496.738776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682500</th>\n",
       "      <td>2020-08-13 16:40:00</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>3.461359</td>\n",
       "      <td>17.919733</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>42.106780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827043</th>\n",
       "      <td>2020-09-30 11:50:00</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>3.595130</td>\n",
       "      <td>10.394158</td>\n",
       "      <td>10.966667</td>\n",
       "      <td>58.858180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278880</th>\n",
       "      <td>2020-04-02 05:20:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>16.338689</td>\n",
       "      <td>15.963571</td>\n",
       "      <td>6.796667</td>\n",
       "      <td>2043.203491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794451</th>\n",
       "      <td>2020-09-19 17:10:00</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>6.913757</td>\n",
       "      <td>8.228349</td>\n",
       "      <td>16.663334</td>\n",
       "      <td>614.239596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580775</th>\n",
       "      <td>2020-07-11 01:10:00</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.650944</td>\n",
       "      <td>14.949392</td>\n",
       "      <td>10.298334</td>\n",
       "      <td>830.078456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122912</th>\n",
       "      <td>2020-02-10 15:20:00</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.982645</td>\n",
       "      <td>19.118705</td>\n",
       "      <td>2.593333</td>\n",
       "      <td>825.983393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11129</th>\n",
       "      <td>2020-01-04 16:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.100355</td>\n",
       "      <td>13.664154</td>\n",
       "      <td>7.396552</td>\n",
       "      <td>653.990937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855014</th>\n",
       "      <td>2020-10-09 17:40:00</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>4.106625</td>\n",
       "      <td>28.984064</td>\n",
       "      <td>7.183333</td>\n",
       "      <td>166.245071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564836</th>\n",
       "      <td>2020-07-05 18:40:00</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>9.763854</td>\n",
       "      <td>11.476947</td>\n",
       "      <td>10.733333</td>\n",
       "      <td>1889.555786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ts  Month  Day  Hour instanceID  Wind_speed  \\\n",
       "958671  2020-11-13 00:30:00     11   13     0    C_WTG01    6.343173   \n",
       "682500  2020-08-13 16:40:00      8   13    16    C_WTG01    3.461359   \n",
       "827043  2020-09-30 11:50:00      9   30    11    C_WTG01    3.595130   \n",
       "278880  2020-04-02 05:20:00      4    2     5    C_WTG01   16.338689   \n",
       "794451  2020-09-19 17:10:00      9   19    17    C_WTG01    6.913757   \n",
       "...                     ...    ...  ...   ...        ...         ...   \n",
       "580775  2020-07-11 01:10:00      7   11     1    C_WTG21    6.650944   \n",
       "122912  2020-02-10 15:20:00      2   10    15    C_WTG21    6.982645   \n",
       "11129   2020-01-04 16:10:00      1    4    16    C_WTG21    6.100355   \n",
       "855014  2020-10-09 17:40:00     10    9    17    C_WTG21    4.106625   \n",
       "564836  2020-07-05 18:40:00      7    5    18    C_WTG21    9.763854   \n",
       "\n",
       "               TI  Temperature        Power  \n",
       "958671  15.312233     9.355000   496.738776  \n",
       "682500  17.919733    23.900000    42.106780  \n",
       "827043  10.394158    10.966667    58.858180  \n",
       "278880  15.963571     6.796667  2043.203491  \n",
       "794451   8.228349    16.663334   614.239596  \n",
       "...           ...          ...          ...  \n",
       "580775  14.949392    10.298334   830.078456  \n",
       "122912  19.118705     2.593333   825.983393  \n",
       "11129   13.664154     7.396552   653.990937  \n",
       "855014  28.984064     7.183333   166.245071  \n",
       "564836  11.476947    10.733333  1889.555786  \n",
       "\n",
       "[210000 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load normalization function \n",
    "scaler1 = load('scaler1.bin')\n",
    "scaler2 = load('scaler2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_count = data_finetune['instanceID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dims: Iterable[int], output_activation: nn.Module = None):\n",
    "        \"\"\"Creates a network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = dims[0]\n",
    "        self.out_size = dims[-1]\n",
    "        self.layers = self.make_seq(dims, output_activation)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_seq(dims: Iterable[int], output_activation: nn.Module) -> nn.Module:\n",
    "        \"\"\"Creates a sequential network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        :return (nn.Module): return created sequential layers\n",
    "        \"\"\"\n",
    "        mods = []\n",
    "\n",
    "        for i in range(len(dims) - 2):\n",
    "            mods.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            mods.append(nn.ReLU())\n",
    "\n",
    "        mods.append(nn.Linear(dims[-2], dims[-1]))\n",
    "        if output_activation:\n",
    "            mods.append(output_activation())\n",
    "        return nn.Sequential(*mods)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Computes a forward pass through the network\n",
    "\n",
    "        :param x (torch.Tensor): input tensor to feed into the network\n",
    "        :return (torch.Tensor): output computed by the network\n",
    "        \"\"\"\n",
    "        # Feedforward\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, quantile, net, lr, batch_size, epoch):    \n",
    "    \n",
    "    # create tensor dataset\n",
    "    train = TensorDataset(Tensor(X), Tensor(y))\n",
    "\n",
    "    # create data loader from dataset\n",
    "    trainset = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr = lr)\n",
    "        \n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for ep in range(epoch):\n",
    "\n",
    "        for t in trainset:\n",
    "            X_temp, y_temp = t\n",
    "            output = net(X_temp)\n",
    "            residual = y_temp - output\n",
    "            loss = Tensor.max(quantile*residual, (quantile-1)*residual).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return net, net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use a very low learning rate at this stage, because we are training on a dataset that is very small. This is to prevent the risk of overfitting very quickly if we apply large weight updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hyperparameters\n",
    "model = torch.load(sys.path[0] + '/hparams_finetune.pth')\n",
    "\n",
    "# load the pretrained weights\n",
    "pretrain = torch.load(sys.path[0] + '/pretrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median': OrderedDict([('layers.0.weight',\n",
       "               tensor([[-0.6934, -0.1782,  0.1139],\n",
       "                       [ 0.1297, -0.1491,  0.2334],\n",
       "                       [-0.2782,  0.1037, -0.0160],\n",
       "                       [-0.4199,  0.0642,  0.3406],\n",
       "                       [-0.5982, -0.0845,  0.0386],\n",
       "                       [ 0.0336,  0.0705,  0.2021],\n",
       "                       [-0.4348, -0.0809, -0.0234],\n",
       "                       [-0.2826, -0.1212,  0.3681],\n",
       "                       [-0.3156,  0.2249,  0.1606],\n",
       "                       [ 0.5576,  0.0397, -0.0183],\n",
       "                       [-0.2828,  0.1926,  0.1895],\n",
       "                       [ 0.3320,  0.0260, -0.0412],\n",
       "                       [-0.5285,  0.1406, -0.2217],\n",
       "                       [ 0.3128, -0.2808, -0.1001],\n",
       "                       [ 0.3667, -0.0926,  0.0011],\n",
       "                       [-0.2467, -0.3039,  0.2554]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.2494, -0.1198, -0.5109, -0.1858,  0.6825, -0.3242,  0.2908, -0.5944,\n",
       "                       -0.4814,  0.6288,  0.2538, -0.3921,  0.5720, -0.1652,  0.5424, -0.2327])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[-9.3185e-02, -1.2552e-01,  1.2752e-01, -3.2349e-02, -1.5121e-01,\n",
       "                         1.5392e-01, -2.7178e-01,  4.0968e-02, -1.3958e-01, -9.9734e-02,\n",
       "                         4.2838e-02, -3.1619e-01, -1.4946e-02, -2.3883e-02, -9.7026e-02,\n",
       "                         1.7854e-01],\n",
       "                       [ 1.0970e-01, -1.0020e-01,  2.9656e-01,  7.6575e-02,  1.0478e-01,\n",
       "                         1.3609e-02, -1.6319e-01,  6.3504e-02, -2.2112e-01,  2.0569e-02,\n",
       "                        -1.1066e-01, -6.9152e-01, -1.7724e-01, -1.0418e-02,  2.7911e-01,\n",
       "                         6.1629e-02],\n",
       "                       [-5.5912e-02,  3.4589e-02, -1.0275e-01, -9.5413e-02, -1.8183e-01,\n",
       "                        -2.8511e-03, -2.3836e-01,  1.7190e-01, -3.4907e-02,  4.0815e-02,\n",
       "                        -1.8326e-02, -1.5887e-01, -5.9887e-02,  1.1600e-01,  2.7212e-01,\n",
       "                        -1.9292e-01],\n",
       "                       [-1.7929e-01,  2.5456e-01, -9.9201e-02, -3.8461e-02,  1.0612e-01,\n",
       "                        -2.3168e-02,  3.5568e-02, -2.4488e-01,  1.5070e-01,  3.1621e-01,\n",
       "                        -4.2826e-02, -8.9981e-02, -1.5574e-01, -6.2557e-02,  8.7450e-02,\n",
       "                        -4.2493e-04],\n",
       "                       [ 2.7481e-02, -1.4085e-01, -4.4711e-02,  1.0677e-01,  2.4246e-01,\n",
       "                         2.6008e-02,  4.1028e-01,  1.1076e-01, -7.1021e-02, -1.0692e-01,\n",
       "                         1.6802e-01, -5.0680e-01, -5.5464e-02, -2.5183e-01, -1.5054e-01,\n",
       "                         7.5071e-02],\n",
       "                       [-1.2873e-01,  5.3939e-02,  1.0931e-01,  1.6444e-01, -1.1042e-01,\n",
       "                        -9.7334e-02,  8.1210e-02, -1.3678e-01,  4.8481e-04, -1.7967e-01,\n",
       "                        -2.8915e-01, -9.7058e-02,  2.0622e-01, -2.7696e-01, -6.0933e-02,\n",
       "                        -1.0878e-01],\n",
       "                       [ 3.2384e-01,  2.0572e-01,  3.7704e-01, -1.2825e-01,  2.4072e-01,\n",
       "                         6.6217e-02,  3.9773e-01, -8.0201e-02,  2.2221e-02, -2.9072e-01,\n",
       "                         8.2364e-03, -2.9331e-01,  1.8160e-01,  5.9200e-01, -8.2390e-02,\n",
       "                        -3.1111e-02],\n",
       "                       [ 1.7762e-01,  6.3046e-02, -8.8433e-02,  3.1658e-02,  3.2710e-01,\n",
       "                         1.1119e-01,  3.6706e-01, -7.0149e-02,  1.6357e-01, -1.9545e-01,\n",
       "                         1.3548e-01, -2.1996e-02,  2.7131e-01, -7.9118e-02, -1.6613e-01,\n",
       "                         5.8923e-02],\n",
       "                       [-1.4055e-01, -1.6463e-01, -5.3581e-01,  1.5824e-01, -3.3428e-01,\n",
       "                         4.7899e-01, -8.0086e-02,  1.3980e-01,  2.7094e-01,  1.7973e-01,\n",
       "                        -1.1645e-01,  3.5992e-02, -6.2140e-02,  1.1511e-01,  1.9375e-01,\n",
       "                        -2.1937e-01],\n",
       "                       [-2.2121e-01,  3.1534e-01,  4.3100e-02,  1.4122e-01, -1.7685e-01,\n",
       "                         9.3628e-02, -4.9449e-01,  1.8000e-01, -1.4798e-01, -2.2655e-01,\n",
       "                         1.2081e-01,  1.9340e-01, -1.4492e-01,  3.0970e-01,  1.8816e-01,\n",
       "                         3.0714e-01],\n",
       "                       [ 4.0749e-02, -2.5823e-02, -9.4840e-04,  1.6545e-01,  2.5992e-01,\n",
       "                         4.3248e-02,  2.6676e-01, -1.8402e-01, -7.4064e-02,  2.9250e-02,\n",
       "                         1.9326e-01, -5.2916e-01,  2.2672e-01, -3.4256e-01,  3.6148e-02,\n",
       "                        -8.4625e-02],\n",
       "                       [ 4.9724e-02, -2.2665e-03,  1.7535e-01,  1.9169e-01, -6.1733e-02,\n",
       "                         1.3411e-01,  1.1071e-01,  1.8306e-01,  1.1970e-02,  1.2555e-01,\n",
       "                        -2.3034e-01, -2.4793e-01, -1.4850e-01, -2.5001e-01, -1.7873e-01,\n",
       "                        -2.2305e-01],\n",
       "                       [ 1.7368e-01, -1.9692e-01, -1.9844e-01, -1.1173e-02, -1.0591e-01,\n",
       "                        -1.8839e-01,  3.7477e-02,  1.3351e-01,  1.0319e-01, -4.8394e-02,\n",
       "                         6.8516e-02, -3.0307e-01,  2.0885e-01, -2.5903e-01,  2.5566e-01,\n",
       "                        -2.0741e-02],\n",
       "                       [ 7.6037e-03, -1.7957e-01,  3.7314e-01,  1.0124e-01,  3.8957e-02,\n",
       "                        -8.5778e-02,  1.6897e-01, -2.1847e-02,  6.5669e-02, -6.5628e-01,\n",
       "                        -1.0443e-01, -2.2707e-01,  1.5930e-01, -1.8495e-02, -5.0897e-01,\n",
       "                         2.2427e-01],\n",
       "                       [-2.0841e-01, -6.2283e-02,  4.5109e-02, -3.8266e-02, -6.6863e-01,\n",
       "                         3.7155e-02, -3.7692e-01,  6.5031e-02,  5.1625e-02,  2.0256e-01,\n",
       "                         1.4219e-02, -7.8536e-03,  1.7687e-01, -6.8729e-02, -1.2997e-01,\n",
       "                         4.8787e-01],\n",
       "                       [-1.8849e-01,  1.6381e-01,  2.1533e-01,  3.5978e-02,  2.4135e-01,\n",
       "                         1.1969e-01, -1.2593e-01, -1.1015e-01,  1.8898e-01, -3.7627e-01,\n",
       "                        -9.3435e-02,  1.0834e-01,  2.0377e-01, -9.0886e-02,  9.2643e-02,\n",
       "                         4.3380e-02]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.0535,  0.1904,  0.5035,  0.1648,  0.5252,  0.0580, -0.0913,  0.3385,\n",
       "                        0.0189, -0.0960,  0.2464, -0.2544,  0.5312, -0.4169,  0.2628,  0.0631])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[-2.4864e-01,  3.2146e-02,  3.2003e-01,  7.2656e-02, -5.3996e-01,\n",
       "                        -5.2583e-02, -8.1959e-03, -3.1796e-01,  1.8649e-01, -1.4150e-01,\n",
       "                        -1.4271e-01, -4.0279e-03,  1.7924e-01,  1.3985e-01,  2.2847e-01,\n",
       "                        -5.1117e-02],\n",
       "                       [-2.0337e-01,  4.3947e-02,  3.3747e-01,  1.3867e-01, -3.8405e-01,\n",
       "                        -1.3150e-01, -9.9382e-02, -2.0899e-01,  1.6655e-01,  1.1579e-01,\n",
       "                         3.1076e-04,  8.7125e-02,  2.6461e-01, -2.5141e-01,  2.6404e-01,\n",
       "                        -5.5905e-02],\n",
       "                       [-2.1580e-01, -2.0300e-01, -1.8255e-01,  1.7633e-01, -2.5618e-02,\n",
       "                        -6.0506e-02, -9.9691e-03,  3.4904e-02, -1.2330e-01, -2.7157e-01,\n",
       "                        -4.1255e-02, -5.6011e-02, -3.5693e-01,  7.4945e-02, -1.6374e-01,\n",
       "                        -2.5876e-01],\n",
       "                       [ 1.4820e-01, -2.7653e-01,  4.3338e-02,  3.2579e-02,  1.4996e-01,\n",
       "                        -2.5046e-01, -7.1042e-02,  2.5163e-02, -1.8380e-01, -9.2254e-02,\n",
       "                         1.0907e-01,  1.3657e-01,  1.7296e-01, -4.5600e-01, -2.0373e-02,\n",
       "                        -5.4457e-02],\n",
       "                       [ 1.4201e-01, -3.4397e-02,  1.1677e-01,  7.6813e-02,  7.3742e-02,\n",
       "                        -1.7695e-01, -1.8891e-01, -3.2911e-01, -8.8391e-02, -2.7596e-01,\n",
       "                        -2.4442e-02,  1.8013e-01,  3.1008e-01,  1.3016e-02, -1.8491e-01,\n",
       "                         1.1052e-01],\n",
       "                       [-4.6679e-02,  2.4750e-01, -2.6117e-01,  5.0244e-02,  3.9432e-01,\n",
       "                         7.8725e-02,  1.5296e-01,  3.8993e-01, -2.0836e-01, -4.6990e-01,\n",
       "                         2.9990e-01, -9.0009e-02,  2.1396e-02, -2.2248e-01, -9.2257e-02,\n",
       "                         1.3117e-01],\n",
       "                       [ 1.0148e-01, -2.6697e-01, -2.9226e-01,  7.9332e-02,  1.1341e-01,\n",
       "                        -2.1517e-02,  8.9511e-03, -1.4702e-01,  1.7072e-01, -3.2892e-01,\n",
       "                         1.8369e-01, -3.2393e-02, -2.3084e-01,  7.0146e-02,  1.1403e-01,\n",
       "                         6.1731e-02],\n",
       "                       [-2.2338e-01,  5.0472e-02,  1.5337e-02, -1.7198e-01,  8.5995e-03,\n",
       "                        -2.8958e-02,  1.9097e-01, -2.2592e-01,  7.4156e-02, -2.8798e-02,\n",
       "                         8.9759e-02,  2.0349e-01, -1.5231e-01,  1.7421e-01, -1.9846e-01,\n",
       "                        -5.2071e-02],\n",
       "                       [-6.8040e-02,  1.0370e-01,  1.4804e-01, -8.1485e-02, -2.2367e-01,\n",
       "                         1.2694e-01,  1.2435e-01, -2.2150e-02, -5.1156e-02, -1.8692e-01,\n",
       "                        -6.9119e-03,  1.7987e-02,  2.0494e-01, -4.4228e-01,  2.9671e-02,\n",
       "                        -5.0827e-02],\n",
       "                       [-2.6862e-01,  1.5383e-01,  2.2090e-01,  3.6686e-01, -2.4096e-01,\n",
       "                        -8.2847e-02, -2.0078e-01, -2.3109e-01,  6.6702e-02, -2.5184e-02,\n",
       "                         1.6652e-01, -2.6817e-01,  3.9087e-01,  2.9126e-01,  2.0466e-02,\n",
       "                        -3.4529e-02],\n",
       "                       [ 1.4101e-01, -2.1006e-01,  1.6437e-01,  4.9622e-03,  4.8300e-02,\n",
       "                         1.2419e-01, -2.6567e-01, -1.6704e-01, -1.9678e-01, -2.2663e-02,\n",
       "                         1.9972e-01, -8.0038e-02, -5.4329e-02, -3.2241e-02,  4.3233e-02,\n",
       "                         1.4106e-01],\n",
       "                       [ 1.8248e-01,  2.4711e-01,  1.5455e-01,  1.4995e-01, -5.8910e-01,\n",
       "                         4.8923e-02, -3.2792e-02, -4.3731e-01, -1.4902e-01,  6.8151e-02,\n",
       "                        -8.4698e-01,  2.5618e-02,  6.5766e-02,  1.8305e-01, -2.7280e-01,\n",
       "                         1.1122e-01],\n",
       "                       [-8.2163e-02,  1.2196e-01,  2.4293e-01,  9.2891e-02, -2.7274e-01,\n",
       "                         6.9581e-02,  7.9800e-02, -2.1783e-01,  1.9886e-01, -1.1078e-01,\n",
       "                         9.7505e-02, -1.7853e-01,  1.9245e-01, -1.0077e-01,  9.8709e-02,\n",
       "                         4.4577e-02],\n",
       "                       [-1.3485e-01,  1.2302e-01,  8.9171e-02, -1.6533e-01,  8.7271e-02,\n",
       "                         1.5787e-01,  7.6810e-02,  2.9044e-01, -3.5105e-01, -4.5123e-01,\n",
       "                         5.4793e-02, -7.6527e-02,  2.6852e-01, -3.2653e-01, -9.2771e-02,\n",
       "                         2.2971e-01],\n",
       "                       [ 1.2134e-01,  1.9897e-01,  2.7204e-01,  3.4512e-02, -5.6078e-01,\n",
       "                         1.9790e-01, -5.3213e-01, -3.4477e-01, -1.9895e-01,  2.1631e-01,\n",
       "                        -3.7521e-01,  1.9673e-01, -1.2562e-01, -3.2208e-02,  2.0484e-01,\n",
       "                         7.2935e-02],\n",
       "                       [ 1.3830e-01, -1.7867e-01, -1.3085e-01, -1.5134e-01,  2.3936e-01,\n",
       "                         1.7488e-01,  3.4606e-01, -1.4772e-02,  6.0167e-02,  5.6250e-03,\n",
       "                         9.5358e-02, -1.7110e-01,  2.0278e-01, -3.6042e-02, -1.9668e-01,\n",
       "                        -7.7198e-02]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.4063,  0.2573, -0.1774, -0.1858,  0.6326,  0.2563, -0.1421, -0.1197,\n",
       "                        0.0829,  0.1883, -0.3317,  0.1363,  0.0593,  0.2018,  0.3975,  0.1685])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[ 4.6075e-01,  3.2641e-01,  1.7957e-01, -4.4623e-02,  2.2644e-01,\n",
       "                        -1.0858e-01, -1.3234e-01,  1.2930e-01,  2.4199e-01,  3.7681e-01,\n",
       "                        -1.6391e-01,  2.1303e-01,  1.3067e-01, -1.0024e-01,  3.0029e-01,\n",
       "                        -1.4165e-01],\n",
       "                       [-2.0699e-01, -6.0729e-03, -2.3427e-01, -1.7612e-01, -6.4784e-02,\n",
       "                         1.5100e-01,  1.4962e-01, -5.9490e-02,  8.9927e-02,  7.7024e-02,\n",
       "                         1.7212e-01, -1.6745e-01, -2.9274e-01, -7.6833e-02, -1.8822e-01,\n",
       "                         1.8992e-02],\n",
       "                       [ 5.3232e-02, -1.0651e-01,  2.3429e-01,  9.7444e-02, -1.8816e-01,\n",
       "                        -1.9372e-01, -4.0689e-02,  1.7008e-01,  3.9744e-02, -2.4869e-01,\n",
       "                         1.2179e-02, -1.1899e-01, -1.2841e-01, -7.9793e-03, -2.2087e-01,\n",
       "                        -1.7226e-01],\n",
       "                       [-1.5633e-01, -2.4808e-01, -1.0510e-02, -3.5183e-02, -3.9469e-01,\n",
       "                         6.1472e-02, -9.6863e-02, -7.5919e-02, -2.4925e-01,  5.1652e-02,\n",
       "                         1.3182e-01,  6.5973e-02, -2.2801e-01, -2.3861e-01,  1.0543e-01,\n",
       "                        -2.3041e-01],\n",
       "                       [ 4.0967e-01,  3.6637e-01, -1.4055e-01,  1.3539e-01,  2.6942e-01,\n",
       "                        -2.3585e-01, -1.2082e-01,  2.2044e-01,  8.2790e-03,  5.0852e-02,\n",
       "                         2.1190e-01,  3.3633e-01,  2.9458e-01, -8.5534e-02,  5.0749e-01,\n",
       "                        -1.8896e-01],\n",
       "                       [ 3.7971e-02,  2.2034e-01,  1.3109e-01, -1.5900e-01, -6.3552e-02,\n",
       "                         3.3813e-01, -6.3565e-02,  5.2941e-02,  9.8041e-02,  6.9369e-02,\n",
       "                        -1.2642e-01, -2.4350e-01,  8.3026e-02,  3.2557e-01, -1.0005e-01,\n",
       "                        -1.0851e-02],\n",
       "                       [-7.5479e-02, -1.1774e-01, -1.7942e-01, -1.5658e-01, -1.3323e-01,\n",
       "                         8.1163e-02, -1.8139e-01, -1.6127e-01,  1.3129e-01,  5.2076e-03,\n",
       "                        -1.7981e-01, -2.5968e-01,  4.1608e-02, -1.0776e-01,  2.0316e-01,\n",
       "                         1.3941e-02],\n",
       "                       [-1.4764e-01,  1.5820e-02, -2.6227e-01,  8.9600e-02,  8.4112e-02,\n",
       "                         1.8739e-01,  6.3405e-02,  1.8541e-01, -5.3310e-02, -2.2380e-01,\n",
       "                        -1.8428e-01, -4.5447e-01, -4.0512e-02,  3.4446e-02,  1.4076e-01,\n",
       "                         2.2329e-01],\n",
       "                       [ 2.5333e-01,  2.2911e-01, -5.8395e-03, -4.0293e-02,  8.6768e-02,\n",
       "                        -1.9803e-02,  1.6333e-01,  8.9665e-02,  2.3974e-01,  1.2135e-01,\n",
       "                        -4.8529e-02,  3.7029e-02, -2.1405e-02,  4.4901e-02,  1.8079e-01,\n",
       "                         1.2527e-02],\n",
       "                       [-9.1097e-03, -3.1583e-01, -3.1333e-02, -5.3523e-02,  1.5658e-01,\n",
       "                         2.5385e-01, -1.1645e-01,  5.1728e-02,  1.8648e-01, -7.1989e-02,\n",
       "                         1.7798e-01, -2.3397e-01,  1.0341e-02, -9.6760e-02, -2.3382e-01,\n",
       "                         9.0035e-03],\n",
       "                       [ 1.0899e-01, -3.6998e-02, -1.7580e-02, -2.4901e-01, -1.1602e-01,\n",
       "                         1.9423e-02, -2.1920e-01, -2.2250e-01,  1.9292e-01, -1.3768e-01,\n",
       "                         1.4870e-01, -2.9903e-02, -2.4711e-01, -5.2206e-02,  1.2716e-01,\n",
       "                        -2.1515e-01],\n",
       "                       [-4.6136e-02, -1.2146e-01,  2.8852e-02,  1.0203e-01,  1.5539e-01,\n",
       "                         3.6647e-01,  1.1961e-01, -2.6536e-02,  1.7620e-01, -2.1670e-01,\n",
       "                        -2.4653e-01, -3.6492e-01,  6.7567e-02,  2.9842e-01, -2.0385e-01,\n",
       "                         2.4826e-01],\n",
       "                       [-5.1354e-02, -2.1540e-01, -1.5080e-01,  1.2750e-02,  3.5888e-02,\n",
       "                         8.2740e-02, -1.9059e-01,  4.5966e-03, -1.7997e-01,  1.2404e-01,\n",
       "                         4.5273e-02, -2.5216e-01,  1.4114e-01, -1.9658e-01,  3.3054e-02,\n",
       "                         2.5456e-02],\n",
       "                       [-6.1210e-02, -9.3619e-02,  2.2724e-01, -4.9821e-04, -1.4583e-01,\n",
       "                        -2.0311e-01, -1.4383e-01, -1.8683e-01, -7.6408e-02,  1.2626e-01,\n",
       "                        -1.5602e-02,  2.4900e-01,  4.1297e-02,  1.3204e-01, -2.3457e-03,\n",
       "                         1.0187e-02],\n",
       "                       [-1.8151e-01, -2.4897e-01, -2.7592e-01,  9.0831e-02,  1.0511e-01,\n",
       "                         6.4096e-02,  7.9016e-02,  7.4856e-02,  2.1511e-01,  2.1855e-02,\n",
       "                        -2.1928e-01, -5.0337e-01,  6.3906e-02,  2.8603e-01, -1.3126e-01,\n",
       "                         8.2029e-03],\n",
       "                       [ 6.8401e-02,  1.6723e-01,  1.8068e-01, -3.2507e-02, -1.0582e-01,\n",
       "                        -2.7522e-01, -7.3736e-02,  2.8272e-02, -2.8931e-02, -1.3652e-01,\n",
       "                        -2.2280e-01, -2.1048e-02,  5.0990e-02,  1.8341e-01, -2.3026e-01,\n",
       "                         1.9565e-02]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.4504, -0.3252, -0.1619, -0.3137,  0.4733, -0.2074, -0.0843,  0.2417,\n",
       "                       -0.0005,  0.3104, -0.1332,  0.2321, -0.1173, -0.2143,  0.2777, -0.0977])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[ 0.4375,  0.0782, -0.0497, -0.0987,  0.3334, -0.2041,  0.1243, -0.2425,\n",
       "                         0.1481, -0.1358, -0.1144, -0.2527,  0.1286,  0.1774, -0.1656,  0.1852]])),\n",
       "              ('layers.8.bias', tensor([-0.0007]))]),\n",
       " 'UQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[-0.3781,  0.0721,  0.0314],\n",
       "                       [-0.5171, -0.0620, -0.5287],\n",
       "                       [ 0.3446, -0.1210,  0.0747],\n",
       "                       [-0.1550, -0.3372, -0.3488],\n",
       "                       [ 0.1464, -0.3079,  0.0695],\n",
       "                       [-0.3921,  0.0826,  0.0093],\n",
       "                       [-0.5988, -0.0237, -0.1486],\n",
       "                       [-0.9224, -0.1787,  0.0710],\n",
       "                       [-0.4047, -0.2602,  0.1639],\n",
       "                       [ 0.1308,  0.0565,  0.0533],\n",
       "                       [ 0.0508,  0.0516,  0.3035],\n",
       "                       [ 0.2139, -0.0365, -0.1996],\n",
       "                       [-0.3469,  0.0391,  0.0945],\n",
       "                       [-0.3332, -0.0442, -0.3558],\n",
       "                       [-0.4406,  0.1858,  0.0423],\n",
       "                       [-0.7148, -0.0841,  0.0275]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.4939, -0.3004,  0.2687, -0.1376,  0.0198,  0.7015,  0.5204,  0.3121,\n",
       "                       -0.2366,  0.1253, -0.5889,  0.2695,  0.5885,  0.0978, -0.3318,  0.5683])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[ 8.5722e-02,  3.2998e-02, -7.1080e-02, -1.3088e-01, -2.0130e-01,\n",
       "                        -3.7294e-01,  5.2704e-02,  1.4555e-01,  7.7336e-02,  1.0148e-01,\n",
       "                        -9.0045e-02, -1.5951e-01,  9.4910e-02, -1.6776e-01,  1.6929e-01,\n",
       "                        -3.3909e-01],\n",
       "                       [ 1.2861e-01, -1.8286e-01,  8.3030e-02,  1.0428e-01,  1.8000e-01,\n",
       "                         6.6102e-02,  2.4079e-01, -3.9200e-01,  1.9372e-02,  1.0750e-01,\n",
       "                         3.1553e-01,  2.1286e-01,  2.3438e-03, -4.9039e-02, -3.4449e-01,\n",
       "                        -2.5833e-01],\n",
       "                       [-2.3939e-01, -3.0256e-01, -7.4748e-02,  9.8755e-02, -1.2297e-01,\n",
       "                        -2.8485e-01,  6.1611e-02,  1.7263e-01,  7.7869e-02, -1.3171e-02,\n",
       "                        -9.2682e-02, -8.6715e-02, -2.6873e-01,  3.2200e-02,  9.6775e-03,\n",
       "                         2.1686e-01],\n",
       "                       [-2.5339e-01,  8.6014e-02, -2.3198e-01, -1.7289e-01, -3.5372e-02,\n",
       "                        -2.5719e-02, -2.1338e-01,  5.3273e-02,  5.2890e-02,  7.0568e-02,\n",
       "                        -2.4306e-01,  8.3932e-03, -3.0867e-02,  8.6170e-02, -3.5502e-02,\n",
       "                        -1.4729e-01],\n",
       "                       [ 2.7782e-01,  4.0145e-02, -6.6319e-02,  1.9742e-02,  6.8141e-02,\n",
       "                         4.5686e-01,  3.9311e-01,  3.1484e-01,  2.2983e-01,  1.8981e-01,\n",
       "                         5.3865e-02,  1.1153e-01,  3.3271e-01,  4.8146e-02,  8.8109e-02,\n",
       "                         4.1052e-01],\n",
       "                       [ 1.8960e-01, -1.8899e-01, -3.1521e-01,  1.2205e-01, -1.2616e-01,\n",
       "                         7.1368e-02, -1.6684e-01,  6.3078e-02, -3.6274e-01, -4.7140e-02,\n",
       "                        -1.6862e-01, -4.0810e-01, -3.0252e-02,  1.0761e-01, -8.5045e-02,\n",
       "                         2.8029e-01],\n",
       "                       [ 9.7894e-02, -5.6919e-02, -2.0301e-01,  2.3179e-01, -1.8112e-01,\n",
       "                        -3.4076e-02, -2.8835e-01, -5.1736e-01, -1.9995e-01,  2.0741e-02,\n",
       "                        -1.1246e+00, -7.5356e-02, -2.8797e-01,  4.1461e-01,  5.6820e-01,\n",
       "                        -4.8801e-01],\n",
       "                       [-1.5407e-01,  7.1297e-02, -1.8852e-01, -2.4705e-01,  1.7243e-02,\n",
       "                        -4.1070e-01,  6.1665e-02, -1.8850e-01,  7.3708e-02, -5.6801e-04,\n",
       "                         1.4722e-01,  5.8662e-02, -2.1148e-01, -2.2204e-01,  5.0930e-02,\n",
       "                        -1.2863e-01],\n",
       "                       [-2.3627e-01, -1.1984e-01,  6.4962e-03, -2.0485e-01, -1.0595e-01,\n",
       "                        -2.6249e-02,  1.2661e-02, -2.0088e-01, -8.5981e-02,  1.9215e-01,\n",
       "                         3.1061e-01,  1.4557e-01, -4.3598e-03, -4.0354e-02, -2.6133e-01,\n",
       "                         3.4540e-02],\n",
       "                       [ 1.6276e-01, -2.3500e-01, -4.9924e-02,  1.9172e-01,  7.8845e-02,\n",
       "                        -3.9857e-02, -2.3353e-01, -1.8153e-02, -1.1408e-01,  2.4000e-01,\n",
       "                        -1.7983e-01,  1.1673e-02,  2.3660e-01, -1.6080e-02,  4.4382e-02,\n",
       "                        -1.6662e-01],\n",
       "                       [ 1.0598e-01, -3.2982e-01, -1.6759e-02,  1.0503e-01,  3.0535e-01,\n",
       "                        -3.6357e-01,  1.8854e-01, -1.1417e-01, -1.7637e-01, -1.4351e-02,\n",
       "                         1.2072e-01,  3.1244e-01,  1.9043e-01,  1.2217e-01, -5.6897e-02,\n",
       "                        -2.9377e-01],\n",
       "                       [ 7.6424e-02, -3.8909e-01,  1.4930e-01,  9.4044e-02, -1.0445e-01,\n",
       "                        -2.0941e-01,  2.4501e-02,  9.3193e-02,  2.4672e-02, -2.7064e-02,\n",
       "                         2.9668e-01, -3.0051e-01,  1.5770e-01, -1.6658e-01,  4.4124e-02,\n",
       "                         2.0104e-01],\n",
       "                       [-7.5094e-02,  4.1268e-02,  1.2381e-01,  1.7012e-01,  1.7508e-01,\n",
       "                        -2.9497e-01, -1.8058e-01, -4.0399e-01,  1.2801e-01,  1.9915e-01,\n",
       "                         7.5607e-02, -9.2300e-02, -6.9445e-03,  2.5155e-01,  4.2727e-01,\n",
       "                        -2.0774e-01],\n",
       "                       [-2.2345e-01,  1.5164e-02, -3.4289e-02, -2.5911e-01,  5.4966e-02,\n",
       "                        -8.3752e-02, -9.8611e-02, -6.3195e-02,  1.2615e-01, -1.3292e-01,\n",
       "                        -1.8524e-01,  1.5707e-01, -1.2975e-01,  4.8641e-02, -2.3613e-01,\n",
       "                         2.1422e-01],\n",
       "                       [ 3.0031e-01, -2.2752e-01, -2.2830e-01,  1.0745e-01,  2.1307e-01,\n",
       "                         1.6657e-01,  2.7392e-01, -2.2730e-01, -3.3154e-01, -2.7973e-01,\n",
       "                        -2.0054e-02, -7.8496e-02,  3.3509e-01,  3.2854e-02, -3.8441e-01,\n",
       "                         3.3988e-01],\n",
       "                       [ 3.0302e-03, -9.8509e-03, -9.9317e-02,  1.6104e-01, -9.8623e-02,\n",
       "                        -2.4014e-01, -6.3965e-02, -1.2277e-01, -1.2055e-01, -1.1464e-01,\n",
       "                        -2.4153e-01, -7.0544e-02, -5.8203e-02, -2.1064e-01,  2.0700e-03,\n",
       "                         1.5004e-01]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.4816,  0.4065, -0.1515, -0.1669, -0.1282, -0.1382,  0.1431, -0.4126,\n",
       "                        0.3992,  0.1179,  0.4398, -0.0755,  0.0349, -0.2564,  0.2963, -0.1373])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[ 0.1232,  0.1954,  0.2181,  0.2601, -0.1481, -0.1620,  0.2588, -0.1708,\n",
       "                         0.1344,  0.1778,  0.1110,  0.2792,  0.1371,  0.1614, -0.0510,  0.2058],\n",
       "                       [ 0.0753, -0.0754, -0.1177, -0.2281, -0.0426, -0.2681, -0.0333, -0.0191,\n",
       "                         0.0636, -0.2922,  0.1515, -0.6198, -0.2986,  0.1848, -0.0659,  0.1492],\n",
       "                       [ 0.2848, -0.0152, -0.1054, -0.1419, -0.3059, -0.0963, -0.0767,  0.0230,\n",
       "                        -0.0109,  0.0774,  0.3568,  0.2881,  0.1776,  0.0120,  0.1019, -0.1274],\n",
       "                       [-0.2664,  0.0797, -0.1726,  0.0660, -0.2639,  0.1107, -0.1767,  0.1651,\n",
       "                        -0.0055, -0.2011, -0.2045,  0.0074, -0.0468,  0.0846, -0.2508,  0.0816],\n",
       "                       [ 0.1516,  0.0212,  0.1013,  0.0019, -0.0296, -0.1722, -0.1096,  0.1833,\n",
       "                        -0.0769,  0.0819,  0.2832, -0.0661, -0.0418, -0.1395, -0.2079, -0.0694],\n",
       "                       [-0.2770, -0.0999, -0.2143, -0.0697,  0.3010, -0.0069, -0.2297,  0.1627,\n",
       "                        -0.1299,  0.2676,  0.0818, -0.0052,  0.1576, -0.0916,  0.1925, -0.0959],\n",
       "                       [-0.1563, -0.5674, -0.1688, -0.0230,  0.1299,  0.2778,  0.1038,  0.0359,\n",
       "                        -0.7693,  0.2172, -0.2567,  0.0520, -0.0254,  0.0959, -0.2819, -0.1710],\n",
       "                       [ 0.2260, -0.0056, -0.1181, -0.1561,  0.4911, -0.0758, -0.1229, -0.1135,\n",
       "                        -0.0331,  0.1087, -0.1094,  0.0421,  0.2363,  0.2392,  0.3303, -0.0690],\n",
       "                       [ 0.2246, -0.0151, -0.0540, -0.0708,  0.5114, -0.1284,  0.4588, -0.1168,\n",
       "                        -0.2193, -0.1017, -0.2696,  0.2996, -0.4280,  0.0372,  0.2822,  0.1304],\n",
       "                       [ 0.3646,  0.2053, -0.0658,  0.0500, -0.3206, -0.2017,  0.2952,  0.2270,\n",
       "                         0.1507,  0.1766, -0.1000, -0.1273,  0.2547,  0.2107,  0.4185,  0.1692],\n",
       "                       [ 0.4883, -0.5178, -0.2015, -0.1002, -0.0594,  0.2120, -0.5932, -0.0853,\n",
       "                        -0.2721,  0.0668, -0.4328, -0.2944,  0.0103,  0.1448,  0.2690,  0.1967],\n",
       "                       [ 0.2337,  0.3234, -0.1494,  0.0907, -0.2057, -0.1009,  0.4206,  0.0718,\n",
       "                         0.1638,  0.1969,  0.1085, -0.2032,  0.2950, -0.0332,  0.2538,  0.0032],\n",
       "                       [ 0.1804, -0.1284, -0.1486, -0.2479, -0.1450,  0.0147, -0.2637, -0.1729,\n",
       "                        -0.0168,  0.0657, -0.2093,  0.1762, -0.1607, -0.1648, -0.0655, -0.0503],\n",
       "                       [ 0.1432, -0.0421, -0.1027, -0.0636, -0.0160,  0.0014, -0.0033,  0.1946,\n",
       "                        -0.2407,  0.0745, -0.3019,  0.1454,  0.2317,  0.0032, -0.3124, -0.2445],\n",
       "                       [ 0.4892,  0.3240, -0.0694,  0.1732, -0.1401, -0.0847, -0.0713,  0.0232,\n",
       "                        -0.1851,  0.1281,  0.0040, -0.2291, -0.1830, -0.2163,  0.0084,  0.1170],\n",
       "                       [ 0.0010, -0.2264,  0.1302, -0.0166,  0.0124, -0.2436, -0.0463,  0.1206,\n",
       "                         0.0101, -0.2488,  0.0918,  0.0847,  0.1725, -0.0870, -0.0384, -0.2485]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.1708,  0.1717,  0.4994, -0.0227,  0.3485,  0.0858, -0.1727,  0.0957,\n",
       "                        0.2381,  0.2532,  0.2071,  0.3218, -0.0305,  0.0928,  0.1446, -0.1860])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[ 0.2029, -0.0091,  0.3916, -0.0443,  0.2962,  0.0265, -0.1770, -0.3732,\n",
       "                         0.0904,  0.1855,  0.1279,  0.3138,  0.1135, -0.0178,  0.1845, -0.0149],\n",
       "                       [-0.1477, -0.0254,  0.2896,  0.1373,  0.0464,  0.2613, -0.2840, -0.2769,\n",
       "                        -0.0150, -0.0555,  0.0276,  0.1380,  0.1440, -0.1681,  0.0787,  0.2511],\n",
       "                       [ 0.0844,  0.0674,  0.3032, -0.1573,  0.1522, -0.3200, -0.6783, -0.0133,\n",
       "                        -0.2936,  0.1212, -0.3274,  0.0750, -0.2031,  0.0828,  0.1107, -0.0696],\n",
       "                       [ 0.0261, -0.2652,  0.0871, -0.1730,  0.0363,  0.0456, -0.0799,  0.0635,\n",
       "                        -0.0869, -0.2881, -0.2197, -0.2841,  0.1912, -0.0774,  0.1429, -0.0815],\n",
       "                       [-0.1100, -0.1175,  0.2834,  0.2428,  0.1113, -0.3231, -0.2641, -0.3543,\n",
       "                        -0.2687, -0.0137,  0.2430,  0.3195, -0.0581,  0.0471,  0.2787,  0.0808],\n",
       "                       [-0.1088, -0.1781,  0.0517,  0.1265,  0.0918,  0.1807, -0.0751, -0.1815,\n",
       "                         0.0905, -0.5495, -0.0496, -0.0845, -0.0737, -0.0650, -0.3664, -0.1878],\n",
       "                       [ 0.0089, -0.1135,  0.0734, -0.0528, -0.2893,  0.0097,  0.2301, -0.0499,\n",
       "                         0.0516,  0.0474, -0.2531, -0.2432, -0.1705,  0.0112,  0.0730, -0.1789],\n",
       "                       [-0.2652, -0.0262, -0.1689,  0.1003, -0.0509, -0.0060, -0.2418, -0.1905,\n",
       "                        -0.0888, -0.1202,  0.1010,  0.0240, -0.2839, -0.0292,  0.1196,  0.1896],\n",
       "                       [-0.2597,  0.0023, -0.2476,  0.0096, -0.1220, -0.0901, -0.0651, -0.1593,\n",
       "                        -0.2160,  0.1234, -0.2447, -0.0666, -0.1053,  0.0508, -0.3402, -0.1009],\n",
       "                       [ 0.1184, -0.1602, -0.0626,  0.1860,  0.2698,  0.0312,  0.1611, -0.0700,\n",
       "                        -0.9035,  0.0151,  0.2853,  0.2586,  0.0547, -0.0530,  0.0294, -0.0479],\n",
       "                       [-0.2466,  0.0790, -0.3690, -0.0347, -0.2870,  0.3175, -0.0374,  0.3573,\n",
       "                         0.5300, -0.3088,  0.2691,  0.1165,  0.2228,  0.0297, -0.0152, -0.0944],\n",
       "                       [-0.0762, -0.1061,  0.2990,  0.0690,  0.3218,  0.0264, -0.1337, -0.4233,\n",
       "                        -0.9298,  0.1889, -0.0463,  0.1397,  0.0765,  0.1316, -0.1685, -0.1311],\n",
       "                       [ 0.2812,  0.2212,  0.0212,  0.0885, -0.0426,  0.1216, -0.1195, -0.3877,\n",
       "                        -0.0250,  0.3517,  0.0849,  0.0600,  0.1041,  0.0211,  0.0831, -0.1965],\n",
       "                       [ 0.0308, -0.0656, -0.0677, -0.2194,  0.1757, -0.0491,  0.0828, -0.1826,\n",
       "                        -0.0400, -0.2431,  0.1357,  0.0022,  0.0713,  0.2142,  0.0580,  0.0515],\n",
       "                       [-0.0023,  0.2459,  0.2748,  0.0793, -0.0908,  0.1471, -0.0311, -0.4165,\n",
       "                         0.0447,  0.1608, -0.1455,  0.3844,  0.0104,  0.1914, -0.0088, -0.1543],\n",
       "                       [-0.2292, -0.0560,  0.1368,  0.0496, -0.0631,  0.3501, -0.0587,  0.3287,\n",
       "                        -0.0453, -0.3384,  0.1781, -0.0419,  0.1098,  0.1417, -0.1843,  0.1095]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.3522,  0.0447,  0.3873, -0.2665,  0.3603, -0.0918, -0.2498, -0.0222,\n",
       "                        0.0838,  0.0019,  0.4055,  0.3644,  0.3231, -0.1573,  0.2645,  0.0637])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[ 0.3145,  0.0443,  0.3350, -0.0484,  0.2526,  0.0245, -0.0893, -0.1261,\n",
       "                         0.0328,  0.0590, -0.3980,  0.2082,  0.2588, -0.1265,  0.2272, -0.2276]])),\n",
       "              ('layers.8.bias', tensor([0.2997]))]),\n",
       " 'LQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[ 0.6867, -0.0196, -0.0528],\n",
       "                       [ 0.2928,  0.1640, -0.3091],\n",
       "                       [ 0.1954, -0.4318,  0.0959],\n",
       "                       [-0.8542, -0.1183, -0.0490],\n",
       "                       [-0.5906, -0.1082, -0.0143],\n",
       "                       [-0.2154, -0.0596,  0.2088],\n",
       "                       [-0.6100,  0.0744,  0.1082],\n",
       "                       [ 0.8124, -0.1206, -0.1235],\n",
       "                       [ 0.4441, -0.0208,  0.0502],\n",
       "                       [ 0.1671,  0.3805,  0.1159],\n",
       "                       [ 0.1027, -0.1643, -0.1283],\n",
       "                       [-0.1229, -0.1044, -0.3109],\n",
       "                       [-0.2125,  0.0920, -0.0635],\n",
       "                       [-0.5986, -0.1924,  0.0948],\n",
       "                       [-0.2040, -0.5075, -0.1104],\n",
       "                       [-0.1144, -0.0189, -0.4046]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([-0.0271, -0.4348, -0.7391,  0.1949,  0.5218, -0.0268,  0.5465, -0.6723,\n",
       "                        0.5178,  0.3936, -0.1974,  0.3443,  0.5393,  0.6145, -0.5844, -0.4968])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[-1.9032e-01, -1.5638e-01, -2.6699e-01,  2.8610e-01,  7.4163e-02,\n",
       "                         4.6010e-01,  1.3447e-01, -2.6435e-01, -4.5773e-01, -1.6140e-01,\n",
       "                        -1.8051e-02, -1.1374e-01,  1.4139e-02, -3.2951e-02,  2.6915e-01,\n",
       "                        -5.0374e-02],\n",
       "                       [-2.8623e-02,  1.1158e-02, -1.7275e-01, -2.2013e-01,  1.4497e-01,\n",
       "                        -6.6482e-02,  1.8587e-01, -5.7325e-04,  3.4942e-02, -2.4966e-01,\n",
       "                        -9.8337e-02, -1.4305e-01, -2.3041e-01, -1.8261e-01,  8.9435e-02,\n",
       "                         2.5757e-02],\n",
       "                       [ 1.6841e-01,  1.2342e-01,  2.2416e-01, -3.7988e-02, -2.8874e-01,\n",
       "                         1.5978e-02, -1.9624e-01,  4.8263e-01,  3.6965e-01,  2.4619e-01,\n",
       "                         2.6454e-02, -1.5527e-02, -3.2308e-01, -7.3285e-02, -1.8277e-01,\n",
       "                        -4.2833e-01],\n",
       "                       [-1.3701e-01, -5.2762e-01, -8.7829e-02,  3.2858e-01, -2.6619e-02,\n",
       "                        -2.7013e-01,  3.2907e-01, -3.8610e-01,  2.2158e-01, -1.4924e-01,\n",
       "                        -2.4301e-01,  2.0719e-01,  1.3933e-01, -1.6481e-02,  9.4695e-02,\n",
       "                        -1.1573e-01],\n",
       "                       [-3.1587e-01, -1.3979e-01, -9.4831e-02,  6.0389e-01,  2.4696e-01,\n",
       "                        -5.2148e-02,  2.6274e-01, -3.6282e-01, -8.4339e-01, -1.0369e-01,\n",
       "                        -1.9735e-01, -2.3801e-01, -1.8394e-01, -3.4090e-02, -1.6322e-01,\n",
       "                         1.7768e-01],\n",
       "                       [ 9.2857e-02,  2.2389e-02,  5.8036e-02,  6.2690e-02,  1.2987e-02,\n",
       "                         7.9446e-02,  1.7993e-01, -1.2022e-01,  3.3629e-02, -2.1258e-01,\n",
       "                         1.3898e-01, -2.2001e-01,  1.0344e-01, -2.4734e-01, -9.6750e-02,\n",
       "                        -1.1041e-01],\n",
       "                       [-2.3390e-01,  2.0863e-01,  1.1085e-01, -4.5824e-02, -1.0124e-01,\n",
       "                         1.2581e-01,  2.1855e-01, -2.4742e-02, -1.8214e-01, -6.9332e-02,\n",
       "                        -1.8324e-01, -1.9239e-01,  1.7830e-01,  7.1326e-02, -2.8981e-01,\n",
       "                         2.2802e-01],\n",
       "                       [ 8.2327e-04, -9.7071e-02,  1.0640e-01, -8.6914e-02,  5.5466e-02,\n",
       "                         1.6348e-01, -1.7332e-01, -1.7773e-01, -4.2601e-02, -2.3469e-01,\n",
       "                        -1.0226e-01,  1.4559e-01,  1.0211e-01,  2.1859e-02, -2.1244e-01,\n",
       "                         9.8660e-03],\n",
       "                       [-6.9653e-02,  3.1573e-02, -4.5160e-04,  3.1914e-01,  3.1807e-01,\n",
       "                         8.4590e-02,  2.2843e-01, -2.9374e-01, -1.9419e-02,  2.6458e-01,\n",
       "                        -8.7488e-03,  4.4349e-02,  3.0067e-01,  2.7649e-01, -4.0287e-02,\n",
       "                         5.1378e-02],\n",
       "                       [-1.8554e-01, -2.2701e-02, -1.5172e-03, -1.8073e-01,  1.0427e-01,\n",
       "                        -2.5312e-01,  9.1481e-03, -1.9131e-01, -2.6430e-01, -2.3114e-01,\n",
       "                        -1.5105e-02, -6.8580e-02,  2.5118e-02, -2.1741e-01, -2.2233e-01,\n",
       "                        -1.8121e-01],\n",
       "                       [ 1.0302e-01, -2.0839e-01,  1.1802e-01, -5.3576e-02,  7.5192e-03,\n",
       "                        -1.4682e-01, -2.8865e-02, -8.8291e-02, -3.2869e-01, -2.8211e-01,\n",
       "                        -9.6320e-02, -2.5151e-01, -3.1048e-01, -2.4807e-01, -1.5997e-01,\n",
       "                        -1.7579e-03],\n",
       "                       [-7.7084e-02, -3.5313e-02,  3.4772e-01,  2.2704e-01,  1.5350e-01,\n",
       "                         1.3784e-01,  1.7983e-01, -3.2983e-01, -1.5343e-02, -1.5975e-01,\n",
       "                         1.4999e-01,  1.9686e-01,  1.7908e-01,  7.1975e-02, -6.8194e-02,\n",
       "                         7.3649e-02],\n",
       "                       [-1.0795e-02, -7.5124e-02, -1.5478e-01, -1.8935e-01,  3.3305e-02,\n",
       "                        -9.4603e-02,  1.2080e-01, -6.5565e-02, -4.4685e-03, -2.9929e-01,\n",
       "                        -2.1286e-01,  6.3895e-02, -1.2144e-01,  1.7473e-01, -1.0839e-01,\n",
       "                        -6.1091e-02],\n",
       "                       [ 3.5212e-01,  4.4525e-01, -1.3548e-02, -4.5180e-02, -3.0988e-02,\n",
       "                        -1.6930e-01, -1.3754e-01, -8.5084e-02,  1.5959e-02,  1.0334e-01,\n",
       "                        -2.0513e-01, -2.0798e-02,  4.5089e-02, -5.3625e-02, -4.3914e-02,\n",
       "                         6.0773e-02],\n",
       "                       [-3.8628e-01,  1.6514e-01,  5.7613e-02,  2.9569e-02,  3.7765e-01,\n",
       "                         8.7192e-02,  1.2642e-01, -8.8188e-02,  4.2535e-02,  1.9144e-01,\n",
       "                         7.0174e-02, -5.3938e-02,  1.4454e-01,  1.4338e-01,  2.1201e-01,\n",
       "                         2.1665e-01],\n",
       "                       [ 3.3294e-02,  3.0599e-01,  6.6725e-02,  4.2683e-01, -3.7851e-02,\n",
       "                         5.6675e-01,  4.5459e-02,  1.2947e-02, -2.5709e-01,  2.8304e-01,\n",
       "                        -1.4654e-02,  1.5632e-01,  1.2464e-01, -9.7389e-02,  2.0957e-01,\n",
       "                         1.8052e-01]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([-0.0684, -0.1807, -0.0070,  0.1885, -0.0892, -0.1320,  0.3126, -0.1840,\n",
       "                        0.2732,  0.1247,  0.1485,  0.1552, -0.0823, -0.3880,  0.3366, -0.2334])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[-6.1181e-01,  1.0720e-01, -2.3223e-01,  5.8459e-02, -4.4939e-01,\n",
       "                         7.3667e-02,  1.2648e-01,  1.1795e-01,  6.2391e-02,  7.5726e-02,\n",
       "                         9.4884e-02,  5.9893e-02,  5.0337e-02, -1.6154e-01,  2.0628e-02,\n",
       "                        -4.7626e-01],\n",
       "                       [-2.2512e-01,  8.2947e-02, -2.3312e-01,  1.9192e-01, -2.1558e-01,\n",
       "                         1.7151e-01,  6.6393e-02,  2.7203e-01, -5.9706e-02, -7.4919e-02,\n",
       "                         8.1965e-02, -8.4992e-02,  3.5032e-02, -5.6967e-02, -1.3533e-01,\n",
       "                        -2.4983e-01],\n",
       "                       [-8.9546e-02, -7.4795e-02, -3.3224e-01,  1.4071e-01,  1.0974e-01,\n",
       "                        -5.6045e-02,  1.7738e-01, -1.1944e-01,  7.3250e-02, -1.6688e-01,\n",
       "                        -1.3537e-01,  1.8371e-01, -1.1449e-01, -1.6354e-01,  1.1587e-01,\n",
       "                        -9.4421e-02],\n",
       "                       [-3.0248e-01, -1.7680e-01, -9.2197e-02,  1.5241e-01,  1.4429e-01,\n",
       "                        -1.9071e-01,  1.8713e-01,  2.5666e-02,  8.9549e-02, -4.6624e-02,\n",
       "                         3.4545e-01,  4.1938e-02, -1.0676e-01,  2.2732e-01,  1.8814e-01,\n",
       "                         1.9583e-01],\n",
       "                       [ 2.7036e-02, -4.8776e-02,  3.7812e-02, -4.2649e-02, -1.2252e-02,\n",
       "                         1.2502e-01,  3.6464e-02, -6.6344e-02,  2.3430e-01, -1.4605e-01,\n",
       "                        -1.1219e-01,  4.7904e-02,  7.4543e-02, -1.0325e-01,  1.8046e-01,\n",
       "                         1.0951e-01],\n",
       "                       [-1.6904e-01,  4.2061e-02, -3.7440e-01, -7.1528e-02,  2.6100e-01,\n",
       "                        -1.3473e-01,  1.6623e-01,  2.7086e-01, -3.5616e-02,  1.8652e-01,\n",
       "                        -2.1529e-01, -8.2472e-03, -1.3941e-01, -4.9118e-02, -6.9313e-02,\n",
       "                        -1.0441e-01],\n",
       "                       [ 6.8300e-02,  2.0182e-01, -2.3127e-01,  1.8441e-01, -1.5203e-01,\n",
       "                         1.8150e-01,  7.6701e-02,  8.9533e-03,  2.1597e-01,  2.9443e-01,\n",
       "                        -5.0816e-02,  2.7422e-01,  5.1501e-02, -9.6596e-02,  3.1125e-01,\n",
       "                         3.7510e-02],\n",
       "                       [ 1.9910e-02, -7.8649e-02, -2.1327e-01, -2.4017e-01, -1.2388e-01,\n",
       "                        -1.1142e-01,  1.3106e-01,  4.7013e-02,  1.0041e-01, -1.2351e-01,\n",
       "                        -2.2926e-01,  4.0678e-02, -2.6324e-01, -3.0198e-01, -2.5536e-01,\n",
       "                        -1.4836e-01],\n",
       "                       [-2.0053e-01, -2.1481e-01, -1.6559e-01, -2.1205e-01, -1.7945e-01,\n",
       "                        -1.8296e-01, -2.0858e-02, -2.6680e-02,  9.2325e-03,  1.7049e-01,\n",
       "                         4.1352e-02,  4.6952e-02,  1.0917e-01,  9.1804e-02, -3.1176e-02,\n",
       "                        -2.4287e-02],\n",
       "                       [-2.5624e-01,  2.3769e-02, -2.0701e-01, -1.0560e-01,  1.8788e-01,\n",
       "                         1.4101e-01, -1.4065e-01,  9.2946e-02, -1.7324e-01,  1.8753e-01,\n",
       "                        -2.4556e-01,  3.1365e-04, -3.0878e-02, -1.0716e-01,  5.2147e-03,\n",
       "                        -2.7449e-01],\n",
       "                       [ 1.2781e-01, -1.2545e-01, -2.0302e-01,  1.1189e-01,  1.1775e-01,\n",
       "                         1.2540e-01, -2.9369e-01, -9.1940e-02, -2.5132e-01, -4.1126e-02,\n",
       "                        -1.5019e-01,  1.2673e-01, -4.7079e-02, -3.0187e-01,  1.2039e-01,\n",
       "                        -7.6509e-02],\n",
       "                       [-1.5930e-01,  2.1234e-01,  1.6073e-01, -2.4260e-01, -1.9185e-01,\n",
       "                        -2.4834e-01, -1.6692e-01, -3.0173e-01, -4.1718e-01, -6.9831e-02,\n",
       "                         1.7947e-02,  1.3630e-01, -1.5224e-03, -4.3366e-01, -4.2916e-02,\n",
       "                         8.6331e-02],\n",
       "                       [ 8.1308e-02, -1.0922e-01, -2.3511e-01, -3.7513e-03, -3.5305e-01,\n",
       "                        -5.0573e-02, -3.3062e-02, -2.7284e-01, -1.3307e-01,  1.9361e-01,\n",
       "                         3.4360e-02,  4.0648e-02, -2.0340e-01, -4.0122e-01,  1.7137e-01,\n",
       "                        -5.0653e-02],\n",
       "                       [ 3.7570e-02,  1.6972e-01, -1.0046e-01,  3.0321e-01,  1.3698e-01,\n",
       "                         1.9019e-01,  2.5162e-01,  2.9563e-02,  2.7222e-01, -6.8545e-02,\n",
       "                         1.4323e-01,  8.7688e-02,  2.8314e-01,  4.9763e-02,  2.7297e-01,\n",
       "                        -4.1483e-02],\n",
       "                       [-1.7460e-01, -1.1832e-02, -2.1106e-01, -2.2969e-01,  2.1524e-01,\n",
       "                         9.0884e-02,  8.3761e-02, -1.5698e-01,  1.6397e-01, -1.5928e-01,\n",
       "                         2.1802e-01,  1.8074e-01, -2.0244e-01,  2.2786e-01,  1.7394e-01,\n",
       "                        -9.9328e-02],\n",
       "                       [ 6.1615e-02,  2.2030e-01, -1.0848e-01,  7.5097e-02,  9.9970e-02,\n",
       "                         1.9849e-01,  9.3798e-02, -1.7299e-01, -4.6456e-02,  6.4259e-02,\n",
       "                        -1.7990e-01,  8.7118e-02, -4.1971e-02, -2.6806e-01, -1.4509e-01,\n",
       "                        -1.0564e-01]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.2429,  0.2209,  0.2464, -0.0143, -0.0745,  0.0583,  0.2968,  0.0723,\n",
       "                       -0.1990,  0.1299, -0.1669,  0.1017,  0.2470,  0.1130,  0.2158, -0.0674])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[ 2.2016e-01,  1.5199e-01,  1.7305e-01,  1.0622e-01,  5.3281e-02,\n",
       "                        -2.8589e-01,  2.1971e-02, -2.0818e-01,  1.8534e-02, -1.8917e-01,\n",
       "                        -1.8044e-01, -8.4909e-02, -1.8264e-01,  8.4935e-03, -2.0190e-01,\n",
       "                        -1.9926e-01],\n",
       "                       [-7.3473e-02,  1.6370e-03,  1.7775e-01,  1.6871e-01, -2.0704e-01,\n",
       "                         1.4218e-01,  3.0117e-01,  2.2135e-01,  1.4787e-01,  6.8392e-02,\n",
       "                        -1.0883e-01,  1.7205e-01, -3.4836e-01,  7.9415e-02,  9.8713e-02,\n",
       "                        -1.1099e-01],\n",
       "                       [ 2.2820e-01,  1.7515e-01,  6.3854e-02, -2.2907e-01,  1.9837e-01,\n",
       "                        -7.9769e-02,  2.0929e-01, -1.1415e-01, -7.5523e-02,  2.3564e-01,\n",
       "                         5.9371e-02, -2.8507e-01,  1.0666e-01, -1.4648e-01, -1.9090e-01,\n",
       "                         2.6452e-01],\n",
       "                       [-7.6702e-02, -9.4884e-02, -9.1512e-02, -8.2909e-02, -3.3273e-02,\n",
       "                         8.4784e-02, -4.4744e-03,  7.7745e-03,  2.3095e-02, -1.9826e-01,\n",
       "                        -1.7228e-01, -5.1657e-02, -1.2014e-01,  6.7660e-02, -1.5790e-01,\n",
       "                        -1.1487e-01],\n",
       "                       [ 3.4434e-01,  3.4095e-01,  1.8916e-01,  4.9160e-02,  1.5875e-01,\n",
       "                        -1.2745e-02, -1.7130e-01,  1.2556e-01,  6.7725e-02,  3.1174e-01,\n",
       "                         7.6282e-02, -8.8137e-03,  3.9554e-01, -9.2852e-02, -1.1797e-01,\n",
       "                        -6.7049e-02],\n",
       "                       [ 1.3940e-01,  8.3220e-02, -1.2263e-01, -2.0395e-01,  3.6649e-02,\n",
       "                        -9.0161e-03, -2.7143e-01, -9.7402e-02, -2.1310e-01,  1.7366e-01,\n",
       "                         4.5992e-02, -9.2645e-02,  8.4498e-02,  1.1690e-02, -2.6306e-01,\n",
       "                         9.5709e-02],\n",
       "                       [-3.0142e-01, -7.5506e-02, -1.9973e-01, -7.5399e-03, -2.1268e-01,\n",
       "                         7.4574e-03, -4.1238e-01, -1.4104e-01,  2.3941e-01,  5.9966e-02,\n",
       "                        -2.2646e-01,  1.9775e-01, -1.3216e-01, -1.7096e-01, -1.3608e-01,\n",
       "                        -2.0032e-01],\n",
       "                       [-4.1048e-01, -2.2581e-01,  1.7234e-01,  2.4711e-01,  2.6158e-01,\n",
       "                        -2.4461e-01,  2.3081e-01, -6.6773e-02,  7.7407e-03,  8.2247e-03,\n",
       "                        -1.3688e-01,  4.5364e-02,  6.2744e-02,  1.0996e-01,  7.3904e-02,\n",
       "                         2.4243e-01],\n",
       "                       [-1.9376e-01, -2.5006e-03,  3.0302e-01,  9.3401e-02,  2.5785e-01,\n",
       "                         1.2670e-01,  2.1006e-01,  8.4262e-02, -6.9823e-02, -8.8387e-02,\n",
       "                         2.7282e-02,  1.5505e-01, -3.6275e-02,  3.1944e-01,  1.0168e-01,\n",
       "                        -7.8650e-02],\n",
       "                       [-4.8656e-02, -2.6930e-01,  7.1934e-02, -1.7970e-01,  1.9754e-01,\n",
       "                         2.0773e-05, -4.2419e-02,  1.4194e-01, -1.5129e-01, -1.7811e-01,\n",
       "                         5.7736e-02, -6.7091e-02, -2.7081e-01, -1.6570e-01,  1.6246e-01,\n",
       "                         1.3912e-01],\n",
       "                       [-7.6761e-02, -1.0562e-01,  1.8396e-01, -8.3120e-02,  6.2485e-02,\n",
       "                        -5.4485e-02, -1.5448e-02,  6.5840e-02, -1.8984e-01,  1.2603e-01,\n",
       "                         6.5404e-02,  1.5129e-01, -1.1523e-01, -1.9175e-02, -1.3507e-01,\n",
       "                         8.4653e-02],\n",
       "                       [ 1.0701e-01,  2.6213e-02,  9.0851e-03,  4.1421e-03,  1.9888e-01,\n",
       "                        -1.3508e-01,  1.2407e-01,  7.9886e-03, -1.2012e-01, -1.4864e-01,\n",
       "                         6.9107e-02, -2.3862e-01, -1.3088e-02, -6.5957e-02, -2.2157e-01,\n",
       "                        -5.7396e-02],\n",
       "                       [ 2.0010e-01, -2.4087e-01,  1.3980e-01, -2.4087e-01, -6.4551e-02,\n",
       "                         1.5632e-01, -1.5214e-01, -1.1512e-01,  1.9652e-01, -1.3319e-01,\n",
       "                        -1.2544e-01,  1.5402e-01, -2.3412e-01,  2.0382e-01, -5.4729e-02,\n",
       "                        -8.5339e-02],\n",
       "                       [ 6.7716e-02, -3.2222e-01, -3.1594e-01, -3.3328e-01,  9.3649e-02,\n",
       "                        -2.8684e-01, -8.4448e-02, -6.3006e-02,  1.4898e-01,  1.6000e-01,\n",
       "                        -2.7273e-01, -5.5291e-02,  1.8375e-02, -3.3570e-01,  6.3434e-02,\n",
       "                         1.4034e-01],\n",
       "                       [ 7.8847e-02,  1.0861e-01, -1.8124e-01, -1.6628e-01, -2.0110e-01,\n",
       "                         1.6856e-01, -1.8643e-02, -2.2333e-01,  1.4495e-01, -1.8659e-01,\n",
       "                         4.9289e-02,  1.6918e-01, -1.6570e-01, -9.1916e-02, -1.1422e-01,\n",
       "                        -1.8651e-01],\n",
       "                       [-6.2911e-02, -9.3635e-02, -2.0111e-01, -4.6012e-02, -2.5429e-01,\n",
       "                        -4.8911e-02,  2.2315e-01, -8.8657e-02, -6.6382e-03,  8.0298e-02,\n",
       "                         2.3034e-01,  1.2844e-01, -2.4799e-01, -5.5257e-02,  1.4351e-01,\n",
       "                         2.7635e-01]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([-0.2346,  0.1112, -0.1984, -0.2359, -0.0365, -0.0162,  1.2592,  0.1815,\n",
       "                        0.1402,  0.0131, -0.1409, -0.2338, -0.1992,  0.3228,  0.2837,  0.0962])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[-0.0055, -0.1919, -0.1335,  0.0880,  0.1157,  0.1152,  1.4256, -0.2520,\n",
       "                        -0.2573,  0.0226,  0.0471,  0.2041,  0.0101,  0.3527,  0.1886, -0.0255]])),\n",
       "              ('layers.8.bias', tensor([-0.1026]))])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define quantiles and hyperparameters\n",
    "q_median = 0.5\n",
    "q_upper = 0.975\n",
    "q_lower = 0.025\n",
    "dims = model['dims']\n",
    "lr = model['lr']\n",
    "batch_size = int(model['batch_size'])\n",
    "epoch = model['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch size: 500\n",
      "epoch: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"lr:\", lr)\n",
    "print(\"batch size:\", batch_size)\n",
    "print(\"epoch:\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done C_WTG01\n",
      "Done C_WTG02\n",
      "Done C_WTG03\n",
      "Done C_WTG04\n",
      "Done C_WTG05\n",
      "Done C_WTG06\n",
      "Done C_WTG07\n",
      "Done C_WTG08\n",
      "Done C_WTG09\n",
      "Done C_WTG10\n",
      "Done C_WTG11\n",
      "Done C_WTG12\n",
      "Done C_WTG13\n",
      "Done C_WTG14\n",
      "Done C_WTG15\n",
      "Done C_WTG16\n",
      "Done C_WTG17\n",
      "Done C_WTG18\n",
      "Done C_WTG19\n",
      "Done C_WTG20\n",
      "Done C_WTG21\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################################### training ######################################################### \n",
    "\n",
    "turbines = data_finetune.instanceID.unique()\n",
    "median_state_dict_all = []\n",
    "UQ_state_dict_all = []\n",
    "LQ_state_dict_all = []\n",
    "\n",
    "\n",
    "for ID in turbines:\n",
    "    \n",
    "    # select data based on turbine ID\n",
    "    data_temp = data_finetune[data_finetune['instanceID'] == ID]\n",
    "\n",
    "    # normalize data\n",
    "    X = scaler1.transform(data_temp.iloc[:, 5:-1])\n",
    "    y = scaler2.transform(data_temp.iloc[:, -1:])\n",
    "    \n",
    "    # create network and load pretrain weights\n",
    "    net_median_temp = Net(dims = dims)\n",
    "    net_median_temp.load_state_dict(pretrain['median'])\n",
    "    \n",
    "    net_upper_temp = Net(dims = dims)\n",
    "    net_upper_temp.load_state_dict(pretrain['UQ'])\n",
    "    \n",
    "    net_lower_temp = Net(dims = dims)\n",
    "    net_lower_temp.load_state_dict(pretrain['LQ'])\n",
    "    \n",
    "    # train\n",
    "    net_median_temp, median_state_dict = train(X=X, y=y, quantile=q_median, net=net_median_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_upper_temp, UQ_state_dict = train(X=X, y=y, quantile=q_upper, net=net_upper_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_lower_temp, LQ_state_dict = train(X=X, y=y, quantile=q_lower, net=net_lower_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    \n",
    "    median_state_dict_all.append(median_state_dict)\n",
    "    UQ_state_dict_all.append(UQ_state_dict)\n",
    "    LQ_state_dict_all.append(LQ_state_dict)\n",
    "    \n",
    "    print('Done', ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_state_dict_all_zip = dict(zip(turbines, median_state_dict_all))\n",
    "UQ_state_dict_all_zip = dict(zip(turbines, UQ_state_dict_all))\n",
    "LQ_state_dict_all_zip = dict(zip(turbines, LQ_state_dict_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save trained network\n",
    "\n",
    "torch.save(median_state_dict_all_zip, sys.path[0] + '/median.pth')\n",
    "torch.save(UQ_state_dict_all_zip, sys.path[0] + '/UQ.pth')\n",
    "torch.save(LQ_state_dict_all_zip, sys.path[0] + '/LQ.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
