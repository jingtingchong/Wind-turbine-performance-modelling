{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from typing import Iterable\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from joblib import dump, load\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data_finetune = pd.read_csv(\"data_finetune.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>instanceID</th>\n",
       "      <th>Wind_speed</th>\n",
       "      <th>TI</th>\n",
       "      <th>Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958671</th>\n",
       "      <td>2020-11-13 00:30:00</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>6.343173</td>\n",
       "      <td>15.312233</td>\n",
       "      <td>496.738776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682500</th>\n",
       "      <td>2020-08-13 16:40:00</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>3.461359</td>\n",
       "      <td>17.919733</td>\n",
       "      <td>42.106780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827043</th>\n",
       "      <td>2020-09-30 11:50:00</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>3.595130</td>\n",
       "      <td>10.394158</td>\n",
       "      <td>58.858180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278880</th>\n",
       "      <td>2020-04-02 05:20:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>16.338689</td>\n",
       "      <td>15.963571</td>\n",
       "      <td>2043.203491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794451</th>\n",
       "      <td>2020-09-19 17:10:00</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>6.913757</td>\n",
       "      <td>8.228349</td>\n",
       "      <td>614.239596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580775</th>\n",
       "      <td>2020-07-11 01:10:00</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.650944</td>\n",
       "      <td>14.949392</td>\n",
       "      <td>830.078456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122912</th>\n",
       "      <td>2020-02-10 15:20:00</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.982645</td>\n",
       "      <td>19.118705</td>\n",
       "      <td>825.983393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11129</th>\n",
       "      <td>2020-01-04 16:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.100355</td>\n",
       "      <td>13.664154</td>\n",
       "      <td>653.990937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855014</th>\n",
       "      <td>2020-10-09 17:40:00</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>4.106625</td>\n",
       "      <td>28.984064</td>\n",
       "      <td>166.245071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564836</th>\n",
       "      <td>2020-07-05 18:40:00</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>9.763854</td>\n",
       "      <td>11.476947</td>\n",
       "      <td>1889.555786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ts  Month  Day  Hour instanceID  Wind_speed  \\\n",
       "958671  2020-11-13 00:30:00     11   13     0    C_WTG01    6.343173   \n",
       "682500  2020-08-13 16:40:00      8   13    16    C_WTG01    3.461359   \n",
       "827043  2020-09-30 11:50:00      9   30    11    C_WTG01    3.595130   \n",
       "278880  2020-04-02 05:20:00      4    2     5    C_WTG01   16.338689   \n",
       "794451  2020-09-19 17:10:00      9   19    17    C_WTG01    6.913757   \n",
       "...                     ...    ...  ...   ...        ...         ...   \n",
       "580775  2020-07-11 01:10:00      7   11     1    C_WTG21    6.650944   \n",
       "122912  2020-02-10 15:20:00      2   10    15    C_WTG21    6.982645   \n",
       "11129   2020-01-04 16:10:00      1    4    16    C_WTG21    6.100355   \n",
       "855014  2020-10-09 17:40:00     10    9    17    C_WTG21    4.106625   \n",
       "564836  2020-07-05 18:40:00      7    5    18    C_WTG21    9.763854   \n",
       "\n",
       "               TI        Power  \n",
       "958671  15.312233   496.738776  \n",
       "682500  17.919733    42.106780  \n",
       "827043  10.394158    58.858180  \n",
       "278880  15.963571  2043.203491  \n",
       "794451   8.228349   614.239596  \n",
       "...           ...          ...  \n",
       "580775  14.949392   830.078456  \n",
       "122912  19.118705   825.983393  \n",
       "11129   13.664154   653.990937  \n",
       "855014  28.984064   166.245071  \n",
       "564836  11.476947  1889.555786  \n",
       "\n",
       "[210000 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load normalization function \n",
    "scaler1 = load('scaler1.bin')\n",
    "scaler2 = load('scaler2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_count = data_finetune['instanceID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dims: Iterable[int], output_activation: nn.Module = None):\n",
    "        \"\"\"Creates a network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = dims[0]\n",
    "        self.out_size = dims[-1]\n",
    "        self.layers = self.make_seq(dims, output_activation)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_seq(dims: Iterable[int], output_activation: nn.Module) -> nn.Module:\n",
    "        \"\"\"Creates a sequential network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        :return (nn.Module): return created sequential layers\n",
    "        \"\"\"\n",
    "        mods = []\n",
    "\n",
    "        for i in range(len(dims) - 2):\n",
    "            mods.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            mods.append(nn.ReLU())\n",
    "\n",
    "        mods.append(nn.Linear(dims[-2], dims[-1]))\n",
    "        if output_activation:\n",
    "            mods.append(output_activation())\n",
    "        return nn.Sequential(*mods)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Computes a forward pass through the network\n",
    "\n",
    "        :param x (torch.Tensor): input tensor to feed into the network\n",
    "        :return (torch.Tensor): output computed by the network\n",
    "        \"\"\"\n",
    "        # Feedforward\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, quantile, net, lr, batch_size, epoch):    \n",
    "    \n",
    "    # create tensor dataset\n",
    "    train = TensorDataset(Tensor(X), Tensor(y))\n",
    "\n",
    "    # create data loader from dataset\n",
    "    trainset = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr = lr)\n",
    "        \n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for ep in range(epoch):\n",
    "\n",
    "        for t in trainset:\n",
    "            X_temp, y_temp = t\n",
    "            output = net(X_temp)\n",
    "            residual = y_temp - output\n",
    "            loss = Tensor.max(quantile*residual, (quantile-1)*residual).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return net, net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use a very low learning rate at this stage, because we are training on a dataset that is very small. This is to prevent the risk of overfitting very quickly if we apply large weight updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hyperparameters\n",
    "model = torch.load( sys.path[0] + '/hparams_finetune.pth')\n",
    "\n",
    "# load the pretrained weights\n",
    "pretrain = torch.load( sys.path[0] + '/pretrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median': OrderedDict([('layers.0.weight',\n",
       "               tensor([[-3.3409e-02,  3.4334e-01],\n",
       "                       [-4.8709e-01, -5.6009e-02],\n",
       "                       [-1.9211e-01,  7.6824e-02],\n",
       "                       [ 4.8681e-01, -2.4664e-01],\n",
       "                       [ 1.6888e-01,  3.1723e-01],\n",
       "                       [-4.2182e-01,  2.5050e-01],\n",
       "                       [-6.1909e-01, -1.5120e-01],\n",
       "                       [-6.4049e-03, -1.2806e-01],\n",
       "                       [ 3.4663e-01,  1.9104e-02],\n",
       "                       [ 6.3092e-01,  3.4026e-01],\n",
       "                       [-5.8796e-01, -8.7002e-02],\n",
       "                       [ 4.6378e-01, -5.9955e-04],\n",
       "                       [ 2.0005e-01, -4.4539e-01],\n",
       "                       [ 2.9766e-01, -1.6475e-01],\n",
       "                       [-7.1311e-01, -3.7808e-01],\n",
       "                       [-7.0781e-01,  3.2813e-01]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 2.6803e-01,  4.8245e-01,  8.6715e-01,  7.5978e-02, -5.2458e-01,\n",
       "                       -7.1778e-01,  3.2871e-01,  8.2258e-01,  1.2770e-01,  5.1465e-04,\n",
       "                        4.7288e-01,  6.0068e-01, -1.0665e-01,  4.8070e-01, -4.4539e-03,\n",
       "                       -5.6836e-02])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[ 0.1945,  0.0555, -0.2273,  0.2078, -0.3095, -0.1958,  0.3314, -0.0041,\n",
       "                        -0.1932,  0.1779,  0.3506, -0.2670,  0.0826,  0.1931,  0.0285,  0.1941],\n",
       "                       [-0.1338,  0.0035,  0.1715, -0.1471, -0.0090, -0.1625, -0.3428, -0.2050,\n",
       "                         0.0947,  0.0316, -0.0362,  0.0969, -0.2011, -0.0082, -0.0558, -0.0390],\n",
       "                       [ 0.1260, -0.1747,  0.1304,  0.1575, -0.0938, -0.2503, -0.1744,  0.4056,\n",
       "                         0.0346,  0.1370, -0.3249,  0.2455,  0.0906,  0.0194,  0.0203, -0.0723],\n",
       "                       [-0.0627,  0.1980, -0.2364, -0.0049, -0.2436,  0.1367, -0.1531, -0.1078,\n",
       "                        -0.0084,  0.0952,  0.0287, -0.2407, -0.2262,  0.0405,  0.0308,  0.0568],\n",
       "                       [-0.0098, -0.0927, -0.1016, -0.1994, -0.1734, -0.1523,  0.2232, -0.1743,\n",
       "                        -0.1363,  0.1594, -0.1097, -0.1642, -0.2261, -0.2400, -0.2160,  0.0612],\n",
       "                       [-0.3726,  0.2929,  0.0461,  0.1230,  0.1292, -0.3534, -0.0397, -0.0420,\n",
       "                         0.0886,  0.4109, -0.0374, -0.0752,  0.2532, -0.0138,  0.1855,  0.1742],\n",
       "                       [-0.0392,  0.0720,  0.3299, -0.2216, -0.0534, -0.0103,  0.0878,  0.0882,\n",
       "                        -0.1968, -0.2102,  0.0119, -0.3338,  0.0326,  0.1034,  0.2325,  0.0937],\n",
       "                       [ 0.1904,  0.0374,  0.3476, -0.0457, -0.0656,  0.1181,  0.1151,  0.0963,\n",
       "                        -0.1771, -0.0326,  0.1717, -0.1399,  0.0354, -0.2117,  0.1581,  0.3145],\n",
       "                       [ 0.1033, -0.1902,  0.0667, -0.0255, -0.1707, -0.0157, -0.1790,  0.1074,\n",
       "                         0.1253, -0.2659,  0.0851,  0.0719, -0.2668,  0.1397,  0.1932,  0.0031],\n",
       "                       [ 0.1428, -0.2375,  0.1657, -0.1791, -0.2097,  0.1275, -0.3180,  0.2869,\n",
       "                        -0.1099, -0.0819, -0.6097,  0.2335, -0.2138, -0.0960,  0.0104, -0.1476],\n",
       "                       [-0.0949,  0.1138,  0.3083, -0.4438,  0.0160,  0.0413, -0.0443,  0.3268,\n",
       "                         0.0095, -0.1517,  0.0581, -0.1596, -0.0757, -0.1060,  0.1824,  0.0727],\n",
       "                       [-0.0022, -0.3413,  0.2688,  0.1944, -0.0424,  0.0026, -0.0352,  0.0790,\n",
       "                        -0.0636,  0.0484, -0.4867,  0.3347,  0.2455, -0.0226,  0.0826, -0.0935],\n",
       "                       [ 0.1708,  0.1141, -0.0744, -0.1090, -0.1128,  0.1335, -0.2506, -0.2179,\n",
       "                         0.0159, -0.1830, -0.0673, -0.0433,  0.0382,  0.1025,  0.0939, -0.0733],\n",
       "                       [-0.0443, -0.1452, -0.2598,  0.2833,  0.0595, -0.0050,  0.0112, -0.2757,\n",
       "                        -0.1217, -0.0369, -0.0840, -0.2806,  0.1536, -0.0857,  0.0499,  0.0777],\n",
       "                       [-0.1305, -0.3292,  0.3140,  0.1280,  0.0117,  0.1815, -0.0824,  0.2203,\n",
       "                        -0.0068,  0.1436, -0.2831,  0.0516,  0.1394,  0.3190, -0.1295,  0.0428],\n",
       "                       [-0.0746, -0.0274, -0.2286,  0.1180, -0.0377, -0.3645, -0.1723, -0.1705,\n",
       "                         0.0317, -0.2577,  0.0218,  0.1188, -0.0373, -0.1960, -0.1700,  0.0200]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([-0.0071, -0.2035,  0.2745, -0.0936, -0.0585, -0.2683,  0.4357,  0.3517,\n",
       "                       -0.3350,  0.4902,  0.4424,  0.0925, -0.2474, -0.2608,  0.2773, -0.2138])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[-0.1574, -0.1680, -0.3979,  0.0935, -0.1443, -0.4821, -0.0879,  0.1958,\n",
       "                        -0.1829,  0.2820, -0.0586, -0.1087,  0.0759,  0.1511,  0.1752,  0.0854],\n",
       "                       [-0.1228,  0.0050, -0.1351, -0.1802,  0.0380, -0.0604,  0.1145,  0.0982,\n",
       "                        -0.0399,  0.0938, -0.0523,  0.0634,  0.2605, -0.1359, -0.0234, -0.2390],\n",
       "                       [-0.2491, -0.1306, -0.1497,  0.0242,  0.0262, -0.0783, -0.3188, -0.1183,\n",
       "                         0.1983, -0.2036,  0.0474, -0.0830, -0.0546,  0.0944, -0.2596,  0.1594],\n",
       "                       [-0.0909,  0.1364, -0.0631, -0.0058,  0.0708, -0.2225, -0.3859, -0.4957,\n",
       "                         0.0124,  0.0759, -0.5366,  0.3050,  0.1148, -0.0995,  0.0406, -0.0566],\n",
       "                       [ 0.0413,  0.2817,  0.1864, -0.0330, -0.0785, -0.1977,  0.1080,  0.0413,\n",
       "                         0.0137,  0.2574, -0.4811, -0.1403, -0.2235, -0.0057,  0.1521,  0.2100],\n",
       "                       [ 0.1325, -0.0430,  0.1087, -0.0599, -0.1130, -0.1628, -0.1465, -0.0032,\n",
       "                         0.1484,  0.1201, -0.1986,  0.0829,  0.2003,  0.1041, -0.3087,  0.0892],\n",
       "                       [-0.1710, -0.0506,  0.1605,  0.1568,  0.1685, -0.1153,  0.1915,  0.1043,\n",
       "                        -0.1325,  0.3662, -0.2907,  0.2588,  0.1591, -0.0438,  0.2832, -0.0634],\n",
       "                       [-0.1321,  0.2765,  0.4016, -0.1979,  0.1232, -0.2684, -0.1138, -0.1361,\n",
       "                         0.2595,  0.2410, -0.0805, -0.0231, -0.2259,  0.0264,  0.0531, -0.0290],\n",
       "                       [ 0.1789, -0.1197,  0.0349, -0.0608, -0.0188, -0.0769, -0.1554, -0.0990,\n",
       "                        -0.1872, -0.0831, -0.1575, -0.2936, -0.0980, -0.1460, -0.0693,  0.1956],\n",
       "                       [ 0.2385,  0.0570,  0.1026, -0.0826, -0.1423, -0.0014,  0.2411,  0.3316,\n",
       "                        -0.0374, -0.0988,  0.1069,  0.0940, -0.0952,  0.2532, -0.0221, -0.1625],\n",
       "                       [ 0.1155, -0.0564,  0.1259,  0.2399, -0.0989,  0.0055, -0.2278, -0.1715,\n",
       "                        -0.0429, -0.1123,  0.0864,  0.0649, -0.0880,  0.1072, -0.1869, -0.0038],\n",
       "                       [-0.0490, -0.0898, -0.1169,  0.0192, -0.2228,  0.0462,  0.0696,  0.2395,\n",
       "                        -0.2858,  0.0098,  0.0836, -0.1244,  0.0527, -0.0235, -0.1718,  0.0824],\n",
       "                       [ 0.3295, -0.0157, -0.0708, -0.1990, -0.0601,  0.3305,  0.2165,  0.0598,\n",
       "                         0.0701, -0.1952,  0.0177,  0.0985, -0.1606,  0.0926, -0.2417, -0.0545],\n",
       "                       [ 0.1338, -0.0757, -0.3430,  0.0882, -0.0458, -0.1431,  0.2416,  0.2731,\n",
       "                         0.0867,  0.2778,  0.3221, -0.1326, -0.0138, -0.1136,  0.0330, -0.2090],\n",
       "                       [-0.1876, -0.0736,  0.3955,  0.0618, -0.1108, -0.0278, -0.1530, -0.1780,\n",
       "                        -0.1536,  0.2202, -0.1282,  0.1694,  0.1148,  0.1230,  0.2926,  0.0851],\n",
       "                       [-0.2035,  0.0098,  0.1522, -0.1586,  0.1786, -0.0340, -0.2957, -0.2113,\n",
       "                        -0.1416, -0.0499, -0.2308,  0.0686, -0.1992, -0.2764,  0.3653,  0.0776]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([-0.0395,  0.2592, -0.1092,  0.2575, -0.0473, -0.2238,  0.2753,  0.4292,\n",
       "                        0.0331, -0.2286, -0.2071,  0.4355,  0.2878,  0.4694,  0.3453,  0.3702])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[-0.0348,  0.0463,  0.0060,  0.1353,  0.0028,  0.0405, -0.1493, -0.0051,\n",
       "                         0.0833, -0.0874, -0.1781, -0.2192, -0.1514,  0.0709, -0.2000,  0.1430],\n",
       "                       [ 0.1670,  0.0229,  0.0510, -0.1549,  0.1815, -0.0725, -0.0646, -0.0252,\n",
       "                         0.0370,  0.0624, -0.0996,  0.3844,  0.2148,  0.2006,  0.0532, -0.2277],\n",
       "                       [-0.1725,  0.1097, -0.0937,  0.1577, -0.0411, -0.2582, -0.1112,  0.1159,\n",
       "                        -0.0976,  0.1247,  0.2580, -0.2631, -0.2794,  0.0054, -0.1602, -0.0555],\n",
       "                       [ 0.2121,  0.2033,  0.1091, -0.0134, -0.0900, -0.1591, -0.2258,  0.0743,\n",
       "                         0.0808, -0.1457, -0.2481, -0.0410, -0.0730, -0.0506,  0.0888, -0.0308],\n",
       "                       [-0.2087, -0.2544,  0.1210,  0.0687, -0.0554,  0.1432,  0.0673,  0.1381,\n",
       "                        -0.1672,  0.0709,  0.1777, -0.1962,  0.1074,  0.1319, -0.2787, -0.2420],\n",
       "                       [ 0.2417,  0.3016, -0.0500,  0.1296, -0.1190, -0.0834, -0.0601,  0.3083,\n",
       "                         0.0541, -0.0245, -0.0275,  0.0695,  0.1186, -0.2945,  0.2327,  0.1782],\n",
       "                       [ 0.0081, -0.0975, -0.0465,  0.3735,  0.0254, -0.1529,  0.3822,  0.3789,\n",
       "                         0.0018, -0.1234,  0.1717,  0.1378, -0.1018, -0.1582,  0.3127,  0.2577],\n",
       "                       [ 0.2355,  0.2881,  0.1132, -0.2945, -0.1702, -0.0940,  0.1639, -0.1544,\n",
       "                         0.1419,  0.0299,  0.0408,  0.2836,  0.3574,  0.2625,  0.0299, -0.2218],\n",
       "                       [ 0.0220, -0.1220, -0.1150, -0.2953, -0.0326,  0.2189,  0.0951, -0.0500,\n",
       "                        -0.1347,  0.0445,  0.0229,  0.2612,  0.0654,  0.3300,  0.0433,  0.0980],\n",
       "                       [ 0.3918, -0.1053, -0.2423,  0.1316, -0.0462,  0.2040,  0.3207,  0.1918,\n",
       "                         0.2121, -0.5113, -0.1206, -0.4357, -0.4960, -0.5949,  0.0649,  0.1878],\n",
       "                       [ 0.1540,  0.2317, -0.1653,  0.0521,  0.1998, -0.2329,  0.3917, -0.0096,\n",
       "                        -0.2226, -0.2245, -0.0305, -0.1915, -0.0503, -0.1076,  0.2162,  0.2055],\n",
       "                       [ 0.0722,  0.1310,  0.1148, -0.0495,  0.2630, -0.0822,  0.1791,  0.2280,\n",
       "                         0.1936, -0.0029,  0.2141,  0.0676,  0.1394, -0.0859,  0.1579,  0.2691],\n",
       "                       [ 0.0945,  0.2614, -0.0202, -0.2367, -0.0303,  0.0589,  0.1681,  0.1497,\n",
       "                        -0.0173,  0.0677,  0.1665,  0.3374,  0.1210,  0.3939, -0.2692, -0.3040],\n",
       "                       [ 0.0795,  0.0496,  0.0362, -0.3143, -0.1773, -0.0613,  0.1234,  0.0029,\n",
       "                         0.0474,  0.1993,  0.0036,  0.2522,  0.2943, -0.0615, -0.1237, -0.0576],\n",
       "                       [-0.2960, -0.2716, -0.2427, -0.1885, -0.0861, -0.1432, -0.0929, -0.1486,\n",
       "                         0.1047, -0.0572, -0.1171,  0.0118, -0.0607,  0.1237,  0.0014, -0.1535],\n",
       "                       [ 0.2242, -0.0395,  0.2103, -0.2050, -0.1179, -0.0961,  0.2458, -0.2840,\n",
       "                         0.1151, -0.0238,  0.2453, -0.1682,  0.0675,  0.0862, -0.2297,  0.1901]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([-0.0266,  0.2230,  0.0225, -0.1718, -0.2912,  0.2092,  0.2872,  0.1445,\n",
       "                       -0.1130,  0.3441,  0.3530, -0.0855,  0.3914,  0.0344, -0.0153, -0.0141])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[ 0.1666, -0.2429, -0.0375,  0.0698,  0.0561,  0.1661,  0.3139, -0.1365,\n",
       "                        -0.1848,  0.2740,  0.2039,  0.1673, -0.2296, -0.1612,  0.0549,  0.0055]])),\n",
       "              ('layers.8.bias', tensor([0.0597]))]),\n",
       " 'UQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[-0.9537, -0.2553],\n",
       "                       [-1.0023, -0.2775],\n",
       "                       [ 0.1169,  0.2474],\n",
       "                       [-0.7974,  0.0826],\n",
       "                       [-0.0873,  0.2993],\n",
       "                       [-0.5114, -0.2844],\n",
       "                       [-0.3690, -0.1744],\n",
       "                       [ 0.4473, -0.0970],\n",
       "                       [-0.9219,  0.0663],\n",
       "                       [-0.9941, -0.1092],\n",
       "                       [-0.1220, -0.0889],\n",
       "                       [-0.6981, -0.2649],\n",
       "                       [ 0.2868, -0.0217],\n",
       "                       [ 0.0140, -0.4100],\n",
       "                       [ 0.2613, -0.2494],\n",
       "                       [ 0.6465,  0.1872]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.2299, -0.3152,  0.1087,  0.9554,  0.3957, -0.2301,  0.3000, -0.8800,\n",
       "                        0.0279,  0.7241, -0.5002,  0.3781,  0.6439,  0.4063,  0.6813,  0.2391])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[-1.2269e-01,  1.6766e-01, -1.4461e-01,  5.5071e-02,  4.9868e-03,\n",
       "                         8.0284e-02, -3.4816e-01, -2.0055e-02,  3.7194e-01, -9.6627e-03,\n",
       "                         1.1754e-01, -4.9674e-01, -2.6257e-01, -6.5630e-02, -1.1790e-01,\n",
       "                         2.5730e-02],\n",
       "                       [ 1.2781e-01,  1.2856e-01, -2.5397e-01, -2.3693e-01, -1.3112e-01,\n",
       "                        -2.6026e-01, -3.0241e-01, -7.4162e-03, -1.5894e-01, -4.6062e-02,\n",
       "                        -9.1407e-02, -2.7668e-01,  1.2367e-01, -2.6037e-01,  1.4850e-01,\n",
       "                        -2.1941e-01],\n",
       "                       [-1.3568e-01, -4.1809e-02,  3.2411e-01, -9.4316e-02,  2.5406e-01,\n",
       "                         2.7641e-02, -1.4196e-02,  5.2462e-02, -3.2874e-01, -1.2009e-01,\n",
       "                        -2.5879e-01, -1.5436e-01,  3.2645e-01, -2.0776e-01,  2.2562e-01,\n",
       "                         3.7899e-02],\n",
       "                       [ 5.8859e-01,  1.5490e-01, -5.9187e-02,  3.0252e-01,  1.3642e-01,\n",
       "                         1.4340e-02, -7.1163e-03, -2.2018e-01,  2.6136e-01, -3.2242e-02,\n",
       "                         2.3371e-01,  2.2161e-01, -1.8048e-01, -1.4711e-01, -1.1310e-01,\n",
       "                        -2.7141e-01],\n",
       "                       [-3.7964e-01, -3.2544e-01, -7.3111e-02, -1.5175e-01, -1.2160e-01,\n",
       "                         9.4402e-02, -1.6685e-01,  8.5894e-02,  1.0024e-01, -3.7449e-01,\n",
       "                        -1.0544e-01,  1.2972e-01, -9.8718e-02,  1.5930e-01, -1.6561e-01,\n",
       "                        -1.9285e-01],\n",
       "                       [-1.7203e-01, -1.4042e-02, -1.1505e-01, -2.4489e-01,  2.3453e-01,\n",
       "                        -1.0370e-01,  1.5706e-01, -1.3084e-01,  1.6745e-02,  2.0108e-02,\n",
       "                         8.3560e-02, -1.9196e-01, -8.2771e-02,  4.9341e-03, -1.1886e-01,\n",
       "                        -2.2957e-01],\n",
       "                       [-5.2164e-03,  1.0487e-01, -7.6314e-02, -2.1069e-01,  1.6939e-01,\n",
       "                        -2.1459e-01,  1.5036e-01,  1.4129e-01, -8.6609e-02, -1.3947e-01,\n",
       "                         2.1505e-01, -1.3048e-01, -1.9303e-01, -3.8110e-02, -1.0988e-01,\n",
       "                        -3.4350e-03],\n",
       "                       [-2.2628e-01, -2.9609e-01, -7.4860e-02,  1.3703e-01,  3.3622e-01,\n",
       "                         6.0634e-02,  1.9118e-01, -2.3457e-01, -2.8652e-01, -3.0820e-01,\n",
       "                        -1.2069e-01,  2.4235e-01,  4.0564e-01,  2.7374e-01, -3.0071e-04,\n",
       "                         3.9681e-01],\n",
       "                       [-8.7609e-02, -1.9541e-01,  5.6436e-02, -3.1497e-01, -3.3434e-02,\n",
       "                        -3.6269e-01, -2.1544e-01, -3.4525e-02, -3.4034e-01, -2.2088e-01,\n",
       "                        -7.7922e-03, -1.2375e-01, -5.2407e-02,  3.0299e-01,  1.2876e-01,\n",
       "                         4.8246e-02],\n",
       "                       [ 9.9320e-03, -1.9964e-01, -2.1335e-01, -4.5330e-01, -2.0044e-01,\n",
       "                         3.0570e-02,  2.5057e-01, -1.0566e-01, -1.1573e+00, -2.1241e-01,\n",
       "                         8.3284e-02,  4.7346e-01,  1.7743e-02,  4.5282e-02,  1.8467e-01,\n",
       "                        -3.1752e-01],\n",
       "                       [-1.4920e-01, -1.5582e-01,  3.1927e-01,  3.0345e-02,  1.7072e-01,\n",
       "                        -1.2710e-01,  7.7270e-02, -1.5489e-01, -5.1247e-01, -3.1459e-01,\n",
       "                        -1.5749e-01, -3.5829e-01,  5.0322e-02,  2.0552e-01, -3.6892e-03,\n",
       "                        -8.3599e-02],\n",
       "                       [ 3.7557e-01,  3.0736e-01,  3.7340e-02,  5.8890e-01,  3.1088e-01,\n",
       "                         1.2600e-01,  2.5744e-01,  3.4228e-01,  7.9391e-01,  5.2662e-01,\n",
       "                        -4.6131e-02, -3.3761e-02, -1.2895e-01,  2.8357e-01,  4.0873e-02,\n",
       "                         6.1618e-02],\n",
       "                       [-9.7610e-02, -2.0355e-01,  8.0140e-02, -4.9139e-01,  1.6184e-01,\n",
       "                         7.2381e-02, -6.2817e-02, -1.6388e-01, -6.0848e-01, -3.0884e-01,\n",
       "                        -5.6859e-02, -2.1080e-02,  8.8550e-02,  2.7748e-01,  3.3542e-01,\n",
       "                        -1.4970e-01],\n",
       "                       [-1.1363e-01, -1.3404e-01,  5.0810e-02, -3.4277e-02,  2.9409e-02,\n",
       "                        -9.1908e-02,  1.3320e-01,  1.0365e-01, -3.2222e-02, -1.6473e-01,\n",
       "                         1.2311e-01, -1.1961e-01,  3.5997e-01,  1.4867e-01,  3.7823e-01,\n",
       "                         3.2153e-01],\n",
       "                       [ 1.9235e-01, -1.6913e-01,  1.9950e-01,  6.3633e-01,  7.3844e-02,\n",
       "                         5.3367e-02,  7.3018e-02,  5.0148e-01, -9.1984e-02,  2.9792e-01,\n",
       "                         3.0450e-01,  3.5815e-01,  2.9264e-01,  1.4723e-01,  4.6469e-02,\n",
       "                        -1.2530e-01],\n",
       "                       [-8.1356e-02, -1.1044e-01,  8.3267e-02,  2.5347e-01,  1.1836e-01,\n",
       "                         3.4789e-02, -2.4042e-01, -2.2249e-02,  2.9398e-01,  2.2764e-01,\n",
       "                         1.1228e-01, -6.8932e-02,  1.3055e-02, -5.3671e-02, -1.0729e-01,\n",
       "                        -8.1562e-02]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.0980,  0.0083,  0.1025,  0.0207,  0.0761,  0.0400, -0.1129,  0.0800,\n",
       "                        0.2174, -0.0079,  0.0562, -0.0949,  0.2024,  0.2669, -0.1844, -0.0683])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[ 6.5337e-02,  1.0317e-01,  1.0141e-01, -1.9857e-01, -3.9592e-02,\n",
       "                         1.8553e-01,  2.1550e-01, -2.5986e-01, -2.6863e-01, -6.1380e-02,\n",
       "                        -7.6774e-02,  1.3896e-01, -2.4212e-02, -7.2240e-02, -2.4247e-01,\n",
       "                        -2.8757e-01],\n",
       "                       [ 4.4088e-02, -1.5383e-01, -6.7086e-02, -6.1844e-06,  1.7774e-01,\n",
       "                         1.7052e-01, -2.0026e-01, -2.9908e-01, -8.9236e-04,  1.7972e-01,\n",
       "                        -7.3916e-02,  1.7876e-02,  7.2601e-02, -7.1474e-02, -1.7104e-01,\n",
       "                         1.1931e-01],\n",
       "                       [-2.6177e-02, -1.1589e-01, -1.0403e-01, -2.8350e-02,  6.0191e-02,\n",
       "                         1.9688e-01,  2.8038e-02,  7.4531e-02,  2.1099e-01,  2.0989e-01,\n",
       "                        -1.5341e-01, -5.0614e-02,  2.9340e-01,  8.5646e-02, -2.2997e-01,\n",
       "                        -4.0184e-01],\n",
       "                       [-2.3774e-01,  5.7568e-02,  1.3885e-01,  4.0354e-02, -3.0605e-01,\n",
       "                        -1.0858e-01, -1.6530e-01, -1.7322e-01, -1.7603e-01,  8.6940e-02,\n",
       "                         1.1149e-01, -3.3653e-01, -2.0591e-01,  1.4489e-01, -3.7357e-01,\n",
       "                         1.3607e-01],\n",
       "                       [-6.8445e-02,  8.1658e-02, -2.9313e-01,  4.8441e-03, -2.4627e-02,\n",
       "                         8.4261e-02, -1.6714e-01,  1.7798e-01,  1.0693e-01, -1.4467e-01,\n",
       "                         1.2682e-01, -8.2076e-02, -4.3517e-02, -2.7452e-02, -1.9797e-01,\n",
       "                         9.4747e-02],\n",
       "                       [ 1.2548e-01, -1.2572e-01,  1.8677e-01, -4.7612e-02, -2.4883e-02,\n",
       "                         6.1881e-02,  7.7362e-02,  2.3296e-01,  1.7173e-02,  1.2222e-01,\n",
       "                         4.4767e-02, -1.8961e-01,  3.5084e-01,  1.6496e-01, -4.7203e-01,\n",
       "                         2.3161e-01],\n",
       "                       [ 1.9742e-01,  1.0880e-02, -1.9738e-01,  2.0175e-02, -1.7629e-01,\n",
       "                        -2.3696e-02,  2.4070e-01,  2.4862e-01,  9.4088e-02, -1.9390e-01,\n",
       "                        -1.7920e-01, -2.4050e-01,  1.0841e-01, -1.2490e-01, -5.2530e-02,\n",
       "                         4.3457e-02],\n",
       "                       [ 2.7731e-02,  1.3963e-01, -3.7495e-01,  2.7587e-01, -8.6186e-02,\n",
       "                         1.6349e-01,  1.5592e-01, -3.0377e-01, -2.8502e-02,  1.2965e-01,\n",
       "                        -2.5124e-01,  4.1867e-01, -1.2070e-01, -2.3314e-01,  4.6938e-02,\n",
       "                         2.3923e-01],\n",
       "                       [ 9.2053e-02, -7.0098e-02, -2.9251e-03,  1.1563e-01,  1.6590e-01,\n",
       "                         1.7449e-01,  7.2349e-02, -3.0420e-02, -1.0911e-01, -2.2451e-01,\n",
       "                         6.9803e-03, -2.7671e-01,  2.7566e-02,  1.0113e-03, -1.1941e-01,\n",
       "                        -1.5534e-01],\n",
       "                       [ 1.3744e-01,  1.0878e-01, -1.1469e-01, -9.9041e-02, -4.8845e-02,\n",
       "                        -1.5302e-01,  2.4164e-01,  2.1145e-01,  3.1009e-01, -3.2354e-03,\n",
       "                         1.9846e-02, -3.7963e-01,  2.6791e-01,  2.6773e-01, -8.2621e-02,\n",
       "                         1.3311e-01],\n",
       "                       [ 1.8544e-02, -1.0372e-01,  1.0254e-01, -1.0186e-01, -2.0942e-01,\n",
       "                        -2.0864e-01,  1.2875e-03, -2.7182e-02, -4.6254e-02, -5.1782e-02,\n",
       "                         5.1337e-02,  3.1163e-02,  2.1613e-01, -2.6952e-01, -1.4635e-01,\n",
       "                         8.5219e-02],\n",
       "                       [-7.5525e-02, -1.4398e-02,  3.4450e-01, -4.6168e-02,  1.7766e-01,\n",
       "                        -6.6225e-02, -1.7530e-01,  9.0243e-02,  2.1581e-01,  5.1326e-02,\n",
       "                         2.5020e-01, -4.3923e-01,  1.2298e-01,  2.1662e-01, -5.0801e-01,\n",
       "                         1.5038e-01],\n",
       "                       [-1.1345e-01,  2.9501e-02,  2.7652e-02, -4.2276e-01, -3.2170e-02,\n",
       "                         2.4169e-01, -2.2441e-01,  9.9843e-02,  4.6511e-02,  2.0624e-01,\n",
       "                         6.6024e-02, -4.0167e-01,  7.4641e-02,  2.7630e-01, -9.4630e-02,\n",
       "                        -2.5504e-01],\n",
       "                       [-7.6172e-02,  1.4152e-01,  1.1291e-02, -3.3643e-01, -5.3005e-02,\n",
       "                        -6.1422e-03,  2.3742e-01,  1.8238e-02,  2.0536e-01,  2.3111e-03,\n",
       "                        -2.0629e-01, -1.7644e-01,  9.2585e-02,  7.5765e-02, -8.2901e-02,\n",
       "                        -2.6231e-01],\n",
       "                       [-1.7577e-01, -4.6226e-02,  2.0837e-02,  2.8515e-01, -5.4863e-02,\n",
       "                         1.7074e-01, -1.9288e-01,  1.9404e-01, -5.3519e-02,  2.5563e-01,\n",
       "                        -2.6115e-02, -3.0696e-01,  3.0216e-01,  1.4007e-01, -4.3990e-02,\n",
       "                         2.0114e-01],\n",
       "                       [ 3.6450e-01,  7.4999e-04, -1.2574e-01,  9.8458e-02,  3.1493e-01,\n",
       "                        -1.8125e-01,  2.3031e-01, -1.7483e-01, -4.3287e-02, -1.6153e-01,\n",
       "                        -1.3193e-02, -4.4325e-01, -1.3694e-01,  2.1848e-01, -2.9378e-01,\n",
       "                        -6.4823e-02]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([-0.0149,  0.0166,  0.3283,  0.0786, -0.2033,  0.2536, -0.2195,  0.0645,\n",
       "                        0.1002,  0.2574, -0.1450,  0.3907,  0.2424,  0.2249,  0.4876,  0.1594])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[-2.8143e-03,  2.9400e-01,  1.4699e-01,  2.1272e-02,  6.1763e-02,\n",
       "                        -4.3523e-02,  2.3529e-01, -2.6839e-01, -2.3531e-02,  1.9948e-01,\n",
       "                         4.4648e-02,  2.6245e-01,  2.1170e-01, -9.7387e-02,  3.8887e-01,\n",
       "                         4.7047e-02],\n",
       "                       [-2.1006e-01, -2.2991e-01, -1.5613e-01, -3.2080e-01, -1.4229e-01,\n",
       "                        -4.2889e-02, -1.3226e-01,  6.8490e-03,  1.1165e-01, -3.0216e-01,\n",
       "                         2.1817e-02, -2.1744e-01, -1.0979e-01,  1.4393e-01, -2.0410e-01,\n",
       "                        -1.8859e-01],\n",
       "                       [ 9.4986e-04,  2.0465e-02, -1.4241e-01, -1.3297e-01, -1.1723e-01,\n",
       "                        -2.1728e-01,  1.4881e-01,  2.9528e-02, -1.0870e-02,  6.3829e-02,\n",
       "                         1.6851e-01, -2.7404e-01,  1.4861e-01, -6.3584e-03, -2.7645e-01,\n",
       "                        -1.6437e-01],\n",
       "                       [ 2.1537e-01, -1.1887e-01,  3.8414e-02,  5.6650e-01, -1.9805e-01,\n",
       "                         9.3475e-04, -1.2954e-02,  4.9446e-01,  2.1784e-01,  7.0696e-02,\n",
       "                        -9.1410e-02, -4.0090e-02, -4.2970e-02,  2.2592e-01, -9.7053e-02,\n",
       "                        -7.9866e-02],\n",
       "                       [-2.3999e-01,  5.6216e-02,  8.5241e-02,  1.4835e-01, -4.8650e-02,\n",
       "                         1.6629e-01,  5.2848e-02, -2.4541e-01, -2.1655e-03, -3.0710e-01,\n",
       "                        -2.2676e-01, -2.9833e-01, -2.6425e-01, -2.7559e-01,  2.1061e-02,\n",
       "                        -2.3971e-01],\n",
       "                       [ 9.0524e-02,  3.9950e-03,  2.2511e-01,  2.5366e-01,  1.5737e-01,\n",
       "                        -2.7024e-01, -9.3643e-02,  2.0577e-03, -1.2155e-01,  1.9435e-01,\n",
       "                        -1.9086e-01, -9.7483e-02, -3.4339e-01, -7.3868e-02, -2.0457e-01,\n",
       "                         2.2187e-01],\n",
       "                       [ 1.7456e-01,  8.7180e-02,  8.8772e-02,  3.3723e-01,  2.0470e-01,\n",
       "                         3.2176e-01,  2.3485e-01, -3.5472e-01,  3.8035e-02,  1.7226e-01,\n",
       "                         6.6013e-02,  7.1790e-02,  3.1992e-01, -4.1094e-02, -4.4925e-02,\n",
       "                         8.5203e-02],\n",
       "                       [-1.9592e-01,  9.6663e-03,  2.2144e-01,  8.5814e-02, -1.0918e-01,\n",
       "                         2.7829e-01, -5.1688e-02, -1.0871e-01,  5.3666e-02, -6.0721e-05,\n",
       "                         1.2517e-01,  1.4188e-01,  8.1998e-02,  2.6963e-01, -1.2270e-01,\n",
       "                         3.1696e-01],\n",
       "                       [ 5.1584e-02, -1.4873e-01, -2.0887e-01, -1.5784e-01, -1.0614e-01,\n",
       "                        -5.0937e-01,  4.2523e-02,  6.5342e-02, -5.4466e-02, -6.4645e-02,\n",
       "                         2.0341e-01, -7.9712e-02, -2.4602e-01,  6.4613e-02,  8.1028e-02,\n",
       "                         1.6966e-01],\n",
       "                       [-1.0933e-01,  1.0113e-01, -5.2373e-02,  4.0831e-02,  7.4165e-02,\n",
       "                         2.1731e-01, -3.9391e-02, -6.0008e-02,  8.0793e-02,  2.9974e-01,\n",
       "                        -1.2157e-01,  9.9239e-02,  6.7002e-02,  3.1962e-01,  2.7289e-01,\n",
       "                         2.5733e-01],\n",
       "                       [-9.5075e-02,  1.2583e-01, -1.5258e-01, -9.8317e-02, -1.5475e-01,\n",
       "                        -1.5298e-01,  1.9877e-01, -3.2984e-01,  3.8375e-02,  9.4078e-02,\n",
       "                        -4.6158e-02, -2.0923e-01,  7.7951e-02, -3.6768e-01, -1.7944e-02,\n",
       "                        -1.5464e-01],\n",
       "                       [-2.5518e-01,  1.4223e-02, -1.2168e-01,  9.9365e-02, -1.6558e-04,\n",
       "                        -1.9051e-01,  5.6649e-02,  4.6652e-01, -3.2163e-02, -2.9572e-01,\n",
       "                         1.3530e-01,  2.9269e-02, -1.7077e-01, -2.1608e-01, -1.8398e-01,\n",
       "                        -2.4036e-01],\n",
       "                       [ 2.7148e-02, -1.9632e-01,  1.9587e-01,  4.0983e-02,  6.8523e-02,\n",
       "                         9.3028e-02,  2.0755e-01, -1.5568e-01, -1.9326e-01, -2.5351e-01,\n",
       "                         6.9672e-02, -9.8719e-03, -1.3032e-01,  8.1686e-02, -2.3768e-02,\n",
       "                        -6.5874e-02],\n",
       "                       [-1.2482e-01, -4.9402e-02, -7.9846e-02, -2.9462e-02, -7.9637e-02,\n",
       "                         1.6329e-01, -1.1695e-01,  2.3355e-01, -2.2451e-01, -2.2141e-01,\n",
       "                         1.6633e-01, -1.5910e-02,  2.1929e-01,  1.0326e-01, -2.7596e-01,\n",
       "                         3.3825e-02],\n",
       "                       [-1.2233e-01, -1.4842e-01,  2.7853e-01, -7.1424e-02, -1.1721e-01,\n",
       "                         2.9361e-01,  1.0348e-01, -1.8977e-01,  1.3911e-01,  1.8615e-01,\n",
       "                        -4.9190e-02,  3.5579e-01,  1.9857e-01,  2.0943e-01,  2.2117e-01,\n",
       "                         2.3747e-01],\n",
       "                       [ 3.0318e-01, -3.9228e-02, -1.4681e-03,  2.5214e-01, -9.7624e-03,\n",
       "                        -1.0851e-01,  1.1972e-01, -4.4587e-02,  3.5700e-01, -5.8738e-02,\n",
       "                         1.1283e-01,  1.1491e-01,  2.6734e-02,  2.9829e-01,  1.8808e-01,\n",
       "                        -1.2403e-02]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.3399,  0.1075, -0.3205, -0.0040,  0.0320, -0.2224,  0.3391,  0.0179,\n",
       "                       -0.1612,  0.2122,  0.0621,  0.1491, -0.1908, -0.6300,  0.4114,  0.0813])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[ 0.3611, -0.0225,  0.0014, -0.2622,  0.0061, -0.0679,  0.2792,  0.0971,\n",
       "                         0.0075,  0.1510, -0.1420, -0.4136,  0.1776,  0.7092,  0.3565,  0.0722]])),\n",
       "              ('layers.8.bias', tensor([-0.0850]))]),\n",
       " 'LQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[-0.0826, -0.1061],\n",
       "                       [-0.6991, -0.1286],\n",
       "                       [ 0.2072,  0.2918],\n",
       "                       [-0.7332, -0.2198],\n",
       "                       [-0.4805,  0.4532],\n",
       "                       [-0.2970,  0.3563],\n",
       "                       [-0.0624,  0.1516],\n",
       "                       [ 0.6385,  0.0173],\n",
       "                       [-0.2179,  0.1001],\n",
       "                       [-0.5876,  0.3690],\n",
       "                       [ 0.3805,  0.2347],\n",
       "                       [ 0.5794, -0.4650],\n",
       "                       [-0.7338, -0.1271],\n",
       "                       [ 0.6683, -0.0042],\n",
       "                       [ 0.3055,  0.2301],\n",
       "                       [-0.2337, -0.0204]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.7541,  0.8113, -0.7788,  0.0756, -0.4517,  0.2571,  0.6483,  0.1609,\n",
       "                       -0.4085, -0.4164,  0.8635,  0.4500,  0.5910, -0.5872,  0.6065,  0.3303])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[ 0.2797, -0.0021,  0.1892,  0.2408,  0.3153, -0.1424,  0.3001, -0.1983,\n",
       "                         0.1848,  0.3383, -0.0036, -0.0139,  0.4382, -0.6543, -0.0752,  0.1118],\n",
       "                       [ 0.3175, -0.3545,  0.0374, -0.1734, -0.1578,  0.1449,  0.2050,  0.4254,\n",
       "                        -0.2646, -0.3113,  0.0575,  0.4216, -0.0129,  0.2507,  0.2485, -0.2329],\n",
       "                       [-0.1521, -0.0782, -0.2292,  0.1876, -0.0344,  0.0721,  0.1722, -0.5315,\n",
       "                        -0.0705,  0.0261, -0.2052, -0.3042,  0.0809, -0.4739,  0.0895, -0.0258],\n",
       "                       [ 0.2051, -0.4885,  0.2238,  0.4886, -0.0419,  0.1522,  0.0469, -0.2250,\n",
       "                         0.0945,  0.0842,  0.2098,  0.1439, -0.2982, -0.1442,  0.0363, -0.3313],\n",
       "                       [-0.0908, -0.2198, -0.0202,  0.1608, -0.1834, -0.0701,  0.0715,  0.1629,\n",
       "                        -0.1206,  0.2037, -0.2396,  0.0252, -0.2610, -0.2605,  0.0489, -0.1017],\n",
       "                       [-0.0198,  0.0149,  0.1387, -0.1075,  0.1970,  0.0149, -0.1541, -0.0627,\n",
       "                        -0.0931, -0.2580, -0.2504, -0.2266,  0.0155,  0.1555,  0.1883,  0.1085],\n",
       "                       [-0.1057,  0.1379, -0.1412, -0.0537, -0.0016, -0.2985,  0.1493, -0.0384,\n",
       "                        -0.2637,  0.1543,  0.3037,  0.1316, -0.2722, -0.4935,  0.2800, -0.0814],\n",
       "                       [ 0.1324, -0.0461, -0.1201, -0.1309, -0.1612, -0.2033, -0.1073, -0.1202,\n",
       "                        -0.1489,  0.1788, -0.1145, -0.1682,  0.0781, -0.2144,  0.0020, -0.0776],\n",
       "                       [-0.0167, -0.0115,  0.1026, -0.0946, -0.0838,  0.1281, -0.1804,  0.1161,\n",
       "                         0.1414, -0.2047, -0.2337, -0.2428, -0.2502, -0.1718,  0.0993, -0.2937],\n",
       "                       [ 0.2733, -0.2404, -0.1023,  0.0178, -0.2271, -0.1343, -0.0212, -0.2559,\n",
       "                        -0.1336,  0.0912,  0.1943,  0.1613,  0.1439, -0.3705,  0.0296, -0.2893],\n",
       "                       [ 0.2658,  0.0503,  0.0330,  0.0105, -0.1138, -0.0600, -0.5978, -0.4663,\n",
       "                        -0.0980, -0.0543, -0.4329,  0.4035, -0.2571, -0.9308, -0.2303, -0.2929],\n",
       "                       [ 0.3310,  0.1119, -0.2098, -0.0016, -0.3616, -0.0815,  0.0600, -0.2423,\n",
       "                         0.1172, -0.0099,  0.3932,  0.2135,  0.0571, -0.4203, -0.0565, -0.1788],\n",
       "                       [ 0.2721, -0.0594, -0.2636, -0.1263, -0.1038, -0.0656,  0.0586, -0.0030,\n",
       "                        -0.0438, -0.0630,  0.2997,  0.0276, -0.1098, -0.5158,  0.1229, -0.2361],\n",
       "                       [-0.1227,  0.0635, -0.2443, -0.2797,  0.1089,  0.1048, -0.0275, -0.7887,\n",
       "                        -0.2849,  0.1095, -0.1900, -0.2501, -0.0951, -0.2973,  0.1671,  0.1692],\n",
       "                       [ 0.3418,  0.3543,  0.2352,  0.4040, -0.1039,  0.3117,  0.0508, -0.4452,\n",
       "                        -0.0995, -0.0445,  0.2179, -0.0406,  0.3743, -0.3658,  0.3243,  0.0874],\n",
       "                       [-0.0369, -0.0721,  0.0277, -0.2296, -0.0024, -0.1634,  0.2286, -0.5300,\n",
       "                         0.2042,  0.0776, -0.0940, -0.4231, -0.1206, -0.5711,  0.1889, -0.0816]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.2580,  0.1194,  0.0550,  0.1967,  0.0232, -0.1362,  0.2197, -0.0491,\n",
       "                        0.0746,  0.2045, -0.0499,  0.1178,  0.3101, -0.1614,  0.0143, -0.1074])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[-1.1422e-01,  8.8987e-02, -3.7078e-02,  2.9829e-02,  1.9196e-01,\n",
       "                        -1.4045e-01, -3.3932e-03, -6.5050e-02, -6.8338e-02, -9.2822e-02,\n",
       "                        -4.8406e-01, -2.0504e-01,  2.2642e-01,  4.0474e-03,  9.3533e-02,\n",
       "                        -2.2783e-01],\n",
       "                       [-2.0793e-01,  2.1733e-01, -1.7524e-01,  4.1405e-01,  2.4336e-01,\n",
       "                        -1.0867e-01,  1.8603e-01, -9.6514e-02,  1.7661e-01,  1.6890e-01,\n",
       "                        -1.9747e-01,  3.7819e-01,  2.7615e-01, -8.4643e-02, -1.8833e-01,\n",
       "                         2.1651e-01],\n",
       "                       [ 1.0907e-01, -1.1736e-02,  2.8151e-01, -1.7911e-01,  2.6900e-01,\n",
       "                         1.3867e-01, -8.7073e-02, -2.1209e-02, -1.3195e-01, -9.2354e-02,\n",
       "                        -5.4143e-02, -4.5674e-02,  2.2083e-01,  2.8107e-01,  3.9088e-01,\n",
       "                         4.7570e-02],\n",
       "                       [-1.2010e+00,  8.1027e-02, -2.2955e-01,  3.0087e-01, -1.1251e-01,\n",
       "                        -1.0869e-02, -1.1676e-01, -7.1194e-02, -4.1655e-03,  3.8987e-02,\n",
       "                        -1.1308e-01,  2.8167e-01,  3.4016e-01,  1.7561e-01, -9.5650e-01,\n",
       "                         7.5497e-02],\n",
       "                       [ 1.1522e-01, -2.4584e-01,  2.3171e-01,  8.1697e-02, -2.0518e-01,\n",
       "                        -2.1046e-01,  2.6443e-01,  1.3315e-01, -2.8741e-01,  1.2665e-01,\n",
       "                        -6.4824e-02, -1.2317e-03, -4.0686e-02, -1.0857e-01,  2.8036e-01,\n",
       "                         5.8607e-02],\n",
       "                       [ 3.1863e-01, -3.2861e-01, -7.2030e-02,  1.9118e-02,  1.7960e-01,\n",
       "                        -1.0212e-01, -1.2588e-02, -8.8470e-02,  1.3230e-01,  3.6834e-01,\n",
       "                         2.0563e-01,  3.9204e-01, -7.6494e-02, -1.2177e-01,  1.0062e-01,\n",
       "                         2.7861e-01],\n",
       "                       [ 8.0179e-02,  3.8783e-01,  3.6258e-02,  1.2312e-01,  5.3842e-02,\n",
       "                        -1.4596e-01,  3.4753e-01, -4.8756e-02,  1.8429e-01,  2.1557e-01,\n",
       "                        -1.6602e-01,  9.0333e-02, -2.0018e-02,  1.1861e-02, -1.2056e-01,\n",
       "                        -2.3029e-02],\n",
       "                       [-3.4366e-01, -1.2571e-01,  6.2332e-02,  1.9858e-01, -1.5787e-01,\n",
       "                         1.3993e-01,  2.8084e-01,  8.3608e-02, -1.7345e-02, -1.0823e-01,\n",
       "                        -1.2113e-03,  1.7175e-01,  1.4142e-01,  2.1008e-01, -3.4971e-01,\n",
       "                         2.5572e-01],\n",
       "                       [ 1.9500e-01, -1.5844e-01,  1.9098e-01, -8.7255e-02,  1.8612e-01,\n",
       "                         2.4580e-02,  1.9305e-01, -1.7347e-01, -7.5762e-02,  4.8939e-02,\n",
       "                         1.0472e-01, -6.3458e-03,  9.4390e-02, -1.0840e-01,  1.8378e-01,\n",
       "                        -1.7560e-01],\n",
       "                       [-1.7533e-01, -1.0551e-01, -1.6770e-01, -2.0903e-01,  1.3704e-01,\n",
       "                        -1.1086e-03,  2.0841e-02,  1.8230e-01,  1.7396e-01,  5.0110e-02,\n",
       "                         9.2859e-02,  1.1298e-01,  2.8549e-01, -2.1090e-01, -1.5329e-01,\n",
       "                        -3.9635e-01],\n",
       "                       [-1.7763e-01,  4.9830e-03,  5.6972e-02,  9.9726e-02,  1.5208e-01,\n",
       "                         1.1956e-01, -3.1182e-01,  1.5603e-01, -1.5119e-01, -2.9154e-01,\n",
       "                         5.7118e-02, -4.1658e-02, -2.3331e-01,  1.5076e-01, -4.5200e-02,\n",
       "                         1.0993e-01],\n",
       "                       [-3.8245e-01,  3.7085e-01, -8.2092e-02,  5.8055e-01, -1.6954e-01,\n",
       "                        -4.7108e-02,  1.4363e-01,  1.9325e-02, -1.6388e-01, -1.6014e-02,\n",
       "                        -4.6093e-01,  7.6049e-02,  3.3572e-01, -2.0654e-01, -2.0803e-02,\n",
       "                        -1.6894e-02],\n",
       "                       [-8.8253e-02, -8.7903e-02, -3.6278e-01, -3.2242e-01,  6.4680e-02,\n",
       "                         4.9491e-02,  5.8990e-02, -1.6901e-01,  1.0291e-01, -3.2986e-01,\n",
       "                         1.7962e-01, -3.3725e-01, -3.5878e-01, -2.3632e-01, -1.1091e-01,\n",
       "                        -1.9226e-01],\n",
       "                       [ 2.5975e-01, -1.7760e-01,  1.7808e-02,  2.4606e-01,  2.7873e-01,\n",
       "                        -1.2801e-01,  1.4911e-01, -2.2016e-01, -6.7869e-02, -1.6483e-02,\n",
       "                         1.3828e-01,  3.3278e-01,  2.7578e-01,  3.1184e-01,  3.4490e-01,\n",
       "                         6.9505e-02],\n",
       "                       [-2.8508e-02,  3.2618e-01,  2.0672e-01,  4.9212e-01, -2.5325e-01,\n",
       "                        -8.9884e-02,  2.1769e-01, -2.0158e-01, -1.9601e-01,  1.6940e-01,\n",
       "                        -1.1839e-01,  2.2855e-01,  3.4259e-01, -3.6536e-02, -9.1765e-02,\n",
       "                         5.0230e-02],\n",
       "                       [-1.4844e-02,  4.4754e-03, -2.5953e-02,  3.2980e-02, -2.0987e-01,\n",
       "                         2.4851e-01,  2.9979e-01,  9.4985e-02, -7.7137e-02,  5.0692e-02,\n",
       "                        -3.1732e-01,  2.6597e-01,  1.5546e-01,  8.3181e-02, -2.3841e-02,\n",
       "                         1.2768e-02]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([-0.0414,  0.4241,  0.0386,  0.4709,  0.2907,  0.3646,  0.0506,  0.1253,\n",
       "                        0.1734,  0.2299,  0.0611,  0.0672, -0.1310,  0.1640,  0.0304, -0.1261])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[ 1.1286e-01, -2.7577e-01, -1.8578e-01,  5.8697e-02, -1.8252e-01,\n",
       "                        -1.3809e-01,  1.8692e-02, -3.5537e-01, -2.1534e-01, -6.3202e-02,\n",
       "                        -2.2743e-02,  2.0019e-02,  1.8136e-01, -2.6257e-01,  1.1612e-01,\n",
       "                         1.9418e-02],\n",
       "                       [ 1.0043e-01,  4.3757e-01, -1.2726e-02,  1.4272e+00, -1.6355e-01,\n",
       "                         1.6818e-01,  1.8879e-01, -1.2324e-01,  9.4258e-02,  1.1091e-01,\n",
       "                        -1.3082e-01,  4.8437e-01, -6.4041e-03,  1.0492e-01,  1.0044e-01,\n",
       "                        -7.5615e-02],\n",
       "                       [ 3.6677e-02, -2.6097e-01,  2.3274e-04, -7.3419e-02, -1.6845e-01,\n",
       "                         6.4307e-02,  2.2784e-02, -1.2362e-01,  7.0489e-02, -1.6776e-02,\n",
       "                         3.4649e-02, -2.6095e-02, -1.8865e-01, -1.6498e-01,  5.0745e-02,\n",
       "                        -2.2900e-01],\n",
       "                       [ 8.5022e-02,  2.0022e-01, -2.5889e-01,  6.6947e-02,  3.6263e-02,\n",
       "                        -2.2453e-01,  4.2299e-01,  2.0284e-01, -3.0166e-01, -2.4043e-01,\n",
       "                         1.4800e-01,  4.6798e-01, -3.7459e-02, -1.2206e-01,  8.1754e-02,\n",
       "                         8.7721e-02],\n",
       "                       [ 4.5276e-02,  2.3387e-01, -5.0002e-02,  2.8016e-01,  4.1560e-01,\n",
       "                         4.0576e-01, -3.0157e-01,  3.0043e-01,  2.7956e-01,  1.3659e-01,\n",
       "                        -1.4115e-01, -1.8227e-01,  8.9640e-02,  3.8432e-01, -4.3493e-01,\n",
       "                        -2.5288e-01],\n",
       "                       [-9.8133e-03,  2.2864e-01,  3.3046e-02,  2.9708e-01, -1.8681e-01,\n",
       "                        -1.2207e-01,  3.7984e-01, -5.0647e-02, -1.7933e-01,  2.7227e-01,\n",
       "                         1.0778e-01,  1.0165e-01, -2.5754e-01,  2.3653e-01,  3.7854e-01,\n",
       "                         2.4023e-03],\n",
       "                       [-4.8395e-02, -2.9155e-02,  1.7218e-01, -1.5836e-01,  1.9486e-01,\n",
       "                         1.0318e-01, -3.3442e-01, -1.5797e-01,  1.5718e-01, -5.3007e-02,\n",
       "                        -9.3034e-02,  2.0644e-01,  5.5988e-02,  2.8329e-01, -3.5163e-01,\n",
       "                        -2.6435e-01],\n",
       "                       [ 1.3993e-01,  1.1265e-01,  1.1326e-01,  1.5576e-03,  2.9474e-01,\n",
       "                         3.1346e-01, -2.2356e-01, -2.2221e-03,  1.1345e-01,  1.9762e-01,\n",
       "                        -1.9351e-01, -1.3599e-01,  1.0848e-01, -8.7036e-03, -2.6388e-02,\n",
       "                         8.8453e-02],\n",
       "                       [ 1.6712e-02, -2.3878e-01, -2.0037e-02,  1.1159e-01, -2.6506e-02,\n",
       "                         4.2208e-02, -1.4051e-01,  7.9594e-02, -1.9311e-01, -3.9651e-02,\n",
       "                        -2.2745e-01,  1.0447e-01, -4.6937e-02, -2.1752e-01,  1.1234e-01,\n",
       "                        -4.1376e-02],\n",
       "                       [ 7.3280e-02, -2.4864e-01, -1.9849e-01, -3.4651e-02, -7.6681e-02,\n",
       "                        -1.7484e-01, -2.8577e-02,  1.2453e-01,  2.1643e-01,  1.0068e-01,\n",
       "                        -1.7257e-01,  5.5984e-04, -1.2708e-01,  1.1389e-01, -9.9430e-02,\n",
       "                        -1.0956e-01],\n",
       "                       [ 1.8768e-01,  4.1238e-01, -1.3294e-01,  1.8909e-01,  5.8923e-02,\n",
       "                        -1.3878e-01,  1.2810e-01,  3.1172e-01,  1.4036e-01,  3.1678e-01,\n",
       "                        -2.1451e-01,  3.7486e-01,  4.1312e-02,  1.5557e-01,  2.5901e-01,\n",
       "                        -9.0141e-02],\n",
       "                       [-8.8878e-02,  4.3512e-01, -1.5814e-01, -1.3259e-01, -2.1772e-01,\n",
       "                        -4.4722e-01,  1.4407e-01,  4.1114e-01, -5.9841e-01,  4.0326e-02,\n",
       "                         4.6568e-02,  3.2009e-02,  2.3682e-01, -2.1717e-01,  2.0986e-01,\n",
       "                         1.7004e-01],\n",
       "                       [ 7.5912e-02,  2.4176e-01,  1.1255e-01, -2.4238e-02,  2.5556e-01,\n",
       "                         3.1578e-01, -4.0521e-02,  1.4254e-01,  1.9633e-01,  6.6174e-02,\n",
       "                         1.8722e-01,  2.5838e-02,  2.6731e-01,  1.4554e-01, -3.2867e-01,\n",
       "                         1.3933e-01],\n",
       "                       [ 4.8651e-02,  9.5445e-02, -2.8050e-01,  8.8653e-02, -1.1032e-01,\n",
       "                         5.0728e-02,  1.5264e-02, -2.4280e-01, -7.4338e-02, -2.2675e-01,\n",
       "                        -2.2382e-01, -5.3648e-02, -1.4857e-01, -3.2441e-01, -1.0486e-01,\n",
       "                        -8.1260e-02],\n",
       "                       [ 1.7103e-01, -7.2891e-02, -2.0753e-01, -7.3704e-03,  1.2287e-01,\n",
       "                        -1.2144e-01, -1.5866e-01, -7.1942e-02,  1.0418e-01, -1.0648e-01,\n",
       "                        -4.6296e-02, -5.0978e-02, -2.2572e-01, -5.7356e-02,  6.5058e-02,\n",
       "                         1.8374e-01],\n",
       "                       [ 8.8966e-02,  1.1220e-01,  2.7782e-01,  3.5564e-01,  6.7077e-02,\n",
       "                         1.4935e-01,  2.0884e-02,  3.3751e-02,  7.1088e-02,  1.7938e-01,\n",
       "                         2.7027e-01, -3.7310e-01,  2.8475e-01,  3.7619e-01, -4.1012e-01,\n",
       "                        -2.2420e-01]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([-0.2892,  0.0064, -0.0367,  0.0566,  0.4275,  0.1116,  0.2770,  0.2136,\n",
       "                       -0.0801, -0.1236,  0.0222,  0.1872, -0.0322, -0.0089, -0.1186,  0.2031])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[-0.1152,  0.2029, -0.0248,  0.1212, -0.1844,  0.1000, -0.1092, -0.1247,\n",
       "                        -0.0031,  0.1901,  0.1580,  0.1295, -0.1020, -0.0035, -0.0336, -0.1847]])),\n",
       "              ('layers.8.bias', tensor([-0.0941]))])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define quantiles and hyperparameters\n",
    "q_median = 0.5\n",
    "q_upper = 0.975\n",
    "q_lower = 0.025\n",
    "# dims = model['dims']\n",
    "dims = (2, 16, 16, 16, 16, 1)\n",
    "lr = model['lr']\n",
    "batch_size = int(model['batch_size'])\n",
    "epoch = model['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch size: 500\n",
      "epoch: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"lr:\", lr)\n",
    "print(\"batch size:\", batch_size)\n",
    "print(\"epoch:\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done C_WTG01\n",
      "Done C_WTG02\n",
      "Done C_WTG03\n",
      "Done C_WTG04\n",
      "Done C_WTG05\n",
      "Done C_WTG06\n",
      "Done C_WTG07\n",
      "Done C_WTG08\n",
      "Done C_WTG09\n",
      "Done C_WTG10\n",
      "Done C_WTG11\n",
      "Done C_WTG12\n",
      "Done C_WTG13\n",
      "Done C_WTG14\n",
      "Done C_WTG15\n",
      "Done C_WTG16\n",
      "Done C_WTG17\n",
      "Done C_WTG18\n",
      "Done C_WTG19\n",
      "Done C_WTG20\n",
      "Done C_WTG21\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################################### training ######################################################### \n",
    "\n",
    "turbines = data_finetune.instanceID.unique()\n",
    "median_state_dict_all = []\n",
    "UQ_state_dict_all = []\n",
    "LQ_state_dict_all = []\n",
    "\n",
    "\n",
    "for ID in turbines:\n",
    "    \n",
    "    # select data based on turbine ID\n",
    "    data_temp = data_finetune[data_finetune['instanceID'] == ID]\n",
    "\n",
    "    # normalize data\n",
    "    X = scaler1.transform(data_temp.iloc[:, 5:-1])\n",
    "    y = scaler2.transform(data_temp.iloc[:, -1:])\n",
    "    \n",
    "    # create network and load pretrain weights\n",
    "    net_median_temp = Net(dims = dims)\n",
    "    net_median_temp.load_state_dict(pretrain['median'])\n",
    "    \n",
    "    net_upper_temp = Net(dims = dims)\n",
    "    net_upper_temp.load_state_dict(pretrain['UQ'])\n",
    "    \n",
    "    net_lower_temp = Net(dims = dims)\n",
    "    net_lower_temp.load_state_dict(pretrain['LQ'])\n",
    "    \n",
    "    # train\n",
    "    net_median_temp, median_state_dict = train(X=X, y=y, quantile=q_median, net=net_median_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_upper_temp, UQ_state_dict = train(X=X, y=y, quantile=q_upper, net=net_upper_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_lower_temp, LQ_state_dict = train(X=X, y=y, quantile=q_lower, net=net_lower_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    \n",
    "    median_state_dict_all.append(median_state_dict)\n",
    "    UQ_state_dict_all.append(UQ_state_dict)\n",
    "    LQ_state_dict_all.append(LQ_state_dict)\n",
    "    \n",
    "    print('Done', ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_state_dict_all_zip = dict(zip(turbines, median_state_dict_all))\n",
    "UQ_state_dict_all_zip = dict(zip(turbines, UQ_state_dict_all))\n",
    "LQ_state_dict_all_zip = dict(zip(turbines, LQ_state_dict_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save trained network\n",
    "\n",
    "torch.save(median_state_dict_all_zip, sys.path[0] + '/median.pth')\n",
    "torch.save(UQ_state_dict_all_zip, sys.path[0] + '/UQ.pth')\n",
    "torch.save(LQ_state_dict_all_zip, sys.path[0] + '/LQ.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
