{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from typing import Iterable\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from joblib import dump, load\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data_finetune = pd.read_csv(\"data_finetune.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>instanceID</th>\n",
       "      <th>Wind_speed</th>\n",
       "      <th>Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958671</th>\n",
       "      <td>2020-11-13 00:30:00</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>6.343173</td>\n",
       "      <td>496.738776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682500</th>\n",
       "      <td>2020-08-13 16:40:00</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>3.461359</td>\n",
       "      <td>42.106780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827043</th>\n",
       "      <td>2020-09-30 11:50:00</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>3.595130</td>\n",
       "      <td>58.858180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278880</th>\n",
       "      <td>2020-04-02 05:20:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>16.338689</td>\n",
       "      <td>2043.203491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794451</th>\n",
       "      <td>2020-09-19 17:10:00</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>C_WTG01</td>\n",
       "      <td>6.913757</td>\n",
       "      <td>614.239596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580775</th>\n",
       "      <td>2020-07-11 01:10:00</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.650944</td>\n",
       "      <td>830.078456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122912</th>\n",
       "      <td>2020-02-10 15:20:00</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.982645</td>\n",
       "      <td>825.983393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11129</th>\n",
       "      <td>2020-01-04 16:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>6.100355</td>\n",
       "      <td>653.990937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855014</th>\n",
       "      <td>2020-10-09 17:40:00</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>4.106625</td>\n",
       "      <td>166.245071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564836</th>\n",
       "      <td>2020-07-05 18:40:00</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>C_WTG21</td>\n",
       "      <td>9.763854</td>\n",
       "      <td>1889.555786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ts  Month  Day  Hour instanceID  Wind_speed  \\\n",
       "958671  2020-11-13 00:30:00     11   13     0    C_WTG01    6.343173   \n",
       "682500  2020-08-13 16:40:00      8   13    16    C_WTG01    3.461359   \n",
       "827043  2020-09-30 11:50:00      9   30    11    C_WTG01    3.595130   \n",
       "278880  2020-04-02 05:20:00      4    2     5    C_WTG01   16.338689   \n",
       "794451  2020-09-19 17:10:00      9   19    17    C_WTG01    6.913757   \n",
       "...                     ...    ...  ...   ...        ...         ...   \n",
       "580775  2020-07-11 01:10:00      7   11     1    C_WTG21    6.650944   \n",
       "122912  2020-02-10 15:20:00      2   10    15    C_WTG21    6.982645   \n",
       "11129   2020-01-04 16:10:00      1    4    16    C_WTG21    6.100355   \n",
       "855014  2020-10-09 17:40:00     10    9    17    C_WTG21    4.106625   \n",
       "564836  2020-07-05 18:40:00      7    5    18    C_WTG21    9.763854   \n",
       "\n",
       "              Power  \n",
       "958671   496.738776  \n",
       "682500    42.106780  \n",
       "827043    58.858180  \n",
       "278880  2043.203491  \n",
       "794451   614.239596  \n",
       "...             ...  \n",
       "580775   830.078456  \n",
       "122912   825.983393  \n",
       "11129    653.990937  \n",
       "855014   166.245071  \n",
       "564836  1889.555786  \n",
       "\n",
       "[210000 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load normalization function \n",
    "scaler1 = load('scaler1.bin')\n",
    "scaler2 = load('scaler2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_count = data_finetune['instanceID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dims: Iterable[int], output_activation: nn.Module = None):\n",
    "        \"\"\"Creates a network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = dims[0]\n",
    "        self.out_size = dims[-1]\n",
    "        self.layers = self.make_seq(dims, output_activation)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_seq(dims: Iterable[int], output_activation: nn.Module) -> nn.Module:\n",
    "        \"\"\"Creates a sequential network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        :return (nn.Module): return created sequential layers\n",
    "        \"\"\"\n",
    "        mods = []\n",
    "\n",
    "        for i in range(len(dims) - 2):\n",
    "            mods.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            mods.append(nn.ReLU())\n",
    "\n",
    "        mods.append(nn.Linear(dims[-2], dims[-1]))\n",
    "        if output_activation:\n",
    "            mods.append(output_activation())\n",
    "        return nn.Sequential(*mods)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Computes a forward pass through the network\n",
    "\n",
    "        :param x (torch.Tensor): input tensor to feed into the network\n",
    "        :return (torch.Tensor): output computed by the network\n",
    "        \"\"\"\n",
    "        # Feedforward\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, quantile, net, lr, batch_size, epoch):    \n",
    "    \n",
    "    # create tensor dataset\n",
    "    train = TensorDataset(Tensor(X), Tensor(y))\n",
    "\n",
    "    # create data loader from dataset\n",
    "    trainset = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr = lr)\n",
    "        \n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for ep in range(epoch):\n",
    "\n",
    "        for t in trainset:\n",
    "            X_temp, y_temp = t\n",
    "            output = net(X_temp)\n",
    "            residual = y_temp - output\n",
    "            loss = Tensor.max(quantile*residual, (quantile-1)*residual).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return net, net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use a very low learning rate at this stage, because we are training on a dataset that is very small. This is to prevent the risk of overfitting very quickly if we apply large weight updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hyperparameters\n",
    "model = torch.load(sys.path[0] +  '/hparams_finetune.pth')\n",
    "\n",
    "# load the pretrained weights\n",
    "pretrain = torch.load(sys.path[0] + '/pretrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median': OrderedDict([('layers.0.weight',\n",
       "               tensor([[ 0.4175],\n",
       "                       [ 0.6021],\n",
       "                       [-0.3152],\n",
       "                       [-0.0305],\n",
       "                       [ 0.7094],\n",
       "                       [ 0.6145],\n",
       "                       [-1.1585],\n",
       "                       [-0.3033],\n",
       "                       [ 0.2453],\n",
       "                       [ 0.5498],\n",
       "                       [-0.0934],\n",
       "                       [ 0.6481],\n",
       "                       [ 0.1058],\n",
       "                       [ 0.3426],\n",
       "                       [ 0.7285],\n",
       "                       [-0.0037]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([-0.3172, -0.8118,  0.2986,  0.1882,  0.3050, -0.0584, -0.4564,  0.4412,\n",
       "                        0.4808,  0.6898,  1.1586,  0.8732, -0.8024,  0.6636,  0.0805, -0.0071])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[ 3.1792e-02, -6.7930e-01, -7.2555e-02, -3.8765e-02,  1.3527e-01,\n",
       "                        -8.8308e-02,  4.0844e-02, -1.0233e-02, -8.9591e-03,  3.0162e-01,\n",
       "                         3.1685e-01,  1.7777e-01, -1.1310e-01,  6.4624e-02, -5.5034e-02,\n",
       "                         4.9606e-02],\n",
       "                       [-2.5698e-01, -1.2341e-01, -1.7292e-01,  1.7469e-01,  2.9250e-02,\n",
       "                        -3.2539e-02,  3.9216e-01, -1.9562e-01, -2.4067e-01, -3.1748e-01,\n",
       "                         5.7114e-02, -1.3516e-01,  1.3315e-01, -1.6290e-01, -1.8724e-01,\n",
       "                        -2.0579e-01],\n",
       "                       [-1.5673e-01, -3.6964e-01,  8.4406e-02,  2.2260e-01,  2.6433e-01,\n",
       "                         1.9373e-01, -2.3832e-01, -2.9593e-01,  1.2956e-01,  3.4407e-01,\n",
       "                         1.9561e-01,  3.4358e-01,  8.7650e-02,  2.3376e-02, -8.9480e-03,\n",
       "                         9.9246e-02],\n",
       "                       [-5.0637e-01, -6.1887e-01,  2.1590e-01,  6.2370e-02, -6.9351e-02,\n",
       "                        -3.6765e-01,  2.7060e-01,  3.9309e-01,  1.5384e-01,  1.9002e-01,\n",
       "                         1.6919e-01, -1.1440e-01, -1.0006e-01,  2.2981e-01, -1.7150e-01,\n",
       "                         6.8394e-03],\n",
       "                       [ 1.4539e-01,  4.4072e-01,  3.2617e-01,  6.9424e-02,  1.7296e-01,\n",
       "                         1.2080e-01, -2.3228e-02,  2.4969e-01,  2.1594e-02,  1.6597e-01,\n",
       "                        -1.6272e-01, -5.8791e-02, -8.7708e-02, -2.7199e-02, -1.4743e-01,\n",
       "                         5.0496e-02],\n",
       "                       [-4.7648e-03, -4.1397e-01, -1.1845e-01, -1.7853e-01, -1.5689e-01,\n",
       "                         1.8363e-02, -1.3105e-01, -1.6648e-01,  3.2776e-01,  1.4188e-01,\n",
       "                         1.1738e-01, -5.6130e-02, -1.0091e-01,  2.7455e-01,  2.4677e-01,\n",
       "                         7.5468e-02],\n",
       "                       [ 2.1615e-01, -1.7566e-01, -3.4016e-02, -9.7939e-03,  2.1309e-01,\n",
       "                        -2.3330e-01, -5.9348e-02,  4.6994e-02,  2.1838e-01, -1.3276e-01,\n",
       "                        -2.4035e-01,  5.4264e-02, -8.3495e-02,  1.3222e-01, -2.0809e-01,\n",
       "                         1.0574e-04],\n",
       "                       [ 8.5462e-02, -2.2471e-01, -7.1385e-02,  2.1565e-01,  2.0979e-01,\n",
       "                        -1.1273e-01, -1.0191e-01, -7.0800e-02, -1.9669e-01, -6.7037e-03,\n",
       "                         9.9734e-02, -1.5408e-02, -1.8826e-01, -2.3343e-01, -1.6565e-01,\n",
       "                        -2.4368e-01],\n",
       "                       [-3.6069e-01, -4.4878e-02,  3.4615e-01,  1.8278e-01,  1.6036e-02,\n",
       "                         1.0323e-01,  2.9516e-01,  3.0735e-01, -7.5996e-03, -5.0481e-02,\n",
       "                         3.8939e-01, -1.5390e-01,  1.4375e-01,  2.3545e-02, -6.0166e-02,\n",
       "                        -1.5149e-01],\n",
       "                       [-7.3231e-02,  1.4801e-01, -1.4025e-01,  7.6954e-02, -2.0936e-01,\n",
       "                        -1.3016e-01, -1.5182e-01,  4.5982e-03, -2.4241e-01, -1.1742e-01,\n",
       "                         6.7003e-02, -1.9876e-02,  1.7150e-01, -2.4154e-01,  5.5489e-02,\n",
       "                        -1.9358e-01],\n",
       "                       [-3.0085e-01, -2.4770e-01, -1.6177e-01,  2.7741e-01, -9.2420e-02,\n",
       "                         1.1540e-01, -2.5930e-01, -3.1154e-01, -2.8853e-02,  2.5544e-01,\n",
       "                         1.8988e-01, -1.1245e-01, -9.4108e-02,  2.6343e-01, -4.6804e-03,\n",
       "                        -4.7957e-02],\n",
       "                       [-2.6087e-01, -6.6999e-01, -5.1589e-01,  6.9456e-02,  2.3343e-01,\n",
       "                        -7.8486e-02, -1.3921e-01, -2.9216e-01,  1.5578e-01,  6.2167e-02,\n",
       "                         1.8291e-01,  2.3125e-01,  8.1030e-03,  3.0925e-01,  1.8616e-03,\n",
       "                        -1.9942e-01],\n",
       "                       [-1.8941e-01,  1.2429e-01,  3.0834e-02,  1.7189e-01, -2.1521e-02,\n",
       "                        -2.2960e-01, -1.3279e-01, -6.2117e-02, -2.4625e-01, -9.4141e-02,\n",
       "                        -1.1253e-02,  1.6980e-01, -2.3969e-02, -2.6569e-02,  1.0428e-01,\n",
       "                        -2.3619e-01],\n",
       "                       [-1.1848e-01, -4.1696e-01, -4.7920e-01,  1.5677e-01,  5.7845e-02,\n",
       "                         1.2141e-01, -2.5391e-01, -2.9541e-01, -7.3170e-02, -2.5595e-02,\n",
       "                         2.3858e-01,  1.9918e-01, -1.7285e-01,  1.1585e-01, -7.8618e-02,\n",
       "                         2.4606e-01],\n",
       "                       [ 5.0570e-02, -2.1787e-01,  1.1420e-01,  1.3894e-01, -1.7345e-01,\n",
       "                        -1.8741e-01, -2.2022e-01,  1.7581e-02, -2.5990e-01,  1.5043e-01,\n",
       "                        -1.0702e-01, -8.9745e-02,  1.0589e-01, -1.0891e-01, -3.0224e-02,\n",
       "                         1.6250e-01],\n",
       "                       [-6.9288e-02, -6.6232e-01, -4.0452e-01,  2.0649e-01,  2.0841e-01,\n",
       "                         9.0864e-02, -2.3378e-01, -2.9859e-01,  2.4587e-01,  2.2984e-01,\n",
       "                         4.8659e-02,  2.2317e-01, -8.1167e-02,  3.0849e-01,  3.6196e-02,\n",
       "                        -2.2012e-01]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.0028,  0.0178, -0.1522,  0.2802, -0.0449,  0.1500,  0.0627, -0.1940,\n",
       "                        0.1987,  0.0014, -0.1545, -0.2107, -0.1066,  0.3284,  0.0716,  0.0482])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[ 8.5014e-03, -1.5981e-01, -2.3004e-01,  1.7180e-01,  5.2953e-04,\n",
       "                        -1.2631e-01, -2.1159e-01, -2.0183e-02, -2.4350e-01, -1.2947e-01,\n",
       "                        -2.0381e-01,  1.2277e-01,  7.4139e-02,  2.3748e-01, -2.2157e-01,\n",
       "                        -1.3846e-01],\n",
       "                       [ 3.5836e-01,  2.3460e-01,  2.1682e-01, -4.2074e-01, -1.7453e-01,\n",
       "                         6.0570e-02, -1.7367e-01,  7.5988e-02, -3.8623e-01,  1.8989e-01,\n",
       "                         7.8033e-02,  1.5598e-01,  1.4210e-01,  2.9520e-01, -1.7770e-01,\n",
       "                         1.3857e-01],\n",
       "                       [-3.2176e-02, -7.3697e-02,  2.9846e-02, -1.8600e-01, -1.1290e-01,\n",
       "                         8.3481e-02,  1.1843e-01, -2.2289e-01,  8.1169e-02, -6.5634e-02,\n",
       "                         5.5953e-02, -3.6302e-02, -8.3995e-02,  1.6811e-01, -7.4583e-02,\n",
       "                        -9.8114e-02],\n",
       "                       [ 8.0844e-02,  2.3871e-01, -3.4467e-01,  1.6357e-01,  4.2109e-02,\n",
       "                         1.2629e-01, -8.9378e-03, -1.9266e-01,  2.7223e-01,  1.9583e-01,\n",
       "                        -4.4795e-02, -7.7028e-02, -1.2313e-01,  1.1307e-01,  2.1338e-01,\n",
       "                        -1.1915e-02],\n",
       "                       [ 3.1769e-01, -1.5395e-01, -4.2421e-02, -6.3496e-02,  1.6720e-01,\n",
       "                         2.7353e-01,  8.0308e-02, -1.5887e-01, -7.7981e-02, -9.2695e-03,\n",
       "                        -1.3310e-01,  3.6243e-01, -2.3298e-01,  2.0216e-01, -1.5907e-01,\n",
       "                         3.4253e-01],\n",
       "                       [ 2.0219e-01,  1.0989e-01,  1.2381e-02, -1.2913e-01, -2.4324e-01,\n",
       "                        -2.2096e-01, -9.2732e-02,  1.6306e-01, -1.2132e-01, -8.8491e-02,\n",
       "                        -1.9069e-01,  1.0051e-01,  1.8165e-01,  1.1636e-01, -1.6362e-01,\n",
       "                        -1.3732e-01],\n",
       "                       [-6.1853e-02, -9.7344e-02,  3.2648e-01, -3.6176e-01,  6.3762e-02,\n",
       "                         2.1288e-01, -6.4222e-02,  2.2557e-02,  3.5237e-02, -4.7507e-02,\n",
       "                         9.0305e-02, -5.0529e-02, -1.8645e-01,  6.8573e-02,  1.2265e-01,\n",
       "                         1.3270e-01],\n",
       "                       [ 2.5150e-01,  3.2398e-02,  2.7046e-02, -6.3029e-01, -2.4148e-01,\n",
       "                        -9.7069e-02,  6.9413e-02, -5.2771e-02, -3.1689e-01, -7.2317e-03,\n",
       "                         5.1222e-02,  3.6059e-02, -1.0595e-01,  1.1329e-01, -2.9653e-01,\n",
       "                         2.9890e-01],\n",
       "                       [ 3.6613e-01,  1.1394e-01,  9.8857e-02,  6.9555e-02, -7.7322e-04,\n",
       "                        -2.0760e-02,  1.5651e-01, -1.4671e-01, -2.1634e-01, -9.6535e-02,\n",
       "                        -2.4638e-03,  3.3039e-01, -1.7002e-02,  1.0256e-01, -1.0336e-01,\n",
       "                         3.1659e-01],\n",
       "                       [-1.2090e-01,  6.2948e-03,  1.1935e-01, -1.0542e-01, -1.5736e-01,\n",
       "                         2.8220e-01, -1.4547e-01,  9.1494e-02, -2.7077e-01,  1.9062e-02,\n",
       "                         1.1339e-01,  3.1039e-01, -1.5984e-01,  3.0301e-01, -8.7913e-02,\n",
       "                         1.7453e-01],\n",
       "                       [ 2.1049e-01,  4.3665e-02, -1.7861e-01,  2.4511e-01,  6.4577e-02,\n",
       "                         4.7038e-02,  2.2900e-01, -3.6483e-02,  3.0271e-01,  4.7375e-02,\n",
       "                         2.1657e-02, -1.6307e-01, -1.2417e-01,  6.1375e-02, -1.5321e-01,\n",
       "                        -1.6974e-01],\n",
       "                       [ 4.3335e-02, -1.0242e-01,  1.8429e-01, -1.4159e-01,  2.4475e-01,\n",
       "                         2.9214e-02,  9.2742e-02,  2.4979e-01,  1.0049e-01,  6.4193e-02,\n",
       "                         1.3435e-01,  2.7385e-01, -4.1362e-02,  3.0539e-01, -4.2007e-02,\n",
       "                        -8.4725e-02],\n",
       "                       [-1.3590e-01,  2.0155e-01, -2.3031e-01,  6.9313e-02, -1.6752e-01,\n",
       "                        -3.1150e-01,  1.6819e-01, -1.7224e-01,  2.1119e-01,  2.1100e-01,\n",
       "                        -2.4283e-01,  1.2510e-01,  1.1740e-01, -2.1874e-01,  5.1812e-02,\n",
       "                         1.0965e-02],\n",
       "                       [ 1.6907e-01, -4.5852e-02, -8.9567e-02, -4.6052e-02, -2.6981e-01,\n",
       "                        -3.8906e-02, -1.3607e-01, -1.9072e-01, -2.0336e-01,  5.2208e-02,\n",
       "                        -8.4262e-02, -1.1017e-01,  1.3384e-01,  4.8590e-02, -1.6986e-01,\n",
       "                         1.1863e-01],\n",
       "                       [-1.2725e-01,  1.7780e-01, -2.2341e-01, -8.9172e-02, -4.6151e-01,\n",
       "                         8.2736e-02, -1.6876e-01, -4.6543e-02, -9.6004e-02, -7.0241e-02,\n",
       "                        -3.6571e-01, -1.2950e-01, -2.2597e-01,  1.7383e-01, -1.6850e-01,\n",
       "                        -2.2406e-01],\n",
       "                       [-6.3508e-02, -1.8676e-01, -1.0106e-01,  3.2235e-01,  1.4269e-01,\n",
       "                        -3.9624e-02, -1.0621e-01, -1.0578e-01,  3.7108e-01,  1.4517e-01,\n",
       "                         2.0109e-02,  1.9784e-01, -8.8769e-02, -9.8010e-03,  2.0742e-01,\n",
       "                         1.5298e-01]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([-0.0424,  0.0956,  0.1435,  0.2038,  0.0865, -0.0710,  0.0329,  0.1426,\n",
       "                        0.0609,  0.2156,  0.2159, -0.0927,  0.1164, -0.1858,  0.2065,  0.3802])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[-0.1256, -0.1510,  0.2042,  0.3406, -0.0999, -0.0749, -0.2777, -0.0352,\n",
       "                         0.0456, -0.0990,  0.3701, -0.2209,  0.0755,  0.0078,  0.1538,  0.3857],\n",
       "                       [ 0.1876, -0.0528, -0.2087,  0.1380, -0.2482, -0.1170, -0.1163,  0.1764,\n",
       "                         0.1301, -0.3034, -0.1864,  0.1168, -0.3102,  0.0810, -0.1162, -0.1840],\n",
       "                       [ 0.1755, -0.2411, -0.1213, -0.2078,  0.1118,  0.2051, -0.2340, -0.0627,\n",
       "                        -0.0309, -0.0155,  0.0293,  0.0659, -0.2431, -0.1045,  0.1095, -0.1221],\n",
       "                       [ 0.1689, -0.2409, -0.0466, -0.1109,  0.0880,  0.1532, -0.1768, -0.1905,\n",
       "                        -0.1867, -0.2680, -0.2723,  0.2132, -0.1539, -0.1122, -0.2096, -0.2694],\n",
       "                       [-0.1369,  0.2314,  0.2423, -0.0692,  0.0252,  0.0848,  0.1290,  0.3319,\n",
       "                         0.2956,  0.1350,  0.3204, -0.1744,  0.0545, -0.1496,  0.1542, -0.1077],\n",
       "                       [-0.1219, -0.1548, -0.1695, -0.0076,  0.0494,  0.1414,  0.0394, -0.0644,\n",
       "                        -0.1673, -0.1706, -0.1794, -0.1101,  0.0763, -0.0387,  0.2433, -0.3206],\n",
       "                       [-0.2254, -0.0612, -0.0790, -0.1538, -0.2129, -0.0207, -0.2442,  0.1647,\n",
       "                        -0.0910,  0.2318, -0.2190, -0.1387,  0.1947,  0.1515,  0.0695, -0.0977],\n",
       "                       [ 0.1026,  0.3784, -0.1177, -0.0154,  0.2911, -0.1105,  0.1031,  0.4295,\n",
       "                         0.0668,  0.2599, -0.3479,  0.1983, -0.0433,  0.2013, -0.0365,  0.0281],\n",
       "                       [-0.1173,  0.1241, -0.2440,  0.2255,  0.0076,  0.1887,  0.0218,  0.2235,\n",
       "                        -0.0134, -0.1394, -0.2253, -0.0802, -0.1845,  0.1300,  0.0708, -0.1100],\n",
       "                       [ 0.2272,  0.1549,  0.1796, -0.3200,  0.1151,  0.1268, -0.0602, -0.1370,\n",
       "                        -0.0372, -0.1703,  0.0504, -0.1921, -0.2483,  0.0777, -0.3436,  0.1017],\n",
       "                       [ 0.1791,  0.1718, -0.0338,  0.0723, -0.3227, -0.1624, -0.0089,  0.0676,\n",
       "                        -0.2963,  0.0389,  0.3210,  0.0402,  0.1581,  0.0616, -0.0027,  0.0544],\n",
       "                       [-0.0307,  0.2178,  0.1527, -0.2254,  0.3441, -0.0185,  0.2471,  0.1618,\n",
       "                         0.3352,  0.2892, -0.2459,  0.2222, -0.1471, -0.2033, -0.1762,  0.2390],\n",
       "                       [-0.1733, -0.0459, -0.1375, -0.0906, -0.1932,  0.2186, -0.1070,  0.0548,\n",
       "                        -0.1904,  0.2208,  0.2645, -0.0881,  0.1515,  0.1200,  0.2835,  0.1413],\n",
       "                       [-0.0171,  0.3492, -0.0975,  0.0282, -0.0501,  0.1885,  0.1913,  0.3591,\n",
       "                         0.3331,  0.0023, -0.0149,  0.2168,  0.1002,  0.2585, -0.2742, -0.0489],\n",
       "                       [-0.0678, -0.0622, -0.1061, -0.1121,  0.0425,  0.2270,  0.2418, -0.0528,\n",
       "                        -0.1520, -0.1985,  0.0452, -0.0248,  0.0549,  0.0495,  0.0451, -0.1970],\n",
       "                       [-0.0348,  0.0389, -0.1061,  0.0604, -0.2487, -0.0317,  0.1594, -0.1006,\n",
       "                         0.0770, -0.0996,  0.0201,  0.1883, -0.2481,  0.0936,  0.1093, -0.0261]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.4022,  0.1647, -0.0879,  0.1702,  0.0458, -0.2529, -0.0712,  0.0773,\n",
       "                       -0.1429, -0.0071,  0.4504,  0.2070,  0.3196, -0.0670, -0.1046, -0.0516])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[-0.4018,  0.1464, -0.0611,  0.1929,  0.1121, -0.0570, -0.0761,  0.2674,\n",
       "                        -0.0233,  0.0056, -0.3397,  0.2699, -0.1176,  0.1244, -0.2493,  0.0235]])),\n",
       "              ('layers.8.bias', tensor([-0.0054]))]),\n",
       " 'UQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[ 0.0958],\n",
       "                       [-0.9040],\n",
       "                       [ 0.0728],\n",
       "                       [-0.6993],\n",
       "                       [-0.7516],\n",
       "                       [-0.8863],\n",
       "                       [ 0.6527],\n",
       "                       [-0.0285],\n",
       "                       [ 0.4144],\n",
       "                       [ 0.5917],\n",
       "                       [-0.0907],\n",
       "                       [-0.5022],\n",
       "                       [-0.1857],\n",
       "                       [-0.7641],\n",
       "                       [-0.6086],\n",
       "                       [ 0.8059]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([-0.0968, -0.1062,  0.2995,  0.6796,  0.8191, -0.2651,  0.2176, -0.0145,\n",
       "                        0.3491, -0.7865,  0.0040,  0.8271,  0.6865, -0.9518, -0.0205,  0.5221])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[-0.0034, -0.0777, -0.1095,  0.1065, -0.1877,  0.1081,  0.1279,  0.2342,\n",
       "                         0.0752,  0.1480,  0.0645,  0.0178, -0.2880,  0.2088,  0.2302, -0.2189],\n",
       "                       [ 0.2849, -0.2613,  0.3294, -0.2758, -0.3795, -0.1978,  0.3477,  0.1876,\n",
       "                         0.1227, -0.2900,  0.3087,  0.1476,  0.3291,  0.0228, -0.3055,  0.2452],\n",
       "                       [ 0.0865,  0.1556, -0.1957, -0.1431, -0.1242, -0.1789, -0.2323, -0.0575,\n",
       "                         0.1114,  0.2243, -0.1029, -0.0761, -0.1373,  0.0601, -0.2154, -0.1540],\n",
       "                       [ 0.0765, -0.3119,  0.0034, -0.0736, -0.0020,  0.0813,  0.2539, -0.0949,\n",
       "                         0.2627, -0.3606, -0.1161, -0.0185, -0.1074, -0.1767, -0.0020,  0.3174],\n",
       "                       [-0.1554,  0.3669,  0.0273,  0.0768,  0.2610, -0.0675, -0.1581,  0.1153,\n",
       "                         0.1774,  0.3409, -0.1426,  0.3089,  0.2116, -0.8357,  0.1516, -0.1268],\n",
       "                       [-0.1925,  0.1380, -0.0921, -0.1137, -0.1440, -0.1483, -0.1462, -0.1741,\n",
       "                        -0.1793, -0.1805, -0.2074,  0.0980,  0.1540,  0.1389, -0.2573,  0.0044],\n",
       "                       [ 0.1267, -0.3280,  0.3337, -0.1724, -0.3118,  0.0214,  0.2146, -0.1695,\n",
       "                         0.2706,  0.0324,  0.0463,  0.0832,  0.1819,  0.2005,  0.0097,  0.3255],\n",
       "                       [ 0.0538,  0.0066, -0.2117, -0.0628, -0.0335, -0.0672,  0.0726,  0.1381,\n",
       "                         0.2553, -0.0952,  0.1000, -0.1335,  0.1507,  0.1775, -0.0035, -0.2132],\n",
       "                       [ 0.0877, -0.1829,  0.0021,  0.1540, -0.0066,  0.1419,  0.0492,  0.0629,\n",
       "                         0.2083, -0.0951, -0.2375, -0.2346, -0.0589, -0.1482, -0.0158, -0.2317],\n",
       "                       [-0.1688, -0.1556,  0.2284,  0.0708,  0.1221, -0.1841,  0.1228,  0.1170,\n",
       "                        -0.2258, -0.2045, -0.0167, -0.1578, -0.1214,  0.1125,  0.0460, -0.1594],\n",
       "                       [-0.0431, -0.1682, -0.1790, -0.0747, -0.2599, -0.3496,  0.2671,  0.1187,\n",
       "                         0.2879, -0.5473,  0.2038, -0.0966,  0.2148,  0.1346, -0.3170,  0.1379],\n",
       "                       [-0.1667,  0.0338,  0.2211, -0.1219,  0.0265, -0.2232,  0.0815, -0.0798,\n",
       "                        -0.1051, -0.2315,  0.0258,  0.0389,  0.1632, -0.4996,  0.1852,  0.0449],\n",
       "                       [ 0.0893,  0.5023, -0.1060,  0.1962,  0.4543,  0.1571, -0.0864, -0.0515,\n",
       "                         0.2175,  0.6803,  0.1188,  0.2262,  0.0031, -0.7367,  0.2206, -0.0042],\n",
       "                       [-0.0484,  0.1515,  0.0175,  0.3907,  0.4874,  0.3975, -0.0463,  0.0079,\n",
       "                        -0.0723,  0.2458,  0.2006, -0.0199, -0.0538, -0.7083,  0.3445, -0.0967],\n",
       "                       [-0.2968, -0.2370, -0.1882,  0.1384, -0.1778,  0.2124, -0.0153, -0.0351,\n",
       "                        -0.2230,  0.0522, -0.2193, -0.2169, -0.2407,  0.2191, -0.1548, -0.0324],\n",
       "                       [ 0.2049,  0.4671,  0.0589,  0.3037,  0.2298,  0.4914,  0.1673, -0.0145,\n",
       "                        -0.1196,  0.5951, -0.0085,  0.3017,  0.0508, -0.8858,  0.3785, -0.1062]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([-0.1903,  0.3154,  0.1907, -0.0663,  0.2277, -0.0256,  0.0486, -0.1270,\n",
       "                        0.0434,  0.0039,  0.0989,  0.1255, -0.0553,  0.2230, -0.2338, -0.0776])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[ 0.0572,  0.0940, -0.0458, -0.2793,  0.0871,  0.0545, -0.1835,  0.1350,\n",
       "                        -0.1423, -0.2400,  0.1572, -0.2950, -0.0241, -0.1726, -0.1198, -0.2071],\n",
       "                       [-0.1144,  0.1364, -0.2101, -0.1074, -0.2457, -0.0626,  0.2291, -0.1097,\n",
       "                        -0.1978, -0.1752,  0.1230, -0.2483, -0.3328,  0.0819, -0.0397, -0.0236],\n",
       "                       [-0.0070, -0.2789, -0.1641, -0.2183, -0.1597, -0.2290, -0.0542,  0.0962,\n",
       "                         0.0790, -0.0565,  0.1911, -0.1941, -0.1996, -0.1085,  0.0011, -0.1780],\n",
       "                       [-0.0540, -0.0152, -0.0511, -0.1418, -0.3396, -0.0575, -0.0448,  0.2243,\n",
       "                         0.1792, -0.1999,  0.0162, -0.0505,  0.0963,  0.1332,  0.2075, -0.0944],\n",
       "                       [-0.1186,  0.1331, -0.1676,  0.2214,  0.1064,  0.1395,  0.2534,  0.2329,\n",
       "                         0.2363,  0.2301, -0.0743,  0.1443,  0.0209, -0.0069,  0.3077, -0.3443],\n",
       "                       [-0.1247,  0.2485,  0.1880,  0.3221,  0.3178, -0.0990,  0.2549,  0.0074,\n",
       "                         0.2107, -0.1708,  0.2812,  0.0739, -0.3255, -0.3317,  0.0312, -0.2266],\n",
       "                       [ 0.0244,  0.0403,  0.0668,  0.2332, -0.0194,  0.0859,  0.1101,  0.1728,\n",
       "                        -0.2265, -0.0627, -0.1993,  0.2327, -0.1636, -0.0879,  0.1961, -0.0023],\n",
       "                       [-0.1557,  0.2644,  0.1812,  0.1697,  0.2163,  0.1277,  0.1392,  0.1861,\n",
       "                        -0.2185,  0.1047,  0.2585,  0.2940, -0.0684, -0.2251, -0.0157, -0.1450],\n",
       "                       [-0.1451,  0.0754, -0.2310, -0.3064, -0.3540,  0.2692, -0.1498,  0.1199,\n",
       "                        -0.1520, -0.0015, -0.3184,  0.1350,  0.2565,  0.0618, -0.0754, -0.0854],\n",
       "                       [-0.1753, -0.1121,  0.1926, -0.2168, -0.1146, -0.1876,  0.1449, -0.1810,\n",
       "                         0.0082,  0.0413, -0.1442,  0.1995, -0.2101,  0.2357, -0.1773, -0.0258],\n",
       "                       [ 0.0470, -0.1904, -0.0574,  0.1026,  0.2970, -0.1578,  0.1035,  0.1033,\n",
       "                         0.2247, -0.1854, -0.1478,  0.2281,  0.1573,  0.2517, -0.1836,  0.3293],\n",
       "                       [-0.2442,  0.1162, -0.1055, -0.1324,  0.2864, -0.0571, -0.1908, -0.2191,\n",
       "                         0.0857,  0.1470,  0.0931, -0.0224,  0.1420,  0.2619, -0.0380,  0.3201],\n",
       "                       [ 0.0586, -0.1659, -0.2173,  0.0734, -0.0052,  0.1267, -0.1166,  0.1004,\n",
       "                         0.1318, -0.0464,  0.2481, -0.0176, -0.2471,  0.1440, -0.2050, -0.2196],\n",
       "                       [-0.0747,  0.0204,  0.0937,  0.1305, -0.2770,  0.1820, -0.1419, -0.1451,\n",
       "                        -0.1441, -0.2322,  0.1424,  0.1757, -0.1747, -0.1108, -0.1201, -0.0590],\n",
       "                       [ 0.1888, -0.0799,  0.2357, -0.2361,  0.0367, -0.2458,  0.1103,  0.1253,\n",
       "                        -0.1112,  0.0606, -0.1584, -0.1452, -0.1576, -0.1051, -0.2107,  0.1566],\n",
       "                       [-0.1085, -0.2428, -0.0797, -0.0226, -0.0846,  0.1076,  0.1280,  0.0638,\n",
       "                        -0.2193,  0.0265,  0.0873,  0.0505, -0.1800,  0.1845,  0.0841, -0.0540]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([-0.1017,  0.2016,  0.1890, -0.0463,  0.3399,  0.1638, -0.1176,  0.4129,\n",
       "                        0.0330, -0.1136,  0.0205, -0.1404, -0.0778, -0.0468, -0.0476, -0.0381])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[-0.0624, -0.0475,  0.0253, -0.1253,  0.3111,  0.3444,  0.0225, -0.0672,\n",
       "                        -0.1414,  0.1091, -0.2869, -0.2776,  0.1173, -0.1327,  0.1352,  0.0562],\n",
       "                       [-0.0788,  0.1103, -0.1494,  0.1247,  0.2279,  0.1980, -0.0544,  0.3340,\n",
       "                        -0.1636,  0.0635, -0.2005, -0.1323,  0.0888, -0.1631, -0.2674,  0.2224],\n",
       "                       [ 0.1756, -0.1629, -0.0349, -0.0707, -0.0212, -0.2309,  0.1347, -0.1488,\n",
       "                         0.2463, -0.1545, -0.2155, -0.2335,  0.0592, -0.2323,  0.1090, -0.0398],\n",
       "                       [ 0.2951,  0.1125,  0.0508, -0.0837, -0.0138,  0.0748,  0.2025,  0.1828,\n",
       "                        -0.0527, -0.1749, -0.1761, -0.0163,  0.0438,  0.2769, -0.1666, -0.2012],\n",
       "                       [ 0.1134, -0.0219,  0.2439, -0.1234,  0.0819, -0.2595, -0.1787, -0.0269,\n",
       "                        -0.3145,  0.1357,  0.0015,  0.0850,  0.0986,  0.0514,  0.0994,  0.2207],\n",
       "                       [-0.1892,  0.0609, -0.1691,  0.1231, -0.1857,  0.0009,  0.0133,  0.0077,\n",
       "                        -0.1554,  0.1444,  0.2441, -0.2461,  0.0573, -0.2141,  0.0106,  0.1275],\n",
       "                       [-0.1711,  0.2264, -0.1973,  0.1860,  0.3064,  0.3595,  0.2501,  0.2582,\n",
       "                        -0.0234, -0.1438, -0.1600,  0.0509, -0.2381, -0.0339,  0.0057,  0.0056],\n",
       "                       [-0.0972, -0.1103,  0.0039,  0.1370, -0.0019, -0.0184,  0.3449,  0.1403,\n",
       "                        -0.0464, -0.2297,  0.2248,  0.0912,  0.2368,  0.0580,  0.2137, -0.0191],\n",
       "                       [-0.0994, -0.0505,  0.0274,  0.1027, -0.0299, -0.0034,  0.2462,  0.3349,\n",
       "                        -0.0145, -0.0035, -0.1437, -0.0718,  0.0069,  0.1950,  0.0289, -0.0625],\n",
       "                       [-0.0069, -0.0022,  0.1632,  0.1091,  0.0624, -0.0985,  0.0346, -0.1094,\n",
       "                        -0.3149, -0.2240,  0.1224,  0.3165,  0.1790,  0.0442, -0.0864,  0.2381],\n",
       "                       [-0.2385, -0.0263, -0.0019, -0.1584, -0.1797,  0.1801,  0.1397, -0.0915,\n",
       "                         0.0249,  0.0025,  0.3010,  0.2187, -0.2009,  0.0821, -0.2084, -0.0361],\n",
       "                       [-0.1337,  0.2163,  0.1221,  0.0825, -0.2169, -0.1885,  0.1516,  0.1039,\n",
       "                         0.0708, -0.0837,  0.1223,  0.3601,  0.0441,  0.1853, -0.1298,  0.1817],\n",
       "                       [-0.2162, -0.0664,  0.1295,  0.0923,  0.1499, -0.1553,  0.1827,  0.2548,\n",
       "                         0.0868,  0.1409,  0.2191,  0.0483, -0.0026, -0.0528, -0.1665, -0.2377],\n",
       "                       [ 0.0308,  0.0459, -0.1158, -0.0116,  0.1160, -0.2606,  0.2102, -0.1120,\n",
       "                         0.1725, -0.1644, -0.0110,  0.0312, -0.2312, -0.0439,  0.1143,  0.2492],\n",
       "                       [ 0.1080, -0.0076,  0.1119,  0.1162, -0.0675, -0.0275, -0.0694, -0.2287,\n",
       "                        -0.2360, -0.1511, -0.0066, -0.0293,  0.1852, -0.0695, -0.0734,  0.1009],\n",
       "                       [ 0.2166,  0.2887, -0.0762,  0.2069,  0.2960,  0.0581, -0.1174,  0.0607,\n",
       "                        -0.1176, -0.1341,  0.0833, -0.3091, -0.2315, -0.1091, -0.0815,  0.2724]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.3597,  0.1889,  0.0763,  0.2903, -0.2480, -0.0762,  0.2107,  0.0951,\n",
       "                        0.3936,  0.0738,  0.1820,  0.1135, -0.0436, -0.0498,  0.0547,  0.2985])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[ 2.6918e-01,  2.9658e-01,  1.7711e-01,  2.9086e-01,  7.3918e-02,\n",
       "                        -5.5140e-02,  3.2402e-01, -1.7450e-01,  3.6238e-01, -1.7465e-01,\n",
       "                        -2.3068e-01, -2.9189e-01, -1.9900e-01,  1.4471e-04, -1.7496e-03,\n",
       "                         1.9769e-01]])),\n",
       "              ('layers.8.bias', tensor([0.0754]))]),\n",
       " 'LQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[ 0.3341],\n",
       "                       [ 0.5833],\n",
       "                       [ 0.1797],\n",
       "                       [-0.7265],\n",
       "                       [ 0.7996],\n",
       "                       [-0.7656],\n",
       "                       [ 0.0445],\n",
       "                       [-0.8892],\n",
       "                       [-0.5170],\n",
       "                       [ 0.7883],\n",
       "                       [ 0.9730],\n",
       "                       [ 0.1042],\n",
       "                       [-0.1611],\n",
       "                       [-0.8904],\n",
       "                       [ 0.9349],\n",
       "                       [ 0.5740]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.2482,  0.3620,  0.4164,  0.9736, -0.7866,  0.0632, -0.1134, -0.8818,\n",
       "                       -0.6856, -1.0806, -0.6126,  0.0262, -0.9817,  0.5553, -0.0777,  0.2603])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[ 9.3104e-02, -4.4049e-01,  1.0060e-01, -1.3407e-01, -1.2888e-01,\n",
       "                         1.2955e-01, -1.9079e-01, -2.1061e-01,  1.3764e-01,  4.4213e-02,\n",
       "                         1.0569e-01,  1.4044e-01,  3.0379e-02,  2.1483e-01, -1.6660e-02,\n",
       "                        -4.4911e-01],\n",
       "                       [-1.0098e-01, -1.9708e-02,  1.3235e-01,  1.6997e-01, -1.5630e-01,\n",
       "                         3.0360e-01, -2.2799e-02, -2.6759e-01, -1.8707e-01,  9.5438e-04,\n",
       "                        -3.3438e-01, -5.7984e-02,  2.1149e-01,  1.9272e-01, -4.1671e-01,\n",
       "                         1.5679e-01],\n",
       "                       [ 2.1123e-01,  2.8023e-02,  1.0754e-01,  2.7580e-01, -4.1096e-01,\n",
       "                         1.3663e-02,  1.2994e-01, -9.8643e-02, -2.2315e-01, -3.8682e-01,\n",
       "                        -2.8157e-01, -6.0065e-03, -2.4626e-01, -3.4969e-03,  1.1198e-01,\n",
       "                        -2.7545e-01],\n",
       "                       [-6.2329e-01, -3.0040e-01,  1.0194e-02,  2.1601e-01, -8.6473e-03,\n",
       "                         2.0119e-01, -1.0170e-01,  5.2577e-02,  3.0006e-02, -3.4526e-02,\n",
       "                        -1.8670e-01, -4.3461e-01, -2.0319e-01,  2.3646e-01, -3.0013e-01,\n",
       "                        -4.8243e-01],\n",
       "                       [ 2.4971e-01, -1.7326e-01, -7.9582e-03,  2.5150e-01, -2.8540e-01,\n",
       "                        -5.1749e-02, -5.9763e-02, -3.7840e-01,  1.5531e-01, -4.4370e-01,\n",
       "                        -1.1251e-01,  6.7007e-02, -1.0117e-01, -1.5204e-01, -3.0646e-01,\n",
       "                         2.4659e-01],\n",
       "                       [-7.7535e-03, -1.6137e-01,  1.8974e-01, -1.8117e-01, -1.9062e-01,\n",
       "                         2.8072e-02,  1.9790e-01, -2.3079e-01, -1.8371e-01, -1.7153e-01,\n",
       "                         2.1567e-01, -2.3617e-01, -1.4194e-01, -1.4310e-01,  4.5417e-03,\n",
       "                        -2.4095e-01],\n",
       "                       [ 2.5931e-01,  3.5588e-02,  1.0114e-01,  2.5280e-02, -4.0901e-01,\n",
       "                        -2.0620e-01, -6.2342e-02,  2.0584e-01, -4.6773e-02, -3.0527e-01,\n",
       "                        -2.8665e-01, -2.6874e-01,  2.2685e-01, -1.1829e-01, -5.5469e-01,\n",
       "                        -2.4124e-01],\n",
       "                       [ 1.3173e-01, -5.9155e-02,  7.9789e-02,  2.6530e-01, -7.8971e-02,\n",
       "                         1.9318e-01,  1.4310e-01,  1.5563e-01, -1.5862e-02,  4.2062e-02,\n",
       "                        -3.4108e-01,  3.2981e-01,  2.5655e-02,  1.8091e-01, -1.2895e-01,\n",
       "                        -2.7174e-01],\n",
       "                       [-4.2814e-02,  1.6818e-01,  1.7115e-01, -4.8000e-02, -9.1599e-02,\n",
       "                         1.7254e-01, -1.2999e-01,  5.4300e-03, -9.3606e-02,  5.7251e-03,\n",
       "                         7.0504e-02, -5.2135e-02, -9.3572e-02, -2.7263e-01,  1.6683e-02,\n",
       "                        -2.9019e-01],\n",
       "                       [ 9.9320e-02, -8.3111e-02, -7.2879e-02, -2.4895e-01, -4.9093e-02,\n",
       "                         8.8248e-02, -2.2062e-01,  2.3274e-01,  1.3463e-02, -2.1198e-02,\n",
       "                        -8.8911e-02,  5.5168e-02,  3.9286e-02, -9.5289e-02, -1.5749e-01,\n",
       "                        -3.2812e-02],\n",
       "                       [-2.2389e-01, -7.7005e-03, -2.6396e-01, -1.3552e-01, -3.2446e-01,\n",
       "                         1.5384e-01, -2.3637e-01,  4.5850e-02, -1.3212e-01,  2.4138e-02,\n",
       "                        -2.1455e-01, -2.5091e-01,  1.2288e-01,  9.5822e-03,  1.4465e-02,\n",
       "                         1.2333e-01],\n",
       "                       [ 2.9550e-01,  3.0608e-01,  2.9736e-02,  2.5726e-01, -1.6426e-01,\n",
       "                         2.1165e-01, -4.8603e-03,  1.8435e-01, -7.2651e-02, -4.5287e-01,\n",
       "                        -1.6892e-01,  1.4988e-01,  8.2958e-02,  4.0081e-01, -2.2015e-01,\n",
       "                        -9.3933e-02],\n",
       "                       [ 5.6395e-02, -1.5718e-01, -6.8379e-02, -2.4985e-01, -4.2410e-02,\n",
       "                         1.2473e-01,  1.6929e-01, -1.4765e-02, -3.1463e-01,  1.6701e-01,\n",
       "                        -1.8184e-01, -1.5853e-01, -2.2538e-01,  8.6642e-02,  6.6012e-02,\n",
       "                        -2.3102e-01],\n",
       "                       [ 9.3775e-02,  1.4275e-01,  2.6050e-01,  2.2808e-01, -4.7488e-01,\n",
       "                        -2.7974e-01,  3.8946e-03, -3.6773e-01,  2.2423e-01, -2.4808e-01,\n",
       "                        -2.2390e-01,  7.4875e-02, -2.5816e-02, -1.9500e-01, -1.0482e-01,\n",
       "                         1.1274e-01],\n",
       "                       [ 3.2109e-01,  4.7472e-01,  1.8111e-01,  1.7247e-01, -2.7297e-01,\n",
       "                        -5.9686e-02, -3.0706e-02,  4.0941e-01,  7.7945e-01, -4.6776e-01,\n",
       "                        -4.7172e-03,  2.6835e-01, -2.3736e-01, -1.4248e-01,  1.6240e-01,\n",
       "                         2.4746e-01],\n",
       "                       [ 4.2379e-02, -2.1608e-01, -4.6642e-02,  1.3924e-01, -1.4175e-02,\n",
       "                         2.2787e-02, -2.1905e-01, -7.5682e-02, -2.6458e-01,  1.6737e-01,\n",
       "                         2.8136e-02,  1.0595e-01,  1.3614e-01,  7.8832e-02, -1.0826e+00,\n",
       "                        -2.7809e-01]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([-0.2406,  0.3069, -0.1848,  0.1770,  0.2538, -0.2137, -0.0231,  0.0399,\n",
       "                       -0.1258, -0.1136,  0.0128,  0.3483,  0.0347,  0.0496,  0.0160, -0.0781])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[ 0.1611, -0.5193, -0.2493,  0.0419, -0.4680,  0.1104,  0.2400, -0.3434,\n",
       "                         0.1673, -0.1129, -0.0162, -0.5933, -0.0565, -0.5231,  0.2473, -0.2342],\n",
       "                       [ 0.0146,  0.3548, -0.0579,  0.2268,  0.0547, -0.0527,  0.1223,  0.1153,\n",
       "                        -0.0064,  0.1441, -0.1162,  0.2789,  0.2359,  0.3293, -0.3420,  0.0298],\n",
       "                       [-0.0654,  0.0869,  0.2954,  0.2706,  0.1276, -0.1497, -0.1117, -0.1173,\n",
       "                        -0.0297, -0.0841,  0.1622, -0.1062,  0.3250, -0.0201, -0.1073,  0.1694],\n",
       "                       [-0.0919, -0.0809, -0.1141, -0.4328,  0.1001, -0.2048,  0.0275, -0.1582,\n",
       "                        -0.2251,  0.1681, -0.2335, -0.1403,  0.2774, -0.0045,  0.3318, -0.3254],\n",
       "                       [ 0.0914, -0.2579,  0.0986, -0.1371, -0.1468,  0.1360, -0.0305,  0.0588,\n",
       "                        -0.2242, -0.2476, -0.1343,  0.0620,  0.1553, -0.1366, -0.0748, -0.2354],\n",
       "                       [ 0.3425,  0.1857,  0.1574,  0.2597, -0.0869,  0.0014,  0.1117,  0.2454,\n",
       "                         0.1946, -0.1313, -0.0376,  0.2980, -0.0769,  0.1615, -0.4076,  0.2681],\n",
       "                       [ 0.1102, -0.2267,  0.0305, -0.1490, -0.1446, -0.1863,  0.0939,  0.0304,\n",
       "                         0.1027, -0.0395, -0.2066,  0.1801, -0.2057,  0.0095, -0.1123, -0.1463],\n",
       "                       [-0.1099,  0.0460, -0.0104,  0.0894,  0.2131,  0.0267,  0.0622, -0.0705,\n",
       "                        -0.0209,  0.1876,  0.1812,  0.3277,  0.1329,  0.3039, -0.1474,  0.0729],\n",
       "                       [-0.2010, -0.1891, -0.1920,  0.1123, -0.1863,  0.0101, -0.0066,  0.0129,\n",
       "                         0.0553, -0.1220, -0.1209, -0.1548, -0.1153, -0.1151, -0.1622, -0.2815],\n",
       "                       [ 0.1696,  0.1618,  0.1190,  0.1584, -0.1295, -0.1414, -0.1659, -0.0246,\n",
       "                         0.0273, -0.1197,  0.2128, -0.1472,  0.0486, -0.1251, -0.1123, -0.2284],\n",
       "                       [ 0.0505,  0.3422,  0.1588, -0.0284,  0.0779,  0.0289,  0.4543,  0.0290,\n",
       "                        -0.2109, -0.1774,  0.1223, -0.0338,  0.3443,  0.1235,  0.3339,  0.1141],\n",
       "                       [ 0.2013, -0.0734,  0.0684,  0.1472,  0.0479, -0.0843, -0.1035, -0.0309,\n",
       "                        -0.1359,  0.2328,  0.1162,  0.0892, -0.0307,  0.3154,  0.2125,  0.0857],\n",
       "                       [ 0.0716,  0.0415, -0.1482, -0.1760,  0.2253,  0.0194,  0.0255,  0.1550,\n",
       "                         0.0055, -0.2376,  0.1265, -0.2356, -0.1028, -0.1244,  0.1491,  0.1622],\n",
       "                       [-0.0479,  0.2871,  0.0864,  0.2062,  0.2818,  0.0971,  0.0076,  0.3839,\n",
       "                         0.0447,  0.2154,  0.1040,  0.2968, -0.1036, -0.1318, -0.2512, -0.1025],\n",
       "                       [ 0.1318,  0.0263,  0.0322, -0.2352,  0.1060,  0.0099, -0.1587,  0.0752,\n",
       "                        -0.0628, -0.2488,  0.0468, -0.0160, -0.1419, -0.0753, -0.0524,  0.1316],\n",
       "                       [ 0.1913,  0.2971, -0.0897,  0.0962, -0.1599,  0.1218, -0.0354,  0.2103,\n",
       "                        -0.0010, -0.2341,  0.2103,  0.2150, -0.1255, -0.0776, -0.2688,  0.2359]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.6882, -0.0383,  0.1962,  0.3624, -0.0214,  0.0336, -0.0307,  0.1286,\n",
       "                        0.1477, -0.1797, -0.0324, -0.0144,  0.1187,  0.2976, -0.0876,  0.0025])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[-2.0615e-01,  7.1895e-02,  6.5901e-02, -2.8054e-02,  6.0486e-03,\n",
       "                         2.1452e-01, -1.7483e-01, -9.5568e-02,  1.8799e-01,  3.5853e-02,\n",
       "                        -1.3823e-01, -1.2484e-01, -2.1735e-01, -3.2080e-03,  3.8552e-02,\n",
       "                         7.2199e-02],\n",
       "                       [ 2.9820e-02,  1.4426e-01,  1.7402e-01,  2.0104e-01, -1.7805e-01,\n",
       "                         1.6509e-02,  1.1153e-01,  2.2773e-01,  6.2014e-02,  5.9678e-02,\n",
       "                         9.5255e-03, -7.9367e-02,  1.2194e-01,  2.5456e-01, -3.9471e-02,\n",
       "                         2.5335e-01],\n",
       "                       [-1.3119e-01, -1.7904e-01, -1.5426e-01, -5.5589e-02,  3.5171e-02,\n",
       "                        -2.7540e-02,  2.0892e-01, -2.4639e-01, -1.3511e-01, -2.6597e-02,\n",
       "                        -9.7584e-02, -2.0576e-02,  1.8631e-02,  1.6923e-03, -2.0423e-01,\n",
       "                        -1.4065e-01],\n",
       "                       [ 2.4443e-01,  1.7956e-01, -2.2430e-01, -2.0733e-01,  2.1502e-01,\n",
       "                        -1.8764e-01,  1.5224e-01,  1.3065e-01,  5.7690e-02, -1.7935e-01,\n",
       "                        -2.0534e-01, -1.6174e-01,  1.0035e-02, -1.5547e-01, -1.1768e-02,\n",
       "                         1.2257e-01],\n",
       "                       [-1.4661e-01, -2.0706e-01,  2.4305e-01,  1.1350e-01, -1.6423e-01,\n",
       "                         4.0835e-03,  4.1076e-02, -3.5714e-02,  1.6920e-01,  7.3177e-02,\n",
       "                        -1.7783e-01,  2.2089e-01, -1.7340e-01, -1.0992e-01,  1.1988e-01,\n",
       "                        -8.4454e-02],\n",
       "                       [-2.2433e-01,  4.6149e-02, -1.5672e-01, -5.1614e-02,  5.9296e-02,\n",
       "                         1.3584e-02, -1.8854e-01,  1.7973e-01,  2.0464e-01, -2.1544e-01,\n",
       "                        -1.9503e-01,  1.3885e-01, -2.3857e-01,  7.8984e-03,  2.9155e-02,\n",
       "                        -1.5211e-01],\n",
       "                       [ 5.6765e-01, -1.9591e-01,  4.5941e-01,  2.3552e-01, -8.8059e-02,\n",
       "                        -1.9616e-02,  4.4545e-02, -4.2016e-01, -1.3996e-01,  1.2260e-01,\n",
       "                        -2.2515e-01, -7.9142e-02,  2.0349e-01, -5.7679e-01, -7.3510e-02,\n",
       "                        -2.2562e-01],\n",
       "                       [-3.6429e-02, -2.2536e-01,  4.6206e-02, -2.0237e-01,  2.3212e-02,\n",
       "                         3.2664e-02, -8.7494e-02,  1.8058e-01, -1.7009e-01, -1.1482e-01,\n",
       "                         2.0191e-01, -3.5445e-02, -1.4008e-01, -2.0682e-01,  2.3061e-01,\n",
       "                         8.3077e-02],\n",
       "                       [-1.1402e-01,  4.1637e-02,  3.3451e-01,  2.0005e-03, -1.9113e-02,\n",
       "                         1.5482e-01, -3.6442e-02,  2.5527e-01,  2.8148e-01, -7.6552e-02,\n",
       "                        -1.8309e-01,  2.6983e-02, -9.4701e-02,  1.8265e-01,  1.9558e-01,\n",
       "                         1.7925e-01],\n",
       "                       [-1.0413e-01,  2.2441e-01, -4.6799e-02, -4.4510e-01,  1.0936e-01,\n",
       "                         3.6547e-01, -2.1216e-01,  4.7152e-02, -1.6499e-01,  1.4414e-01,\n",
       "                        -1.1671e-01, -1.9534e-01, -1.3570e-01,  1.8018e-01,  5.9746e-02,\n",
       "                         1.6965e-01],\n",
       "                       [-2.8099e-01,  7.4380e-02,  4.8922e-02, -4.7473e-01,  2.2602e-01,\n",
       "                         5.0602e-02, -3.1526e-02,  5.1513e-02,  1.3042e-01,  2.4736e-01,\n",
       "                        -2.6884e-01, -1.2214e-01,  1.5618e-01,  2.6171e-01, -2.0698e-01,\n",
       "                        -2.6527e-02],\n",
       "                       [-1.0877e-01,  2.8413e-02, -2.5676e-02,  5.9327e-02,  2.6987e-02,\n",
       "                        -2.3787e-01, -1.7186e-01,  3.9293e-02,  8.1567e-02, -2.3665e-01,\n",
       "                         1.6570e-02,  3.1728e-02, -9.0345e-02, -1.9950e-01, -9.3526e-02,\n",
       "                         1.5499e-01],\n",
       "                       [-1.6587e-01,  3.2531e-01,  2.2166e-01, -1.6856e-01,  2.4424e-02,\n",
       "                         2.8609e-01,  9.9504e-02, -4.4127e-02, -7.9649e-02, -1.7079e-01,\n",
       "                        -3.3369e-01, -1.0281e-01, -2.9879e-02,  3.0967e-01, -1.9915e-01,\n",
       "                         1.3523e-01],\n",
       "                       [ 5.5000e-01,  2.5395e-01, -5.4850e-02,  5.1103e-01, -2.0230e-01,\n",
       "                        -2.3065e-02, -2.3324e-03,  1.5581e-01,  8.0217e-02, -8.4823e-02,\n",
       "                         3.2859e-01,  2.5861e-01,  2.5329e-01, -9.8173e-02, -6.7451e-03,\n",
       "                         1.5802e-01],\n",
       "                       [-5.4954e-02,  1.6851e-01,  7.1673e-02,  1.2052e-01,  5.4326e-02,\n",
       "                        -1.3610e-01,  6.3293e-02,  1.0026e-01,  2.6380e-02, -1.5460e-01,\n",
       "                        -2.0454e-01, -2.8864e-01, -1.8989e-01, -3.2692e-04,  8.5001e-02,\n",
       "                        -2.7205e-01],\n",
       "                       [ 4.6616e-01, -4.8580e-01,  1.4793e-01,  1.0933e-01, -1.9102e-01,\n",
       "                        -7.0339e-01,  1.4680e-01, -3.5991e-01, -2.5724e-02,  1.8157e-01,\n",
       "                         1.0034e-01,  9.1075e-02, -8.5291e-02, -5.5558e-01, -2.4755e-01,\n",
       "                        -2.7082e-01]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.0097, -0.2021, -0.1122, -0.2292, -0.0599, -0.0501,  0.8513, -0.1963,\n",
       "                        0.1722,  0.2948,  0.2818, -0.3704,  0.3894,  0.1465, -0.1595,  0.4994])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[-1.5657e-02, -1.5864e-01,  2.2785e-01, -1.1495e-01,  1.2278e-01,\n",
       "                         2.0830e-01,  6.4928e-01,  2.2093e-01, -2.6526e-01, -2.9753e-01,\n",
       "                        -1.1653e-01, -6.3296e-04, -1.9098e-01,  1.8690e-01, -1.3376e-01,\n",
       "                         3.2762e-01]])),\n",
       "              ('layers.8.bias', tensor([0.0818]))])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define quantiles and hyperparameters\n",
    "q_median = 0.5\n",
    "q_upper = 0.975\n",
    "q_lower = 0.025\n",
    "# dims = model['dims']\n",
    "dims = (1, 16, 16, 16, 16, 1)\n",
    "lr = model['lr']\n",
    "batch_size = int(model['batch_size'])\n",
    "epoch = model['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch size: 500\n",
      "epoch: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"lr:\", lr)\n",
    "print(\"batch size:\", batch_size)\n",
    "print(\"epoch:\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done C_WTG01\n",
      "Done C_WTG02\n",
      "Done C_WTG03\n",
      "Done C_WTG04\n",
      "Done C_WTG05\n",
      "Done C_WTG06\n",
      "Done C_WTG07\n",
      "Done C_WTG08\n",
      "Done C_WTG09\n",
      "Done C_WTG10\n",
      "Done C_WTG11\n",
      "Done C_WTG12\n",
      "Done C_WTG13\n",
      "Done C_WTG14\n",
      "Done C_WTG15\n",
      "Done C_WTG16\n",
      "Done C_WTG17\n",
      "Done C_WTG18\n",
      "Done C_WTG19\n",
      "Done C_WTG20\n",
      "Done C_WTG21\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################################### training ######################################################### \n",
    "\n",
    "turbines = data_finetune.instanceID.unique()\n",
    "median_state_dict_all = []\n",
    "UQ_state_dict_all = []\n",
    "LQ_state_dict_all = []\n",
    "\n",
    "\n",
    "for ID in turbines:\n",
    "    \n",
    "    # select data based on turbine ID\n",
    "    data_temp = data_finetune[data_finetune['instanceID'] == ID]\n",
    "\n",
    "    # normalize data\n",
    "    X = scaler1.transform(data_temp.iloc[:, 5:-1])\n",
    "    y = scaler2.transform(data_temp.iloc[:, -1:])\n",
    "    \n",
    "    # create network and load pretrain weights\n",
    "    net_median_temp = Net(dims = dims)\n",
    "    net_median_temp.load_state_dict(pretrain['median'])\n",
    "    \n",
    "    net_upper_temp = Net(dims = dims)\n",
    "    net_upper_temp.load_state_dict(pretrain['UQ'])\n",
    "    \n",
    "    net_lower_temp = Net(dims = dims)\n",
    "    net_lower_temp.load_state_dict(pretrain['LQ'])\n",
    "    \n",
    "    # train\n",
    "    net_median_temp, median_state_dict = train(X=X, y=y, quantile=q_median, net=net_median_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_upper_temp, UQ_state_dict = train(X=X, y=y, quantile=q_upper, net=net_upper_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_lower_temp, LQ_state_dict = train(X=X, y=y, quantile=q_lower, net=net_lower_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    \n",
    "    median_state_dict_all.append(median_state_dict)\n",
    "    UQ_state_dict_all.append(UQ_state_dict)\n",
    "    LQ_state_dict_all.append(LQ_state_dict)\n",
    "    \n",
    "    print('Done', ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_state_dict_all_zip = dict(zip(turbines, median_state_dict_all))\n",
    "UQ_state_dict_all_zip = dict(zip(turbines, UQ_state_dict_all))\n",
    "LQ_state_dict_all_zip = dict(zip(turbines, LQ_state_dict_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save trained network\n",
    "\n",
    "torch.save(median_state_dict_all_zip, sys.path[0] + '/median.pth')\n",
    "torch.save(UQ_state_dict_all_zip, sys.path[0] + '/UQ.pth')\n",
    "torch.save(LQ_state_dict_all_zip, sys.path[0] + '/LQ.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
