{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from typing import Iterable\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from joblib import dump, load\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data_finetune = pd.read_csv(\"data_finetune.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>instanceID</th>\n",
       "      <th>Wind_speed</th>\n",
       "      <th>TI</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118992</th>\n",
       "      <td>2020-05-17 17:20:00</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>A_WTG01</td>\n",
       "      <td>15.113220</td>\n",
       "      <td>14.855643</td>\n",
       "      <td>11.627620</td>\n",
       "      <td>2558.2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26598</th>\n",
       "      <td>2020-01-31 18:50:00</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>A_WTG01</td>\n",
       "      <td>13.458100</td>\n",
       "      <td>16.313596</td>\n",
       "      <td>9.734640</td>\n",
       "      <td>2500.3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288948</th>\n",
       "      <td>2020-11-30 10:20:00</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>A_WTG01</td>\n",
       "      <td>14.579640</td>\n",
       "      <td>11.682319</td>\n",
       "      <td>7.631262</td>\n",
       "      <td>2559.3960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79368</th>\n",
       "      <td>2020-04-01 20:40:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>A_WTG01</td>\n",
       "      <td>4.605131</td>\n",
       "      <td>14.969815</td>\n",
       "      <td>7.049312</td>\n",
       "      <td>149.0881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108378</th>\n",
       "      <td>2020-05-05 10:30:00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>A_WTG01</td>\n",
       "      <td>4.765651</td>\n",
       "      <td>23.030998</td>\n",
       "      <td>8.375311</td>\n",
       "      <td>218.0337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127433</th>\n",
       "      <td>2020-05-27 11:40:00</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>A_WTG06</td>\n",
       "      <td>3.136577</td>\n",
       "      <td>28.075118</td>\n",
       "      <td>13.594430</td>\n",
       "      <td>39.7835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252341</th>\n",
       "      <td>2020-10-19 01:20:00</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>A_WTG06</td>\n",
       "      <td>4.021086</td>\n",
       "      <td>22.134016</td>\n",
       "      <td>8.378720</td>\n",
       "      <td>129.2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28691</th>\n",
       "      <td>2020-02-03 04:50:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>A_WTG06</td>\n",
       "      <td>12.679620</td>\n",
       "      <td>14.700496</td>\n",
       "      <td>6.493042</td>\n",
       "      <td>2557.5790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82229</th>\n",
       "      <td>2020-04-05 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>A_WTG06</td>\n",
       "      <td>6.011343</td>\n",
       "      <td>10.698589</td>\n",
       "      <td>6.955961</td>\n",
       "      <td>442.9386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200897</th>\n",
       "      <td>2020-08-20 12:20:00</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>A_WTG06</td>\n",
       "      <td>8.421880</td>\n",
       "      <td>21.098413</td>\n",
       "      <td>20.185780</td>\n",
       "      <td>1253.6620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ts  Month  Day  Hour instanceID  Wind_speed  \\\n",
       "118992  2020-05-17 17:20:00      5   17    17    A_WTG01   15.113220   \n",
       "26598   2020-01-31 18:50:00      1   31    18    A_WTG01   13.458100   \n",
       "288948  2020-11-30 10:20:00     11   30    10    A_WTG01   14.579640   \n",
       "79368   2020-04-01 20:40:00      4    1    20    A_WTG01    4.605131   \n",
       "108378  2020-05-05 10:30:00      5    5    10    A_WTG01    4.765651   \n",
       "...                     ...    ...  ...   ...        ...         ...   \n",
       "127433  2020-05-27 11:40:00      5   27    11    A_WTG06    3.136577   \n",
       "252341  2020-10-19 01:20:00     10   19     1    A_WTG06    4.021086   \n",
       "28691   2020-02-03 04:50:00      2    3     4    A_WTG06   12.679620   \n",
       "82229   2020-04-05 04:00:00      4    5     4    A_WTG06    6.011343   \n",
       "200897  2020-08-20 12:20:00      8   20    12    A_WTG06    8.421880   \n",
       "\n",
       "               TI  Temperature      Power  \n",
       "118992  14.855643    11.627620  2558.2880  \n",
       "26598   16.313596     9.734640  2500.3020  \n",
       "288948  11.682319     7.631262  2559.3960  \n",
       "79368   14.969815     7.049312   149.0881  \n",
       "108378  23.030998     8.375311   218.0337  \n",
       "...           ...          ...        ...  \n",
       "127433  28.075118    13.594430    39.7835  \n",
       "252341  22.134016     8.378720   129.2706  \n",
       "28691   14.700496     6.493042  2557.5790  \n",
       "82229   10.698589     6.955961   442.9386  \n",
       "200897  21.098413    20.185780  1253.6620  \n",
       "\n",
       "[60000 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load normalization function \n",
    "scaler1 = load('scaler1.bin')\n",
    "scaler2 = load('scaler2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_count = data_finetune['instanceID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dims: Iterable[int], output_activation: nn.Module = None):\n",
    "        \"\"\"Creates a network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = dims[0]\n",
    "        self.out_size = dims[-1]\n",
    "        self.layers = self.make_seq(dims, output_activation)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_seq(dims: Iterable[int], output_activation: nn.Module) -> nn.Module:\n",
    "        \"\"\"Creates a sequential network using ReLUs between layers and no activation at the end\n",
    "\n",
    "        :param dims (Iterable[int]): tuple in the form of (IN_SIZE, HIDDEN_SIZE, HIDDEN_SIZE2,\n",
    "            ..., OUT_SIZE) for dimensionalities of layers\n",
    "        :param output_activation (nn.Module): PyTorch activation function to use after last layer\n",
    "        :return (nn.Module): return created sequential layers\n",
    "        \"\"\"\n",
    "        mods = []\n",
    "\n",
    "        for i in range(len(dims) - 2):\n",
    "            mods.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            mods.append(nn.ReLU())\n",
    "\n",
    "        mods.append(nn.Linear(dims[-2], dims[-1]))\n",
    "        if output_activation:\n",
    "            mods.append(output_activation())\n",
    "        return nn.Sequential(*mods)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Computes a forward pass through the network\n",
    "\n",
    "        :param x (torch.Tensor): input tensor to feed into the network\n",
    "        :return (torch.Tensor): output computed by the network\n",
    "        \"\"\"\n",
    "        # Feedforward\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, quantile, net, lr, batch_size, epoch):    \n",
    "    \n",
    "    # create tensor dataset\n",
    "    train = TensorDataset(Tensor(X), Tensor(y))\n",
    "\n",
    "    # create data loader from dataset\n",
    "    trainset = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr = lr)\n",
    "        \n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for ep in range(epoch):\n",
    "\n",
    "        for t in trainset:\n",
    "            X_temp, y_temp = t\n",
    "            output = net(X_temp)\n",
    "            residual = y_temp - output\n",
    "            loss = Tensor.max(quantile*residual, (quantile-1)*residual).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return net, net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use a very low learning rate at this stage, because we are training on a dataset that is very small. This is to prevent the risk of overfitting very quickly if we apply large weight updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hyperparameters\n",
    "model = torch.load(sys.path[0] + '/hparams_finetune.pth')\n",
    "\n",
    "# load the pretrained weights\n",
    "pretrain = torch.load(sys.path[0] + '/pretrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median': OrderedDict([('layers.0.weight',\n",
       "               tensor([[-0.2058,  0.1574,  0.0526],\n",
       "                       [-0.5071, -0.1184, -0.0233],\n",
       "                       [ 0.1560, -0.1836, -0.0684],\n",
       "                       [-0.0306, -0.0834,  0.1948],\n",
       "                       [-0.1010,  0.0483, -0.3136],\n",
       "                       [-0.5427,  0.1885, -0.0202],\n",
       "                       [ 0.6917,  0.0757, -0.0173],\n",
       "                       [ 0.4790,  0.1916,  0.1720],\n",
       "                       [ 0.5465, -0.0473, -0.1253],\n",
       "                       [-0.4558, -0.5142,  0.0997],\n",
       "                       [ 0.0210,  0.2531, -0.0929],\n",
       "                       [-0.6486, -0.0973, -0.0132],\n",
       "                       [-0.1934,  0.2575, -0.1671],\n",
       "                       [-0.4501,  0.1971,  0.0242],\n",
       "                       [-0.6083,  0.0146,  0.1262],\n",
       "                       [-0.4521, -0.0311,  0.0765]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.3656,  0.3384,  0.0042,  0.1991, -0.4763, -0.8338,  0.6098, -0.1333,\n",
       "                       -0.6196, -0.1380, -0.3410,  0.6396,  0.2912,  0.1041, -0.5284,  0.4802])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[-1.2466e-01, -9.2994e-02,  4.7894e-01, -5.3649e-03,  2.1197e-01,\n",
       "                        -2.0790e-01, -2.8310e-01, -1.0369e-02,  2.8567e-03, -2.1112e-01,\n",
       "                         1.6595e-01,  2.3124e-01,  2.0780e-01, -1.9539e-01, -3.3547e-01,\n",
       "                         1.0960e-01],\n",
       "                       [ 3.4151e-01,  1.8221e-01,  3.2275e-01, -6.4902e-02,  1.3869e-01,\n",
       "                        -1.8430e-01, -1.1896e-01,  9.4533e-02,  3.2108e-01, -3.3063e-02,\n",
       "                        -1.5338e-02,  3.0958e-01, -6.9778e-02,  3.2805e-01,  1.3532e-01,\n",
       "                         2.6757e-01],\n",
       "                       [ 5.7802e-02, -1.5888e-01,  2.6690e-01,  4.3431e-02, -4.0308e-02,\n",
       "                        -3.5058e-01,  2.2733e-01,  3.1855e-02,  1.4416e-01,  4.0369e-02,\n",
       "                        -1.2031e-01, -2.8265e-01,  8.2628e-02, -9.5358e-02, -2.1751e-01,\n",
       "                         4.5747e-03],\n",
       "                       [-3.8232e-01, -7.9223e-02,  1.5312e-01, -4.1504e-02, -2.7976e-01,\n",
       "                         1.0728e-01,  3.6081e-01,  3.3093e-02,  1.8488e-01, -4.4172e-01,\n",
       "                        -3.3009e-01, -4.3024e-02, -3.5098e-01, -3.6061e-01,  1.0634e-01,\n",
       "                         9.5592e-04],\n",
       "                       [ 4.4160e-01,  7.7926e-02, -4.5091e-01, -9.2551e-02,  1.9289e-01,\n",
       "                        -1.6036e-01,  2.0394e-02,  3.9488e-02, -4.6998e-01, -9.5758e-01,\n",
       "                        -2.8972e-03,  1.6014e-01, -5.9840e-01, -5.9724e-01, -5.7148e-01,\n",
       "                         2.9350e-01],\n",
       "                       [-2.6390e-01, -2.3035e-01,  2.5169e-01,  1.9374e-01,  1.3249e-01,\n",
       "                         1.8126e-02,  4.4641e-01,  1.0273e-01,  2.8902e-01, -1.3599e-01,\n",
       "                         3.1078e-02, -4.2082e-02, -2.9034e-02,  7.5148e-02,  1.5257e-01,\n",
       "                        -2.9483e-01],\n",
       "                       [ 2.2532e-01, -1.3061e-01,  2.4779e-01,  3.0321e-01, -2.0501e-01,\n",
       "                        -1.2278e-01, -1.8547e-01,  2.2936e-01,  3.4163e-01, -1.7652e-01,\n",
       "                         1.5976e-01,  2.0763e-01,  1.6826e-02,  1.7303e-01, -4.4001e-02,\n",
       "                        -1.2010e-03],\n",
       "                       [-5.0878e-01, -6.4575e-02,  1.4793e-01, -1.1121e-01, -1.0945e-02,\n",
       "                        -1.6528e-01,  9.1624e-02,  2.6959e-01,  2.0454e-01,  6.3685e-01,\n",
       "                        -4.5979e-01,  1.0894e-01, -2.4792e-01, -4.5541e-01, -8.3598e-01,\n",
       "                        -5.4654e-02],\n",
       "                       [-6.4777e-02,  7.7556e-02,  2.5326e-01, -4.9172e-02,  1.0826e-01,\n",
       "                        -1.8524e-02, -2.7718e-01,  3.4523e-02, -3.4351e-01, -1.7148e-02,\n",
       "                         2.8667e-01,  2.3570e-01, -1.5309e-02,  1.3020e-02, -6.5150e-02,\n",
       "                         7.2593e-02],\n",
       "                       [ 7.7158e-02,  1.1458e-01,  5.0662e-02,  1.8933e-01, -2.4379e-01,\n",
       "                        -2.7547e-01, -2.8923e-02, -1.3364e-01, -2.2656e-02, -1.4102e-01,\n",
       "                        -2.3093e-01, -9.5292e-02,  3.3108e-01,  1.6304e-01, -3.8625e-02,\n",
       "                         2.3513e-02],\n",
       "                       [-5.3381e-03, -3.4350e-02, -1.1109e-01, -1.2383e-01, -2.8369e-01,\n",
       "                        -6.9131e-02,  1.2926e-01, -8.9152e-02, -3.0919e-01,  1.0359e-02,\n",
       "                        -2.1854e-01,  9.4690e-02, -2.8230e-02,  1.2455e-01, -3.5328e-01,\n",
       "                        -1.2955e-01],\n",
       "                       [ 3.6294e-02,  2.4654e-01, -9.8446e-02, -1.1242e-01, -6.9568e-02,\n",
       "                         5.4724e-02, -1.7265e-01, -1.3108e-01, -4.9662e-01,  2.1101e-01,\n",
       "                        -1.3910e-01,  4.0102e-01,  2.9089e-02,  1.5140e-01, -1.5584e-01,\n",
       "                         2.5141e-01],\n",
       "                       [ 1.4463e-01, -7.9291e-02, -1.7556e-01, -1.4906e-01,  1.7686e-01,\n",
       "                         1.8375e-01, -1.7193e-01, -2.0072e-01, -2.0874e-03, -2.1831e-01,\n",
       "                        -2.2398e-01, -5.6867e-03, -2.0955e-01, -1.1484e-01, -2.1715e-02,\n",
       "                        -1.5109e-01],\n",
       "                       [-1.2041e-01, -2.3759e-01,  2.6234e-01,  3.1415e-02,  5.8589e-02,\n",
       "                         2.1523e-02,  3.6876e-01, -8.3462e-02, -1.6585e-01,  8.0328e-02,\n",
       "                        -6.1195e-02, -1.2416e-01, -1.3877e-01,  6.9769e-03, -1.5724e-01,\n",
       "                        -1.5956e-02],\n",
       "                       [ 1.0209e-01, -1.2497e-01,  4.1418e-02,  2.7040e-01,  2.2613e-01,\n",
       "                        -8.5351e-02, -1.2862e-01,  2.0013e-02,  4.2456e-01,  1.6231e-01,\n",
       "                         1.1908e-01,  3.1370e-01,  2.1978e-01, -5.6097e-02, -1.2952e-01,\n",
       "                         2.1282e-01],\n",
       "                       [-5.3593e-01,  3.4044e-02, -2.1732e-02, -2.5755e-03, -9.8931e-01,\n",
       "                        -2.6065e-02,  1.6539e-01, -7.4358e-02, -2.2974e-01, -4.0424e-01,\n",
       "                        -2.5571e-01, -2.9832e-01, -2.0035e-01, -2.9225e-01, -9.7106e-02,\n",
       "                         1.0558e-02]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.0928,  0.0220,  0.5652,  0.2119, -0.0313,  0.3631, -0.0319, -0.2870,\n",
       "                        0.2624,  0.1298,  0.0445,  0.4010, -0.0483,  0.5062,  0.0241,  0.2103])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[ 0.0224, -0.2742,  0.3238,  0.2250, -0.0560,  0.0680, -0.1691, -0.6117,\n",
       "                        -0.0199,  0.2623, -0.0834, -0.2940, -0.0204,  0.4487, -0.0259,  0.0668],\n",
       "                       [-0.6362, -0.2180, -0.1700, -0.1893, -0.1041,  0.2400, -0.1349, -0.5284,\n",
       "                        -0.3430,  0.2425, -0.0007, -0.0903, -0.0120,  0.3680, -0.2775,  0.1552],\n",
       "                       [-0.0348,  0.1491,  0.2041, -0.1519, -0.0266, -0.1004,  0.0221,  0.2161,\n",
       "                        -0.0474, -0.1511, -0.2713, -0.0949,  0.0391, -0.1445,  0.0331,  0.0576],\n",
       "                       [ 0.1559,  0.1580, -0.2589,  0.2649,  0.0690,  0.1870, -0.1239,  0.1115,\n",
       "                         0.2455,  0.2244, -0.1950,  0.3175,  0.0373, -0.0931,  0.2746,  0.1812],\n",
       "                       [-0.1990,  0.0311,  0.0138, -0.2235, -0.2458, -0.2204, -0.0377,  0.0026,\n",
       "                        -0.0485, -0.1455, -0.0540, -0.0442, -0.0734,  0.1540,  0.0747, -0.0082],\n",
       "                       [ 0.2007,  0.2263,  0.1994,  0.1193,  0.0409, -0.2071,  0.1568, -0.1446,\n",
       "                         0.0542,  0.1413,  0.0637,  0.0386,  0.3937, -0.2688,  0.1650,  0.1612],\n",
       "                       [-0.0534, -0.3240, -0.2272, -0.2181, -0.2483,  0.1744, -0.0054,  0.0455,\n",
       "                         0.0959, -0.1310,  0.1107,  0.1372, -0.2776, -0.1151,  0.0062, -0.2841],\n",
       "                       [-0.3713, -0.0818,  0.3780,  0.3831, -0.0640,  0.3807, -0.2323, -0.2188,\n",
       "                         0.0271,  0.1051,  0.1756, -0.1840, -0.1656,  0.2178, -0.1976,  0.3322],\n",
       "                       [-0.0320, -0.0259,  0.0046, -0.3124,  0.4304, -0.1942,  0.0990, -0.2718,\n",
       "                         0.1056, -0.0229,  0.0823,  0.2470, -0.0746,  0.1805, -0.1046, -0.2803],\n",
       "                       [ 0.0440,  0.1061,  0.1274, -0.1254, -0.1339,  0.1115, -0.0129,  0.1642,\n",
       "                         0.3314,  0.1251, -0.0922,  0.3249, -0.0241, -0.2775,  0.1013,  0.1255],\n",
       "                       [-0.1031,  0.3044, -0.0707,  0.0989,  0.1017, -0.2184,  0.1760,  0.0350,\n",
       "                        -0.0605,  0.2340,  0.2145,  0.4313,  0.1092, -0.0572,  0.1623, -0.0848],\n",
       "                       [ 0.0758,  0.0867,  0.0612, -0.0129, -0.2713, -0.2418, -0.0814, -0.1806,\n",
       "                         0.1640,  0.1089, -0.0101, -0.1120,  0.2135, -0.0424, -0.1131,  0.0862],\n",
       "                       [ 0.2241,  0.0319, -0.2239,  0.1120,  0.0045, -0.1802,  0.1171, -0.2029,\n",
       "                        -0.1889,  0.0223, -0.1139,  0.0130,  0.2405, -0.0484, -0.1008,  0.1595],\n",
       "                       [ 0.0464, -0.0038,  0.4017,  0.1552,  0.0800,  0.3080, -0.0422, -0.1685,\n",
       "                        -0.1745,  0.0292,  0.1509, -0.1392, -0.2864,  0.4750, -0.0545,  0.3723],\n",
       "                       [ 0.2170,  0.2227, -0.0264, -0.0007, -0.3789,  0.1856,  0.1288,  0.2099,\n",
       "                        -0.0960,  0.1060,  0.1621,  0.2096, -0.0342, -0.1036, -0.0229, -0.0181],\n",
       "                       [ 0.0650,  0.2664, -0.0195, -0.0299,  0.1276,  0.0763, -0.0067,  0.1434,\n",
       "                         0.2871,  0.0516,  0.1466,  0.0406,  0.0369, -0.0269,  0.1481,  0.1571]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.4483,  0.3049, -0.2241, -0.1864, -0.1477,  0.1286, -0.1217,  0.1739,\n",
       "                        0.3302,  0.0134,  0.2204, -0.2949, -0.2723,  0.3499, -0.1458, -0.1359])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[-1.3150e-01,  3.3125e-02,  1.6731e-01,  1.1185e-01,  8.1735e-02,\n",
       "                         1.2047e-01, -8.5815e-02, -2.6325e-01,  6.8723e-02,  1.6887e-01,\n",
       "                        -7.1271e-02, -9.6148e-02,  1.0746e-02, -1.0929e-01, -3.0816e-02,\n",
       "                         2.6486e-01],\n",
       "                       [-3.5132e-01, -1.3430e-01,  3.2347e-02,  2.0897e-02,  4.0859e-02,\n",
       "                         2.8482e-02,  8.7257e-02, -3.6724e-01, -1.2580e-01,  9.3010e-02,\n",
       "                         3.1410e-01, -8.5015e-02, -1.2989e-01, -3.1809e-01,  1.6621e-01,\n",
       "                         2.9538e-01],\n",
       "                       [ 1.6870e-01, -2.4607e-01,  2.0901e-01,  1.9020e-01, -1.1176e-01,\n",
       "                        -1.6551e-01,  1.0422e-01,  7.7620e-02, -1.5122e-01,  1.6982e-01,\n",
       "                         8.1318e-02, -1.4134e-01,  2.8946e-02, -2.1309e-01, -1.5397e-02,\n",
       "                        -2.0514e-01],\n",
       "                       [-2.2102e-01, -2.6606e-01, -1.6488e-01,  2.1333e-01,  2.8202e-02,\n",
       "                        -8.6423e-02, -5.0049e-02, -4.5762e-02,  3.1733e-01,  2.3995e-01,\n",
       "                         3.2652e-01, -4.2110e-03,  3.0021e-01, -3.4858e-01, -1.3853e-01,\n",
       "                        -8.4891e-02],\n",
       "                       [ 3.8137e-01,  2.7872e-01, -1.6183e-01, -2.8497e-01,  2.2726e-01,\n",
       "                        -2.0268e-01,  2.1611e-01, -1.1422e-01, -8.0570e-01, -3.1807e-01,\n",
       "                        -5.7604e-01, -6.1165e-02,  1.4771e-03,  3.6376e-01, -4.2788e-01,\n",
       "                        -2.6738e-01],\n",
       "                       [ 3.2307e-01,  5.0232e-02, -1.5053e-01, -1.6779e-01,  1.4140e-01,\n",
       "                        -1.2525e-01,  1.6652e-01,  4.8023e-01, -6.4551e-01, -3.8245e-01,\n",
       "                        -3.6234e-01, -7.5169e-02, -1.6696e-01,  3.0377e-01, -1.8346e-01,\n",
       "                        -3.3061e-01],\n",
       "                       [ 9.1115e-02,  3.9300e-01,  1.5199e-02, -5.1022e-01, -1.5170e-01,\n",
       "                        -2.2446e-01, -5.3617e-02,  5.5482e-02, -2.3873e-01,  9.9994e-02,\n",
       "                        -3.0187e-01, -1.6434e-01, -1.1040e-02,  1.8357e-01, -1.9040e-01,\n",
       "                         1.1003e-01],\n",
       "                       [ 1.1960e-03, -2.7005e-01,  1.6996e-01, -3.1717e-02,  2.0725e-02,\n",
       "                         3.2215e-01, -1.5615e-01, -1.0789e-01, -8.8282e-04,  1.0764e-01,\n",
       "                         4.1267e-03, -1.3321e-01,  1.5430e-01, -6.7845e-02,  6.0076e-02,\n",
       "                        -1.3838e-01],\n",
       "                       [-7.3978e-02, -1.3265e-01, -9.3494e-02,  1.4604e-01, -2.1327e-01,\n",
       "                         1.9147e-01,  8.7485e-02, -3.8378e-01,  2.2684e-01, -1.2173e-01,\n",
       "                         1.5064e-01,  2.1973e-01,  3.4303e-02, -2.8229e-01,  9.1791e-02,\n",
       "                        -7.3328e-02],\n",
       "                       [-3.0543e-01, -3.5043e-01,  1.3244e-01,  3.4656e-01,  1.1899e-01,\n",
       "                         7.5244e-02, -1.1620e-02, -2.5046e-02,  3.0122e-01, -4.5112e-02,\n",
       "                        -1.0056e-01, -6.6833e-03,  1.4787e-02, -5.2835e-02,  1.6722e-01,\n",
       "                         4.5668e-04],\n",
       "                       [-2.5100e-01,  5.1807e-02, -8.2522e-02, -2.5013e-01, -2.8509e-02,\n",
       "                        -1.7091e-02, -7.0645e-02,  1.1143e-01,  1.5169e-01, -1.6453e-01,\n",
       "                         1.0951e-01,  1.6321e-01, -2.1627e-01, -1.8552e-01, -2.5612e-01,\n",
       "                         1.7312e-02],\n",
       "                       [-1.5632e-02, -2.0245e-01, -5.9368e-02, -1.2713e-01, -3.8125e-02,\n",
       "                        -2.3752e-01, -1.1843e-01,  4.0752e-02, -2.8422e-02,  1.8018e-02,\n",
       "                        -5.6269e-02, -1.7986e-01, -6.6363e-02, -4.0771e-01, -2.8774e-01,\n",
       "                        -5.6308e-02],\n",
       "                       [-6.5748e-02,  7.0603e-02,  8.1948e-02, -5.2332e-02, -2.0967e-01,\n",
       "                         7.7828e-02, -2.4149e-01, -1.4352e-01, -2.2676e-01,  7.1996e-02,\n",
       "                        -1.7104e-01, -1.6985e-01, -8.1842e-02, -1.5278e-01, -1.1292e-01,\n",
       "                         8.7933e-02],\n",
       "                       [ 8.5160e-02,  3.4413e-01,  8.1750e-02, -1.2844e-01,  2.4647e-01,\n",
       "                        -2.9699e-02,  1.9134e-02,  2.0365e-01,  1.3670e-01, -2.6969e-01,\n",
       "                        -7.5872e-02, -6.7887e-03, -1.3564e-01,  3.3417e-01,  3.0079e-01,\n",
       "                        -4.9467e-02],\n",
       "                       [-3.7742e-01, -2.3255e-01, -2.7458e-01,  1.8085e-01, -2.5832e-03,\n",
       "                        -1.3372e-02, -1.1113e-02, -2.4173e-01,  1.7872e-01,  6.9390e-03,\n",
       "                         2.8278e-01,  1.9181e-01, -1.1330e-01, -2.3318e-01,  1.9788e-01,\n",
       "                        -1.6568e-01],\n",
       "                       [ 2.3418e-01, -1.8436e-01,  7.9827e-02,  6.6293e-03, -1.1029e-01,\n",
       "                        -4.8904e-02, -2.0127e-01, -1.2564e-01,  7.3326e-02, -1.2051e-01,\n",
       "                        -1.4908e-01,  1.2786e-01, -1.8464e-01,  1.2605e-02, -1.7862e-01,\n",
       "                         1.4572e-01]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.3194,  0.4248, -0.2127,  0.3436,  0.0357,  0.2069,  0.1512,  0.4506,\n",
       "                        0.2159,  0.2822, -0.1502, -0.2370, -0.0673,  0.2864,  0.2703, -0.2330])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[-0.0828, -0.3043, -0.0927, -0.1609,  0.2425,  0.3974,  0.1491, -0.1942,\n",
       "                        -0.1653, -0.1058,  0.0203, -0.1078, -0.1718,  0.1672, -0.2030,  0.2178]])),\n",
       "              ('layers.8.bias', tensor([0.1625]))]),\n",
       " 'UQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[ 3.5841e-01,  1.6514e-01, -2.3820e-02],\n",
       "                       [-1.7807e-01, -9.4814e-02,  1.9915e-01],\n",
       "                       [ 3.4816e-01,  3.7117e-03, -1.7106e-01],\n",
       "                       [ 2.2942e-01, -6.2445e-02,  2.5059e-01],\n",
       "                       [-7.4990e-01, -1.8808e-01,  4.4076e-02],\n",
       "                       [-1.3382e-01,  1.6536e-01, -1.9002e-01],\n",
       "                       [ 1.1892e-01, -2.4559e-01, -9.9979e-02],\n",
       "                       [ 3.3248e-01,  2.5386e-01, -4.8820e-02],\n",
       "                       [ 2.7385e-03,  5.1566e-01, -9.9104e-02],\n",
       "                       [ 2.8090e-02,  1.2531e-01, -5.5578e-02],\n",
       "                       [-3.2773e-01,  2.8744e-03,  1.9411e-01],\n",
       "                       [ 1.3182e-01, -2.1700e-01,  1.6562e-01],\n",
       "                       [ 6.4298e-02, -4.9701e-01, -1.0539e-04],\n",
       "                       [ 1.2084e-01,  2.6657e-01,  1.4480e-01],\n",
       "                       [-2.2819e-01, -6.5341e-02, -2.1371e-01],\n",
       "                       [-6.5579e-01,  1.1485e-01,  2.5580e-02]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([ 0.2732,  0.0633, -0.3882, -0.1609,  0.4927, -0.2797,  0.5928,  0.5664,\n",
       "                       -0.3753,  0.0296, -0.6192,  0.1247, -0.5511, -0.5585,  0.1369,  0.8618])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[ 0.0944,  0.1405, -0.4810,  0.1297, -0.1456,  0.2459, -0.0733,  0.1624,\n",
       "                         0.0683,  0.1317, -0.2952, -0.1332, -0.3310,  0.2118, -0.2186, -0.1566],\n",
       "                       [ 0.0832, -0.2055,  0.1638,  0.1764,  0.2292, -0.1830,  0.0509, -0.1219,\n",
       "                         0.1620,  0.1146, -0.1200, -0.0718, -0.1385, -0.0410, -0.0953,  0.4222],\n",
       "                       [-0.0776, -0.0322, -0.2518, -0.0932, -0.4961,  0.3614,  0.0497,  0.1025,\n",
       "                         0.7020,  0.1502, -0.1913, -0.0464,  0.0600,  0.1544, -0.1440, -0.8189],\n",
       "                       [ 0.2072,  0.2681,  0.0489,  0.2027,  0.3136,  0.1937, -0.0543,  0.1133,\n",
       "                        -0.1068,  0.0609, -0.1167, -0.0790,  0.3044,  0.1176,  0.0803,  0.5691],\n",
       "                       [-0.2190, -0.1476,  0.0645,  0.0826, -0.0097, -0.1786, -0.0169,  0.0825,\n",
       "                        -0.1604,  0.1241, -0.0224, -0.0239,  0.0213, -0.0542,  0.0384,  0.0776],\n",
       "                       [ 0.2150,  0.2281, -0.0935,  0.1520, -0.3461,  0.0153,  0.3080,  0.3154,\n",
       "                        -0.2334, -0.1463, -0.1958, -0.1066, -0.0712,  0.0027, -0.0670, -0.2075],\n",
       "                       [-0.2651, -0.0933, -0.0750, -0.1750, -0.0483,  0.2603, -0.1450,  0.1203,\n",
       "                        -0.1362, -0.0357,  0.0299, -0.2967, -0.0960, -0.2922, -0.1458,  0.3694],\n",
       "                       [ 0.0689, -0.0263,  0.0340,  0.1134, -0.3094,  0.1162,  0.2802,  0.2952,\n",
       "                        -0.2094,  0.1282, -0.0338, -0.0050,  0.2865,  0.0143,  0.1275, -0.3619],\n",
       "                       [-0.2355,  0.0793,  0.1764, -0.0889, -0.2480, -0.2117,  0.0326,  0.1928,\n",
       "                        -0.2717,  0.0335, -0.1961, -0.0695, -0.0550, -0.1150, -0.1630, -0.1110],\n",
       "                       [-0.3030,  0.1465, -0.8359, -0.1251,  0.4906,  0.0872,  0.0611, -0.2549,\n",
       "                         0.3049, -0.1593, -0.0365, -0.1252,  0.1772, -0.0056,  0.2239,  0.6353],\n",
       "                       [ 0.0974, -0.0864, -0.3862,  0.0811, -0.1973, -0.1686, -0.0621,  0.1801,\n",
       "                        -0.0130, -0.0366, -0.0689, -0.0406,  0.2547, -0.2591,  0.1980, -0.0505],\n",
       "                       [-0.0785,  0.1481, -0.4147, -0.0210,  0.1636, -0.2826, -0.0924,  0.0870,\n",
       "                        -0.1939,  0.0486, -0.0818,  0.0256,  0.1045,  0.3617, -0.0458,  0.3294],\n",
       "                       [-0.1119, -0.1581,  0.1249,  0.1504, -0.0970, -0.0822,  0.1450,  0.0555,\n",
       "                        -0.1289,  0.1312, -0.2660,  0.1139,  0.1352,  0.0858,  0.2347,  0.1095],\n",
       "                       [ 0.2529, -0.1894,  0.0989,  0.3530,  0.5192, -0.1174, -0.0621,  0.0606,\n",
       "                        -0.2441,  0.1026, -0.1155, -0.0062,  0.2827, -0.2423,  0.1320,  0.6340],\n",
       "                       [ 0.1501,  0.1626, -0.0864, -0.1675, -0.4566,  0.2752,  0.2097,  0.1576,\n",
       "                         0.1865, -0.1146, -0.2132, -0.1176, -0.0149,  0.0721, -0.0849, -0.1702],\n",
       "                       [ 0.3139, -0.0019, -0.1926,  0.0009, -0.0474,  0.2283,  0.1326, -0.0989,\n",
       "                         0.0364,  0.1240, -0.1392,  0.0973,  0.1965,  0.0653,  0.1581, -0.2893]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.3654, -0.1284,  0.2181, -0.2140, -0.1842,  0.5600, -0.0194,  0.1580,\n",
       "                       -0.1996,  0.3642,  0.1863, -0.1120,  0.3129, -0.1181, -0.1165,  0.3504])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[ 0.1709,  0.0208,  0.0403, -0.1885,  0.1810, -0.1517, -0.1019, -0.3077,\n",
       "                        -0.0440,  0.0606, -0.0032, -0.3402, -0.0516,  0.2574, -0.0626, -0.2204],\n",
       "                       [-0.0851, -0.1035,  0.1705, -0.2004, -0.1412, -0.0800, -0.1401, -0.2511,\n",
       "                        -0.1090, -0.2027,  0.1968,  0.1429, -0.2884, -0.1910, -0.0576,  0.0765],\n",
       "                       [ 0.0236, -0.1954,  0.1638, -0.2494,  0.0333,  0.0014, -0.1855, -0.1798,\n",
       "                         0.1657, -0.1343,  0.0009,  0.0385, -0.1310, -0.1036,  0.1930, -0.2173],\n",
       "                       [-0.0401,  0.0997,  0.0415,  0.0122, -0.2399,  0.1571, -0.2282, -0.1589,\n",
       "                         0.0429, -0.3078,  0.0272, -0.0336,  0.0607, -0.1662, -0.1746,  0.1183],\n",
       "                       [-0.1745,  0.0528, -0.2336,  0.2206, -0.2336, -0.0848, -0.2333, -0.0051,\n",
       "                         0.1176, -0.1556, -0.1650, -0.1671, -0.2871, -0.1707,  0.0547,  0.0523],\n",
       "                       [-0.2828, -0.3185,  0.2282, -0.0670, -0.0998, -0.0431, -0.1097,  0.2475,\n",
       "                         0.2319, -0.1291,  0.2345,  0.0979, -0.1701, -0.2590,  0.0840,  0.2584],\n",
       "                       [ 0.0546, -0.3459,  0.0834, -0.2321,  0.1228,  0.1722, -0.2624, -0.0795,\n",
       "                         0.1658,  0.0854,  0.0815, -0.2221, -0.2131, -0.4482,  0.0444, -0.0338],\n",
       "                       [ 0.0600, -0.2848,  0.2049, -0.4455,  0.1069, -0.1336,  0.1784,  0.2231,\n",
       "                         0.0274, -0.5508,  0.2067, -0.2141,  0.1736, -0.5242,  0.0697,  0.1715],\n",
       "                       [-0.1695,  0.0851, -0.0462, -0.0543,  0.1887,  0.0471,  0.1542, -0.1330,\n",
       "                        -0.2375, -0.1130, -0.2350, -0.2408,  0.1478, -0.0154,  0.0174, -0.0757],\n",
       "                       [ 0.1841,  0.1352, -0.2034,  0.2327,  0.0980, -0.2372,  0.1028,  0.0327,\n",
       "                        -0.0143,  0.2900,  0.0082,  0.0513, -0.0963,  0.1775,  0.0444, -0.1770],\n",
       "                       [-0.2115,  0.0901, -0.1347, -0.3660,  0.0812,  0.3302,  0.0667,  0.2824,\n",
       "                         0.0846, -0.4138, -0.0575, -0.0914,  0.2253, -0.4118,  0.2680,  0.1990],\n",
       "                       [-0.1842,  0.0690, -0.1058, -0.0189,  0.0749,  0.0324, -0.0805, -0.0842,\n",
       "                         0.1834,  0.0748,  0.1610,  0.1064, -0.2785, -0.1238,  0.0408, -0.1561],\n",
       "                       [-0.2255, -0.0097,  0.0041, -0.2233,  0.0506,  0.1932,  0.0904, -0.2005,\n",
       "                        -0.0902,  0.0870,  0.0176,  0.0536, -0.1257, -0.0506,  0.0969, -0.1753],\n",
       "                       [ 0.1241,  0.0317,  0.3049, -0.1565,  0.0947,  0.0717,  0.0855,  0.2229,\n",
       "                        -0.1255, -0.3678, -0.0264,  0.1394,  0.2301, -0.3900, -0.0463, -0.0105],\n",
       "                       [ 0.3355, -0.2707, -0.0496,  0.0468,  0.0781,  0.3611,  0.1491,  0.2023,\n",
       "                         0.2544, -0.4232,  0.1594,  0.2787,  0.3437,  0.0210,  0.0547,  0.2516],\n",
       "                       [-0.0397, -0.1021,  0.0904,  0.1155, -0.2014, -0.1652,  0.3382,  0.0265,\n",
       "                        -0.0673,  0.5516,  0.0060,  0.3529,  0.3961,  0.0535,  0.1077, -0.0663]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.0590, -0.1787,  0.0482, -0.1420,  0.0986,  0.1432, -0.1420,  0.0168,\n",
       "                        0.0885,  0.2817,  0.1639, -0.1373, -0.2244,  0.4765,  0.5879, -0.1838])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[-0.0490, -0.1653,  0.0665,  0.0611,  0.1201, -0.1849,  0.1444, -0.0253,\n",
       "                        -0.2671,  0.3613, -0.1018,  0.1604, -0.0274, -0.2437, -0.4298, -0.1105],\n",
       "                       [-0.1384, -0.1687, -0.0152, -0.0350,  0.1049, -0.0087,  0.2629, -0.0850,\n",
       "                         0.2021,  0.0745,  0.2158, -0.1670,  0.0774,  0.3095,  0.3875, -0.4549],\n",
       "                       [-0.1511, -0.0917, -0.1656,  0.0008,  0.3279, -0.2161,  0.2873, -0.1853,\n",
       "                         0.2004, -0.0455,  0.0459,  0.1560,  0.0293,  0.2744,  0.2660, -0.3573],\n",
       "                       [ 0.0124, -0.0410, -0.1769, -0.0958,  0.0156,  0.0773,  0.0482, -0.2006,\n",
       "                         0.0170,  0.1427, -0.2144,  0.0433,  0.1102, -0.0190, -0.2694, -0.2272],\n",
       "                       [-0.1378, -0.0737,  0.1594, -0.1986, -0.2035, -0.0112,  0.0977, -0.0659,\n",
       "                         0.0831, -0.0381,  0.2158, -0.2359, -0.1138, -0.2177, -0.2465, -0.2219],\n",
       "                       [ 0.2587, -0.1642,  0.1373,  0.1658, -0.0655,  0.1356,  0.1611,  0.0873,\n",
       "                        -0.1545, -0.1848,  0.1565,  0.2250,  0.1882,  0.1409,  0.3194, -0.1534],\n",
       "                       [-0.0397, -0.1831,  0.1901,  0.0983, -0.1370,  0.2271, -0.1930,  0.1019,\n",
       "                         0.0340, -0.0558,  0.2967, -0.1343,  0.2055,  0.3378,  0.1508, -0.3249],\n",
       "                       [-0.0131,  0.0030, -0.1045, -0.0532, -0.1470, -0.2337, -0.0703,  0.1096,\n",
       "                        -0.0396,  0.1285, -0.2261, -0.0450,  0.2042, -0.0440,  0.0738,  0.1466],\n",
       "                       [-0.0663,  0.0120,  0.1428,  0.0636,  0.1888,  0.3299, -0.1954,  0.3255,\n",
       "                         0.2670,  0.0359,  0.0773,  0.1355,  0.0293, -0.0157, -0.0504,  0.3476],\n",
       "                       [ 0.0406, -0.0677,  0.1021, -0.0232,  0.0057,  0.0490,  0.1947, -0.1299,\n",
       "                        -0.2234, -0.1301, -0.2645,  0.0253,  0.0311,  0.0575,  0.0487, -0.1145],\n",
       "                       [-0.6351, -0.0212,  0.0140, -0.1275,  0.1136,  0.1374, -0.1335, -0.2621,\n",
       "                        -0.1362, -0.3112,  0.0028,  0.0732, -0.0915,  0.1902, -0.0124, -0.4039],\n",
       "                       [ 0.1231,  0.0107, -0.0816,  0.1118,  0.0576,  0.1528, -0.0574, -0.1410,\n",
       "                         0.0329,  0.4843,  0.0487, -0.0357,  0.0105,  0.0486, -0.3228,  0.3126],\n",
       "                       [-0.1193, -0.1806,  0.0018,  0.0122, -0.2499,  0.1874, -0.2378,  0.0650,\n",
       "                        -0.1974,  0.1198, -0.1373, -0.0026,  0.2054, -0.0522,  0.0015, -0.1046],\n",
       "                       [-0.0664,  0.1811, -0.1806,  0.1269, -0.2924,  0.0235, -0.0483, -0.0309,\n",
       "                         0.1038, -0.0722, -0.1556, -0.0386, -0.1000, -0.0066,  0.0265, -0.0442],\n",
       "                       [-0.1624,  0.1669,  0.2222, -0.1701,  0.1602,  0.1913,  0.1216, -0.2770,\n",
       "                         0.0758, -0.1200, -0.3087, -0.1143,  0.1955, -0.0026,  0.0935, -0.1025],\n",
       "                       [-0.1340,  0.2737, -0.1857, -0.1198,  0.1145,  0.0978, -0.1439,  0.1450,\n",
       "                        -0.0413, -0.3528, -0.1453,  0.0598,  0.1831,  0.1981,  0.3959, -0.3171]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([ 0.2129,  0.3643,  0.1845, -0.0831, -0.0651,  0.4786,  0.5067, -0.0447,\n",
       "                       -0.0586, -0.0574, -0.0789,  0.4342, -0.2500,  0.1236, -0.3058,  0.4871])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[-0.1654,  0.3741,  0.1493,  0.1635,  0.0051,  0.2539,  0.3529, -0.0318,\n",
       "                        -0.1377, -0.0812,  0.0040, -0.4712,  0.0625,  0.0107,  0.1188,  0.2518]])),\n",
       "              ('layers.8.bias', tensor([-0.0032]))]),\n",
       " 'LQ': OrderedDict([('layers.0.weight',\n",
       "               tensor([[-0.8684,  0.0893, -0.0856],\n",
       "                       [ 0.5625,  0.3643,  0.0608],\n",
       "                       [-0.8896, -0.3628, -0.2124],\n",
       "                       [-0.1659,  0.0888, -0.2998],\n",
       "                       [ 0.1008, -0.5009, -0.0601],\n",
       "                       [-0.0589, -0.0759,  0.7111],\n",
       "                       [-0.3779,  0.3554, -0.0100],\n",
       "                       [ 0.3125, -0.0608, -0.7775],\n",
       "                       [-0.2173,  0.2062,  0.5100],\n",
       "                       [-0.6714, -0.0848, -0.1719],\n",
       "                       [ 0.6716, -0.0899, -0.1833],\n",
       "                       [ 0.3574,  0.5889, -0.6147],\n",
       "                       [-0.6536,  0.0137, -0.4455],\n",
       "                       [-0.0522,  0.0532, -0.1355],\n",
       "                       [-0.6948, -0.3502,  0.5102],\n",
       "                       [ 0.3349, -0.0164,  0.4295]])),\n",
       "              ('layers.0.bias',\n",
       "               tensor([-0.0171, -0.3588,  0.2489, -0.6247, -0.6947, -0.1985,  0.0771, -0.4047,\n",
       "                       -0.0894,  0.6663, -0.2297, -0.2426,  0.3271, -0.0055, -0.5027,  0.0044])),\n",
       "              ('layers.2.weight',\n",
       "               tensor([[ 0.0894,  0.0066, -0.0225, -0.0747, -0.0276, -0.0210, -0.2132, -1.2195,\n",
       "                         0.0780,  0.0549,  0.0886, -0.8701, -0.0566, -0.2836, -0.2653,  0.2662],\n",
       "                       [-0.1364, -0.1643, -0.1934,  0.0279, -0.1139, -0.4279,  0.1864,  0.1322,\n",
       "                        -0.2512, -0.1194,  0.1003,  0.1573, -0.6400, -0.0936,  0.0028, -0.3433],\n",
       "                       [-0.2131, -0.0308, -0.1767, -0.1432,  0.0908,  0.1301, -0.1422, -0.2292,\n",
       "                        -0.0041, -0.2185, -0.1669, -0.0075,  0.0218, -0.1249, -0.2203, -0.1764],\n",
       "                       [ 0.1570,  0.1396, -0.1652, -0.1402,  0.0297,  0.0586, -0.0629, -0.1015,\n",
       "                        -0.1679, -0.2275, -0.2256, -0.2185, -0.1027,  0.0864,  0.1785, -0.2018],\n",
       "                       [-0.1487, -0.1550,  0.0389, -0.1327, -0.4405,  0.0754,  0.3569,  0.6565,\n",
       "                        -0.4242, -0.5509,  0.0292, -0.2574, -0.6639, -0.0477, -1.0909,  0.0564],\n",
       "                       [ 0.0188,  0.0265, -0.0803, -0.1041, -0.2295, -0.1267, -0.2760, -0.2028,\n",
       "                        -0.0212, -0.2741, -0.1089, -0.2922,  0.0316,  0.1212, -0.1810, -0.0599],\n",
       "                       [ 0.2063, -0.3295, -0.0153,  0.2389, -0.0750,  0.1425,  0.2086, -0.2533,\n",
       "                         0.1284,  0.3130,  0.0089, -0.2768,  0.0874,  0.1839,  0.1825, -0.2608],\n",
       "                       [-0.3013,  0.2186, -0.1703, -0.1151,  0.0080, -0.2220, -0.1626,  0.1100,\n",
       "                        -0.0174, -0.1043, -0.0901, -0.1692,  0.0507,  0.0388,  0.1261, -0.1262],\n",
       "                       [-0.1120,  0.2442,  0.0306,  0.1736,  0.2868, -1.7214, -0.0928,  0.0704,\n",
       "                        -0.0510,  0.1696,  0.2093,  0.0309,  0.2618, -0.1576, -0.4189,  0.3071],\n",
       "                       [ 0.4019,  0.4380,  0.3705,  0.0966,  0.0957, -0.2952,  0.2403,  0.0951,\n",
       "                         0.3073, -0.0519, -0.5523,  0.3352,  0.1083, -0.0402,  0.1749,  0.2590],\n",
       "                       [ 0.0193, -0.0762,  0.0577,  0.1661, -0.0729, -0.1637, -0.2380,  0.1645,\n",
       "                         0.1316, -0.2311, -0.1480, -0.1443,  0.0288,  0.1073,  0.0526,  0.0665],\n",
       "                       [ 0.0587, -0.0284,  0.1126, -0.0068,  0.0203, -0.0945,  0.0527,  0.0254,\n",
       "                        -0.0065, -0.2261, -0.0645, -0.1741,  0.0845, -0.0274, -0.1480,  0.1850],\n",
       "                       [ 0.0550, -0.1975,  0.0749,  0.1261,  0.4422,  0.2704,  0.1917,  0.0898,\n",
       "                         0.1472,  0.3736, -0.0220,  0.1801,  0.0325,  0.1428, -0.1331,  0.1536],\n",
       "                       [ 0.0769, -0.7634,  0.3054, -0.0023, -0.1052,  0.0208,  0.0990,  0.0169,\n",
       "                         0.0590,  0.0911, -0.2945,  0.1008, -0.1412,  0.1920,  0.2922,  0.1231],\n",
       "                       [ 0.2031, -0.2321,  0.2635,  0.3592,  0.2955,  0.0820,  0.1169,  0.3412,\n",
       "                         0.1247,  0.0526, -0.5709,  0.1640,  0.2226, -0.0345,  0.0413, -0.4621],\n",
       "                       [-0.3612, -0.1456,  0.1945,  0.1877, -0.0339, -0.1169,  0.0832,  0.7410,\n",
       "                         0.1051,  0.0048,  0.3052,  0.4861, -0.0528,  0.2942, -0.2599,  0.3927]])),\n",
       "              ('layers.2.bias',\n",
       "               tensor([ 0.1936,  0.2943, -0.2812, -0.1054,  0.4364,  0.0885,  0.1237, -0.1732,\n",
       "                       -0.2829, -0.1052, -0.0905, -0.2195, -0.1622,  0.1273,  0.0166,  0.0681])),\n",
       "              ('layers.4.weight',\n",
       "               tensor([[-3.9340e-02,  1.9182e-01,  3.2218e-02,  8.6378e-03, -4.7713e-01,\n",
       "                         8.6632e-02,  2.0024e-02,  5.2087e-02,  1.3352e-01, -3.4919e-01,\n",
       "                         3.5385e-02,  7.1608e-02, -1.2223e-02, -2.9098e-01,  6.9151e-02,\n",
       "                        -3.9035e-01],\n",
       "                       [-2.5397e-01,  2.4191e-02,  1.2423e-01,  2.2197e-01, -4.3400e-01,\n",
       "                        -1.1159e-01, -1.2198e-01,  1.5413e-01,  1.9130e-01, -5.4174e-02,\n",
       "                         2.9360e-01,  3.8250e-02,  2.0634e-01, -2.9101e-01,  1.3290e-01,\n",
       "                        -1.5884e-02],\n",
       "                       [ 3.3518e-01,  1.5391e-01, -1.8456e-01, -1.8410e-01, -5.3243e-01,\n",
       "                        -6.0285e-02, -9.5760e-02, -1.8205e-01,  2.4398e-01,  2.9420e-02,\n",
       "                         2.9688e-01, -1.4737e-01,  2.5025e-01,  3.4147e-02,  2.8649e-01,\n",
       "                        -3.8980e-02],\n",
       "                       [-8.1042e-02, -2.8688e-01, -1.7941e-01, -5.5147e-02, -2.8188e-01,\n",
       "                        -9.8178e-02,  2.9289e-01,  1.2270e-01, -1.7589e-01,  8.4900e-02,\n",
       "                        -1.4353e-01,  9.1055e-02,  5.2689e-02,  1.9090e-01,  1.3137e-01,\n",
       "                        -4.3012e-01],\n",
       "                       [ 2.9307e-01,  8.4140e-02,  2.2002e-01,  1.2995e-01, -1.1225e+00,\n",
       "                         1.9332e-01,  1.0538e-01, -1.5878e-01,  1.7041e-01, -4.0572e-01,\n",
       "                         2.3353e-01, -4.9941e-02, -6.9296e-02, -2.5207e-01, -2.5780e-01,\n",
       "                        -2.7205e-01],\n",
       "                       [ 6.2945e-01,  3.7389e-01, -1.9798e-01,  6.0293e-02,  4.5362e-01,\n",
       "                         3.7861e-01, -5.5562e-01, -1.4537e-01, -4.3099e-01, -6.5519e-01,\n",
       "                         2.7342e-01,  1.1066e-04, -4.8084e-01, -3.7349e-01, -6.6575e-01,\n",
       "                         1.5445e-01],\n",
       "                       [-2.0314e-01, -1.5942e-01, -7.6821e-03, -1.5082e-01, -2.4192e-01,\n",
       "                         6.9685e-02,  1.5700e-01, -4.6055e-02, -2.0514e-01, -2.4826e-01,\n",
       "                         1.8881e-01,  1.3659e-01, -1.7293e-02, -1.4868e-01, -2.4333e-02,\n",
       "                         2.3044e-02],\n",
       "                       [ 1.8816e-01, -9.1035e-02, -2.5521e-02,  1.0259e-01,  7.4133e-03,\n",
       "                        -5.3961e-02, -1.6441e-02, -1.9217e-01,  7.3260e-02, -1.5971e-02,\n",
       "                         3.9540e-02,  1.3206e-01,  1.9273e-01,  5.8898e-02,  2.0551e-01,\n",
       "                        -1.2251e-01],\n",
       "                       [ 5.9684e-02, -4.4551e-01,  4.8957e-02,  2.2008e-01, -2.4740e-01,\n",
       "                        -2.3716e-02,  1.7413e-01, -2.1854e-01, -3.3156e-02,  2.4748e-01,\n",
       "                        -1.7856e-02,  7.0854e-03,  6.5212e-02,  6.5161e-02,  2.1255e-01,\n",
       "                         8.5987e-02],\n",
       "                       [ 2.8066e-01, -2.5116e-01, -3.4767e-02,  1.2782e-01, -3.0234e-01,\n",
       "                        -1.3209e-01, -1.1205e-01, -2.6297e-01,  1.7412e-01,  1.7586e-01,\n",
       "                         1.7679e-01,  1.0707e-01,  1.2738e-01,  1.7327e-01, -7.3457e-02,\n",
       "                        -4.1694e-01],\n",
       "                       [-2.4783e-01, -2.2139e-01,  8.5869e-02, -1.4084e-01, -2.7582e-01,\n",
       "                        -1.8207e-01,  7.8582e-02, -6.1112e-02,  1.0989e-01, -1.4638e-01,\n",
       "                        -1.4936e-01,  7.0238e-02, -1.1720e-01, -2.8214e-01,  5.4475e-02,\n",
       "                        -9.8122e-02],\n",
       "                       [ 5.0904e-02,  3.4982e-01,  9.6286e-02, -1.7539e-01,  5.2062e-01,\n",
       "                         3.2452e-02, -1.4886e-01,  2.1876e-01, -2.3871e-01, -2.6421e-01,\n",
       "                        -1.4828e-01,  8.1261e-02, -7.0353e-03, -1.5252e-01, -1.4380e-01,\n",
       "                         2.7345e-01],\n",
       "                       [ 1.2886e+00, -1.1457e-01, -6.3880e-02, -1.3640e-01,  3.6928e-01,\n",
       "                        -2.0990e-01, -3.4822e-01,  7.5157e-02, -7.1810e-01, -1.1293e-01,\n",
       "                        -1.2030e-01,  2.0075e-01, -4.6742e-01, -5.0185e-01, -5.5835e-03,\n",
       "                        -2.1546e-01],\n",
       "                       [-2.6348e-01,  1.0009e-01, -1.6744e-01,  4.8137e-02, -9.3048e-02,\n",
       "                        -2.2899e-03, -4.3686e-02,  2.3652e-01,  1.1513e-01, -2.7981e-01,\n",
       "                         3.0687e-02,  2.2116e-01, -2.8012e-01,  6.2067e-02, -1.5198e-01,\n",
       "                        -2.3903e-01],\n",
       "                       [-6.3962e-03, -3.5008e-01, -1.1253e-01,  1.2268e-02,  3.6266e-01,\n",
       "                         1.6968e-01,  1.8856e-01, -2.6138e-01, -5.5930e-02,  1.0644e-01,\n",
       "                         2.4709e-02,  1.9134e-01, -2.6994e-02, -2.1745e-01,  1.8135e-01,\n",
       "                        -1.0180e-01],\n",
       "                       [ 1.2713e-01, -7.5727e-02, -1.3291e-01, -1.0733e-01,  1.3220e-02,\n",
       "                         3.3671e-01,  2.8617e-02,  1.1056e-01, -3.8413e-01, -1.9878e-01,\n",
       "                        -8.8354e-02, -6.5541e-02, -1.0821e-01,  2.6769e-01, -2.1190e-01,\n",
       "                        -7.0258e-01]])),\n",
       "              ('layers.4.bias',\n",
       "               tensor([ 0.1981, -0.2600, -0.0927,  0.3250,  0.2143,  0.0823, -0.1035,  0.3628,\n",
       "                        0.0880,  0.2133, -0.1981,  0.5485, -0.0606,  0.0577,  0.2123,  0.2878])),\n",
       "              ('layers.6.weight',\n",
       "               tensor([[-2.2640e-01,  1.7919e-01, -2.9875e-01, -2.6099e-01, -1.5204e-01,\n",
       "                        -2.3232e-01,  2.1063e-01,  7.2282e-02,  3.2199e-02,  1.5791e-01,\n",
       "                        -1.2497e-01, -1.5364e-01, -2.5261e-01, -2.0499e-01,  1.4000e-01,\n",
       "                        -1.3993e-01],\n",
       "                       [ 2.1735e-02,  7.4618e-02, -1.6960e-01, -2.7145e-01,  7.5257e-02,\n",
       "                        -1.0792e-01,  1.7982e-01, -1.6626e-01,  1.1288e-01, -1.1752e-01,\n",
       "                         5.6374e-02, -2.6012e-01,  8.2339e-02,  8.9356e-02,  7.6684e-03,\n",
       "                         6.6311e-02],\n",
       "                       [ 1.3640e-01, -1.7126e-01, -9.3260e-02, -5.9649e-03,  3.7047e-02,\n",
       "                        -2.4802e-01, -1.4644e-01, -1.0649e-01, -1.1431e-01,  9.4417e-02,\n",
       "                        -6.4055e-02, -1.0950e-01, -1.4755e-01, -4.1037e-02, -3.0762e-01,\n",
       "                        -2.1583e-01],\n",
       "                       [-2.6680e-01,  1.3936e-01,  9.6788e-03,  7.7830e-02, -2.3736e-01,\n",
       "                        -3.0631e-02,  7.8788e-02, -1.8592e-01, -1.0661e-01,  1.9360e-01,\n",
       "                        -1.1319e-01, -1.8824e-01, -1.7290e-01, -6.1103e-02,  2.0890e-01,\n",
       "                        -2.1453e-01],\n",
       "                       [ 3.5683e-01, -8.3243e-02,  1.2542e-01,  2.3603e-01,  9.5561e-02,\n",
       "                         1.6491e-02, -1.0711e-02, -2.7455e-02, -4.1979e-02,  1.2222e-01,\n",
       "                        -1.7331e-02, -3.8040e-01,  2.6685e-01,  1.5283e-03,  1.0088e-01,\n",
       "                         6.7160e-02],\n",
       "                       [-9.9472e-02, -2.1813e-01,  8.4064e-02,  2.2691e-01, -1.8575e-01,\n",
       "                         1.0213e-01,  2.0634e-01, -1.1755e-01, -2.2593e-01, -1.2863e-02,\n",
       "                         1.4626e-01, -1.8385e-01,  1.0981e-01,  3.9422e-02,  4.5056e-03,\n",
       "                        -1.8606e-01],\n",
       "                       [ 3.3667e-02, -2.1471e-01,  4.6724e-03,  2.9955e-01, -1.5808e-02,\n",
       "                         8.1592e-02,  1.4414e-01,  2.2559e-01,  2.3676e-01, -1.9021e-01,\n",
       "                         8.3277e-02, -4.5290e-01,  2.1291e-01, -1.5823e-01, -2.5639e-02,\n",
       "                         1.1627e-01],\n",
       "                       [-9.1456e-01, -6.1976e-02, -6.1514e-01, -1.6127e-01, -1.6520e+00,\n",
       "                         2.5342e-01, -1.0582e-01, -4.1066e-02, -2.9491e-01, -6.3731e-01,\n",
       "                        -5.3274e-02,  5.0736e-01,  3.5573e-01, -1.1558e-01, -1.0145e-02,\n",
       "                        -1.2695e+00],\n",
       "                       [ 1.1769e-01, -2.7989e-02,  8.6633e-02,  1.3926e-01,  2.1145e-01,\n",
       "                        -3.5437e-01,  1.1797e-01,  2.8624e-01,  2.1113e-01,  1.7942e-01,\n",
       "                         1.0465e-02, -4.4372e-01,  2.6842e-01,  1.2458e-01,  2.6276e-01,\n",
       "                         1.5968e-01],\n",
       "                       [ 4.1194e-02,  1.1014e-01, -5.0555e-02, -1.7130e-02,  1.5159e-01,\n",
       "                        -1.3139e-01, -6.7495e-02,  1.2476e-01,  7.7408e-02,  1.4487e-01,\n",
       "                         1.3659e-01,  8.7577e-03, -1.8800e-01,  6.2635e-02, -2.2224e-01,\n",
       "                        -2.1322e-01],\n",
       "                       [-8.7917e-02,  5.1060e-02,  1.9100e-01,  3.0003e-01,  4.3146e-02,\n",
       "                        -1.7637e-01,  9.3159e-03,  4.0971e-02,  2.8879e-01,  1.7803e-01,\n",
       "                        -8.7732e-02, -2.2713e-01, -2.4711e-01, -1.1839e-01,  3.5669e-01,\n",
       "                         2.0005e-01],\n",
       "                       [ 3.0995e-02, -1.6247e-01, -6.7116e-03,  4.3637e-02, -1.0549e-01,\n",
       "                         1.0055e-02, -1.4038e-01, -1.7834e-01,  6.0148e-02,  1.2946e-01,\n",
       "                         1.1530e-01, -7.8736e-02,  5.9595e-02, -2.4557e-01, -1.4439e-02,\n",
       "                        -2.3587e-01],\n",
       "                       [ 3.9054e-01, -6.7263e-03,  4.2837e-02,  6.4888e-02,  1.0908e-02,\n",
       "                        -3.7752e-01,  1.3824e-01,  1.5798e-01, -8.0806e-02,  2.1314e-01,\n",
       "                        -1.2530e-02, -8.8338e-02, -2.5223e-01,  7.2345e-02,  1.9747e-01,\n",
       "                         5.0252e-02],\n",
       "                       [-3.7164e-02, -2.9537e-01, -9.3801e-01, -2.8417e-01, -3.0886e-01,\n",
       "                         2.2405e-01, -1.5799e-01, -1.2492e-01, -1.4190e-01, -4.3513e-01,\n",
       "                        -1.2940e-01,  5.1611e-01,  1.2441e-01, -9.4705e-02, -8.1565e-02,\n",
       "                        -2.8780e-01],\n",
       "                       [ 3.1872e-01,  2.2306e-02,  4.3358e-01,  2.0345e-01,  1.4198e-01,\n",
       "                         4.5533e-01, -5.2061e-02,  1.8049e-01,  8.1670e-03,  2.3901e-01,\n",
       "                        -1.0637e-01,  5.6708e-01,  7.4431e-01, -6.4775e-02,  3.9338e-01,\n",
       "                         1.9994e-01],\n",
       "                       [ 3.6596e-02,  1.8497e-01,  1.8985e-01,  2.3508e-01,  3.5320e-01,\n",
       "                        -2.2501e-01,  1.8742e-01,  1.7320e-01,  1.9803e-01, -1.8496e-01,\n",
       "                        -5.1904e-02, -1.4766e-01, -2.0575e-01, -9.5398e-02,  3.6901e-01,\n",
       "                         2.1886e-01]])),\n",
       "              ('layers.6.bias',\n",
       "               tensor([-0.0103,  0.0576, -0.0328, -0.1896,  0.1817, -0.1449,  0.1356,  0.3901,\n",
       "                        0.2321, -0.0645,  0.4411, -0.2213,  0.3765,  0.1327, -0.0872,  0.3311])),\n",
       "              ('layers.8.weight',\n",
       "               tensor([[ 0.0538, -0.0022,  0.0307, -0.2018, -0.1084,  0.2466, -0.2149,  0.6307,\n",
       "                        -0.3501,  0.0013, -0.2156, -0.0144, -0.3894,  0.1237,  0.3280, -0.2396]])),\n",
       "              ('layers.8.bias', tensor([0.0693]))])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define quantiles and hyperparameters\n",
    "q_median = 0.5\n",
    "q_upper = 0.975\n",
    "q_lower = 0.025\n",
    "dims = model['dims']\n",
    "lr = model['lr']\n",
    "batch_size = int(model['batch_size'])\n",
    "epoch = model['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch size: 500\n",
      "epoch: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"lr:\", lr)\n",
    "print(\"batch size:\", batch_size)\n",
    "print(\"epoch:\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done A_WTG01\n",
      "Done A_WTG02\n",
      "Done A_WTG03\n",
      "Done A_WTG04\n",
      "Done A_WTG05\n",
      "Done A_WTG06\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################################### training ######################################################### \n",
    "\n",
    "turbines = data_finetune.instanceID.unique()\n",
    "median_state_dict_all = []\n",
    "UQ_state_dict_all = []\n",
    "LQ_state_dict_all = []\n",
    "\n",
    "\n",
    "for ID in turbines:\n",
    "    \n",
    "    # select data based on turbine ID\n",
    "    data_temp = data_finetune[data_finetune['instanceID'] == ID]\n",
    "\n",
    "    # normalize data\n",
    "    X = scaler1.transform(data_temp.iloc[:, 5:-1])\n",
    "    y = scaler2.transform(data_temp.iloc[:, -1:])\n",
    "    \n",
    "    # create network and load pretrain weights\n",
    "    net_median_temp = Net(dims = dims)\n",
    "    net_median_temp.load_state_dict(pretrain['median'])\n",
    "    \n",
    "    net_upper_temp = Net(dims = dims)\n",
    "    net_upper_temp.load_state_dict(pretrain['UQ'])\n",
    "    \n",
    "    net_lower_temp = Net(dims = dims)\n",
    "    net_lower_temp.load_state_dict(pretrain['LQ'])\n",
    "    \n",
    "    # train\n",
    "    net_median_temp, median_state_dict = train(X=X, y=y, quantile=q_median, net=net_median_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_upper_temp, UQ_state_dict = train(X=X, y=y, quantile=q_upper, net=net_upper_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    net_lower_temp, LQ_state_dict = train(X=X, y=y, quantile=q_lower, net=net_lower_temp, \n",
    "                                          lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "    \n",
    "    median_state_dict_all.append(median_state_dict)\n",
    "    UQ_state_dict_all.append(UQ_state_dict)\n",
    "    LQ_state_dict_all.append(LQ_state_dict)\n",
    "    \n",
    "    print('Done', ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_state_dict_all_zip = dict(zip(turbines, median_state_dict_all))\n",
    "UQ_state_dict_all_zip = dict(zip(turbines, UQ_state_dict_all))\n",
    "LQ_state_dict_all_zip = dict(zip(turbines, LQ_state_dict_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # save trained network\n",
    "\n",
    "# torch.save(median_state_dict_all_zip, sys.path[0] + '/median.pth')\n",
    "# torch.save(UQ_state_dict_all_zip, sys.path[0] + '/UQ.pth')\n",
    "# torch.save(LQ_state_dict_all_zip, sys.path[0] + '/LQ.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
