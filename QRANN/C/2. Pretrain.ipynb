{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import time\r\n",
    "import sys\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "site = 'C'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# get parent directory\r\n",
    "os.chdir(\"..\")\r\n",
    "\r\n",
    "# import file\r\n",
    "from network import Net\r\n",
    "from learning import train\r\n",
    "\r\n",
    "# get higher level parent directory\r\n",
    "os.chdir(\"..\")\r\n",
    "\r\n",
    "directory = 'Data_clean'\r\n",
    "data_name = site + '_data_pretrain.csv'\r\n",
    "scaler_nameX = site + \"_scalerX.pkl\"\r\n",
    "scaler_nameY = site + \"_scalerY.pkl\"\r\n",
    "\r\n",
    "# load pretrain data and scaler functions \r\n",
    "data_pretrain = pd.read_csv(os.path.join(os.getcwd(), directory, data_name), index_col = 0)\r\n",
    "scalerX = pickle.load(open(os.path.join(os.getcwd(), directory, scaler_nameX),'rb'))\r\n",
    "scalerY = pickle.load(open(os.path.join(os.getcwd(), directory, scaler_nameY),'rb'))\r\n",
    "\r\n",
    "# reset to current directory\r\n",
    "fd = sys.path[0]\r\n",
    "os.chdir(fd)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# separate X and y, and apply standardscaler transform (normalize and scale to unit variance)\r\n",
    "X_pretrain = data_pretrain.iloc[:, 5:-1].values\r\n",
    "X_pretrain = scalerX.transform(X_pretrain)\r\n",
    "\r\n",
    "y_pretrain = data_pretrain.iloc[:, -1:].values\r\n",
    "y_pretrain = scalerY.transform(y_pretrain)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pretraining"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# load hyperparameter settings\r\n",
    "model = torch.load( sys.path[0] + '/hparams.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# # define quantiles and hyperparameters\r\n",
    "q_median = 0.5\r\n",
    "q_upper = 0.975\r\n",
    "q_lower = 0.025\r\n",
    "dims = model['dims']\r\n",
    "lr = model['lr']\r\n",
    "batch_size = int(model['batch_size'])\r\n",
    "epoch = model['epoch']\r\n",
    "\r\n",
    "print(\"lr:\", lr)\r\n",
    "print(\"batch size:\", batch_size)\r\n",
    "print(\"epoch:\", epoch)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lr: 0.005\n",
      "batch size: 1000\n",
      "epoch: 20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# # initialize network \r\n",
    "net_median = Net(dims = dims)\r\n",
    "net_upper = Net(dims = dims)\r\n",
    "net_lower = Net(dims = dims)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "%%time\r\n",
    "# Train\r\n",
    "net_median, median_state_dict = train(X_train=X_pretrain, y_train=y_pretrain, quantile=q_median, net=net_median, \r\n",
    "                                     lr=lr, batch_size=batch_size, epoch=epoch)\r\n",
    "net_upper, UQ_state_dict = train(X_train=X_pretrain, y_train=y_pretrain, quantile=q_upper, net=net_upper, \r\n",
    "                                 lr=lr, batch_size=batch_size, epoch=epoch)\r\n",
    "net_lower, LQ_state_dict = train(X_train=X_pretrain, y_train=y_pretrain, quantile=q_lower, net=net_lower, \r\n",
    "                                 lr=lr, batch_size=batch_size, epoch=epoch)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save trained network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# create dictionary to store the trained weights\r\n",
    "pretrain_state_dict = {'median': net_median.state_dict(), \r\n",
    "                       'UQ': net_upper.state_dict(),\r\n",
    "                       'LQ': net_lower.state_dict()}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# save the dictionary\r\n",
    "# torch.save(pretrain_state_dict, sys.path[0] + '/pretrain.pth')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}