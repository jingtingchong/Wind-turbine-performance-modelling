{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parent directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# import file\n",
    "from network import Net\n",
    "from learning import train\n",
    "\n",
    "# get higher level parent directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "directory = 'Data_clean'\n",
    "data_name = site + '_data_pretrain.csv'\n",
    "scaler_nameX = site + \"_scalerX.pkl\"\n",
    "scaler_nameY = site + \"_scalerY.pkl\"\n",
    "\n",
    "# load pretrain data and scaler functions \n",
    "data_pretrain = pd.read_csv(os.path.join(os.getcwd(), directory, data_name), index_col = 0)\n",
    "scalerX = pickle.load(open(os.path.join(os.getcwd(), directory, scaler_nameX),'rb'))\n",
    "scalerY = pickle.load(open(os.path.join(os.getcwd(), directory, scaler_nameY),'rb'))\n",
    "\n",
    "# reset to current directory\n",
    "fd = sys.path[0]\n",
    "os.chdir(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate X and y, and apply standardscaler transform (normalize and scale to unit variance)\n",
    "X_pretrain = data_pretrain.iloc[:, 5:-1].values\n",
    "X_pretrain = scalerX.transform(X_pretrain)\n",
    "\n",
    "y_pretrain = data_pretrain.iloc[:, -1:].values\n",
    "y_pretrain = scalerY.transform(y_pretrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hyperparameter settings\n",
    "model = torch.load( sys.path[0] + '/hparams.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch size: 1000\n",
      "epoch: 20\n"
     ]
    }
   ],
   "source": [
    "# # define quantiles and hyperparameters\n",
    "q_median = 0.5\n",
    "q_upper = 0.975\n",
    "q_lower = 0.025\n",
    "dims = model['dims']\n",
    "lr = model['lr']\n",
    "batch_size = int(model['batch_size'])\n",
    "epoch = model['epoch']\n",
    "\n",
    "print(\"lr:\", lr)\n",
    "print(\"batch size:\", batch_size)\n",
    "print(\"epoch:\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize network \n",
    "net_median = Net(dims = dims)\n",
    "net_upper = Net(dims = dims)\n",
    "net_lower = Net(dims = dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train\n",
    "net_median, median_state_dict = train(X_train=X_pretrain, y_train=y_pretrain, quantile=q_median, net=net_median, \n",
    "                                     lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "net_upper, UQ_state_dict = train(X_train=X_pretrain, y_train=y_pretrain, quantile=q_upper, net=net_upper, \n",
    "                                 lr=lr, batch_size=batch_size, epoch=epoch)\n",
    "net_lower, LQ_state_dict = train(X_train=X_pretrain, y_train=y_pretrain, quantile=q_lower, net=net_lower, \n",
    "                                 lr=lr, batch_size=batch_size, epoch=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to store the trained weights\n",
    "pretrain_state_dict = {'median': net_median.state_dict(), \n",
    "                       'UQ': net_upper.state_dict(),\n",
    "                       'LQ': net_lower.state_dict()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary\n",
    "# torch.save(pretrain_state_dict, sys.path[0] + '/pretrain.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
